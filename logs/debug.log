2025-07-23 13:26:02,691 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: Initializing trainer with parameters: {'self': <lightning.pytorch.trainer.trainer.Trainer object at 0x7fb9418d1d60>, 'accelerator': 'gpu', 'strategy': <internal.mp_strategy.MPStrategy object at 0x7fb94182d580>, 'devices': -1, 'num_nodes': 1, 'precision': None, 'logger': <lightning.pytorch.loggers.wandb.WandbLogger object at 0x7fb94182e690>, 'callbacks': [<internal.entrypoints.gspl.LazyInstance_SaveGaussian object at 0x7fbb21664bf0>, <internal.entrypoints.gspl.LazyInstance_ValidateOnTrainEnd object at 0x7fb941c14f20>, <internal.entrypoints.gspl.LazyInstance_KeepRunningIfWebViewerEnabled object at 0x7fb941eb2270>, <internal.entrypoints.gspl.LazyInstance_StopImageSavingThreads object at 0x7fb941f822a0>, <internal.entrypoints.gspl.LazyInstance_ProgressBar object at 0x7fb941cfbda0>, <internal.entrypoints.gspl.LazyInstance_StopDataLoaderCacheThread object at 0x7fb941f820c0>, <internal.callbacks.MySaveConfigCallback object at 0x7fb940cd5b80>], 'fast_dev_run': False, 'max_epochs': None, 'min_epochs': None, 'max_steps': 90000, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'overfit_batches': 0.0, 'val_check_interval': None, 'check_val_every_n_epoch': 999999, 'num_sanity_val_steps': 1, 'log_every_n_steps': None, 'enable_checkpointing': False, 'enable_progress_bar': None, 'enable_model_summary': None, 'accumulate_grad_batches': 1, 'gradient_clip_val': None, 'gradient_clip_algorithm': None, 'deterministic': None, 'benchmark': None, 'inference_mode': True, 'use_distributed_sampler': False, 'profiler': None, 'detect_anomaly': False, 'barebones': False, 'plugins': None, 'sync_batchnorm': False, 'reload_dataloaders_every_n_epochs': 0, 'default_root_dir': None, 'model_registry': None, '__class__': <class 'lightning.pytorch.trainer.trainer.Trainer'>}
2025-07-23 13:26:02,778 - lightning.pytorch.utilities.rank_zero - INFO - GPU available: True (cuda), used: True
2025-07-23 13:26:02,779 - lightning.pytorch.utilities.rank_zero - INFO - TPU available: False, using: 0 TPU cores
2025-07-23 13:26:02,779 - lightning.pytorch.utilities.rank_zero - INFO - HPU available: False, using: 0 HPUs
2025-07-23 13:26:02,875 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: trainer fit stage
2025-07-23 13:26:02,875 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_callbacks
2025-07-23 13:26:02,876 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: setting up strategy environment
2025-07-23 13:26:09,697 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: Initializing trainer with parameters: {'self': <lightning.pytorch.trainer.trainer.Trainer object at 0x70f65a8c8fb0>, 'accelerator': 'gpu', 'strategy': <internal.mp_strategy.MPStrategy object at 0x70f65a4cab70>, 'devices': -1, 'num_nodes': 1, 'precision': None, 'logger': <lightning.pytorch.loggers.wandb.WandbLogger object at 0x70f65a71c4a0>, 'callbacks': [<internal.entrypoints.gspl.LazyInstance_SaveGaussian object at 0x70f83a368c50>, <internal.entrypoints.gspl.LazyInstance_ValidateOnTrainEnd object at 0x70f65aa94800>, <internal.entrypoints.gspl.LazyInstance_KeepRunningIfWebViewerEnabled object at 0x70f65ac361b0>, <internal.entrypoints.gspl.LazyInstance_StopImageSavingThreads object at 0x70f65a9ab9b0>, <internal.entrypoints.gspl.LazyInstance_ProgressBar object at 0x70f65a6848f0>, <internal.entrypoints.gspl.LazyInstance_StopDataLoaderCacheThread object at 0x70f65ab19c70>, <internal.callbacks.MySaveConfigCallback object at 0x70f65a6f4980>], 'fast_dev_run': False, 'max_epochs': None, 'min_epochs': None, 'max_steps': 90000, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'overfit_batches': 0.0, 'val_check_interval': None, 'check_val_every_n_epoch': 999999, 'num_sanity_val_steps': 1, 'log_every_n_steps': None, 'enable_checkpointing': False, 'enable_progress_bar': None, 'enable_model_summary': None, 'accumulate_grad_batches': 1, 'gradient_clip_val': None, 'gradient_clip_algorithm': None, 'deterministic': None, 'benchmark': None, 'inference_mode': True, 'use_distributed_sampler': False, 'profiler': None, 'detect_anomaly': False, 'barebones': False, 'plugins': None, 'sync_batchnorm': False, 'reload_dataloaders_every_n_epochs': 0, 'default_root_dir': None, 'model_registry': None, '__class__': <class 'lightning.pytorch.trainer.trainer.Trainer'>}
2025-07-23 13:26:09,764 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: trainer fit stage
2025-07-23 13:26:09,764 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_callbacks
2025-07-23 13:26:09,765 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: setting up strategy environment
2025-07-23 13:26:09,886 - lightning.pytorch.utilities.rank_zero - INFO - ----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 2 processes
----------------------------------------------------------------------------------------------------

2025-07-23 13:26:09,891 - lightning.pytorch.utilities.rank_zero - INFO - You are using a CUDA device ('NVIDIA GeForce RTX 3090 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
2025-07-23 13:26:10,307 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: preparing data
2025-07-23 13:26:10,356 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: preparing data
2025-07-23 13:26:13,286 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: setup
2025-07-23 13:26:13,286 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: setup
2025-07-23 13:26:16,215 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: setup
2025-07-23 13:26:30,960 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: setup
2025-07-23 13:26:31,771 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: setup
2025-07-23 13:26:31,772 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: setup
2025-07-23 13:26:33,331 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: configuring model
2025-07-23 13:26:33,331 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring module and callbacks from checkpoint path: None
2025-07-23 13:26:33,331 - lightning.pytorch.trainer.connectors.checkpoint_connector - DEBUG - `checkpoint_path` not specified. Skipping checkpoint loading.
2025-07-23 13:26:33,348 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: configuring model
2025-07-23 13:26:33,349 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring module and callbacks from checkpoint path: None
2025-07-23 13:26:33,349 - lightning.pytorch.trainer.connectors.checkpoint_connector - DEBUG - `checkpoint_path` not specified. Skipping checkpoint loading.
2025-07-23 13:26:33,649 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [2,7]
2025-07-23 13:26:33,650 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_optimizers
2025-07-23 13:26:33,652 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_fit_start
2025-07-23 13:26:33,653 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_fit_start
2025-07-23 13:26:33,653 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring training state
2025-07-23 13:26:33,664 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2,7]
2025-07-23 13:26:33,665 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_optimizers
2025-07-23 13:26:33,668 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_fit_start
2025-07-23 13:26:33,669 - lightning.pytorch.callbacks.model_summary - INFO - 
  | Name               | Type                                    | Params | Mode 
---------------------------------------------------------------------------------------
0 | gaussian_model     | VanillaGaussianModel                    | 124 M  | train
1 | renderer           | GSplatDistributedRendererImpl           | 0      | train
2 | density_controller | DistributedVanillaDensityControllerImpl | 0      | train
3 | metric             | HasInverseDepthMetricsModule            | 0      | train
---------------------------------------------------------------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
497.487   Total estimated model params size (MB)
6         Modules in train mode
0         Modules in eval mode
2025-07-23 13:26:33,669 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_fit_start
2025-07-23 13:26:33,671 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring training state
2025-07-23 13:26:33,672 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_sanity_check_start
2025-07-23 13:26:33,673 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_sanity_check_start
2025-07-23 13:26:33,674 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: val_dataloader
2025-07-23 13:26:33,675 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: val_dataloader
2025-07-23 13:26:33,730 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_model_eval
2025-07-23 13:26:33,730 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_start
2025-07-23 13:26:33,730 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_start
2025-07-23 13:26:33,730 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: on_validation_start
2025-07-23 13:26:33,730 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_epoch_start
2025-07-23 13:26:33,731 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_epoch_start
2025-07-23 13:26:33,731 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_model_eval
2025-07-23 13:26:33,732 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_start
2025-07-23 13:26:33,732 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_start
2025-07-23 13:26:33,732 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: on_validation_start
2025-07-23 13:26:33,732 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_epoch_start
2025-07-23 13:26:33,732 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_epoch_start
2025-07-23 13:26:34,621 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_before_batch_transfer
2025-07-23 13:26:34,622 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: batch_to_device
2025-07-23 13:26:34,622 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: transfer_batch_to_device
2025-07-23 13:26:34,629 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: on_after_batch_transfer
2025-07-23 13:26:34,629 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_batch_start
2025-07-23 13:26:34,631 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_batch_start
2025-07-23 13:26:34,632 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: validation_step
2025-07-23 13:26:34,641 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_before_batch_transfer
2025-07-23 13:26:34,642 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: batch_to_device
2025-07-23 13:26:34,642 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: transfer_batch_to_device
2025-07-23 13:26:34,648 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: on_after_batch_transfer
2025-07-23 13:26:34,648 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_batch_start
2025-07-23 13:26:34,649 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_batch_start
2025-07-23 13:26:34,649 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: validation_step
2025-07-23 13:31:58,407 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: Initializing trainer with parameters: {'self': <lightning.pytorch.trainer.trainer.Trainer object at 0x73bc56052150>, 'accelerator': 'gpu', 'strategy': <internal.mp_strategy.MPStrategy object at 0x73bc55e14aa0>, 'devices': -1, 'num_nodes': 1, 'precision': None, 'logger': <lightning.pytorch.loggers.wandb.WandbLogger object at 0x73bc563b3080>, 'callbacks': [<internal.entrypoints.gspl.LazyInstance_SaveGaussian object at 0x73be35bdcbf0>, <internal.entrypoints.gspl.LazyInstance_ValidateOnTrainEnd object at 0x73bc61b9c800>, <internal.entrypoints.gspl.LazyInstance_KeepRunningIfWebViewerEnabled object at 0x73bc564fa7b0>, <internal.entrypoints.gspl.LazyInstance_StopImageSavingThreads object at 0x73bc56329ac0>, <internal.entrypoints.gspl.LazyInstance_ProgressBar object at 0x73bc560a76e0>, <internal.entrypoints.gspl.LazyInstance_StopDataLoaderCacheThread object at 0x73bc564fa870>, <internal.callbacks.MySaveConfigCallback object at 0x73bc55dedfd0>], 'fast_dev_run': False, 'max_epochs': None, 'min_epochs': None, 'max_steps': 90000, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'overfit_batches': 0.0, 'val_check_interval': None, 'check_val_every_n_epoch': 999999, 'num_sanity_val_steps': 1, 'log_every_n_steps': None, 'enable_checkpointing': False, 'enable_progress_bar': None, 'enable_model_summary': None, 'accumulate_grad_batches': 1, 'gradient_clip_val': None, 'gradient_clip_algorithm': None, 'deterministic': None, 'benchmark': None, 'inference_mode': True, 'use_distributed_sampler': False, 'profiler': None, 'detect_anomaly': False, 'barebones': False, 'plugins': None, 'sync_batchnorm': False, 'reload_dataloaders_every_n_epochs': 0, 'default_root_dir': None, 'model_registry': None, '__class__': <class 'lightning.pytorch.trainer.trainer.Trainer'>}
2025-07-23 13:31:58,473 - lightning.pytorch.utilities.rank_zero - INFO - GPU available: True (cuda), used: True
2025-07-23 13:31:58,473 - lightning.pytorch.utilities.rank_zero - INFO - TPU available: False, using: 0 TPU cores
2025-07-23 13:31:58,473 - lightning.pytorch.utilities.rank_zero - INFO - HPU available: False, using: 0 HPUs
2025-07-23 13:31:58,549 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: trainer fit stage
2025-07-23 13:31:58,550 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_callbacks
2025-07-23 13:31:58,550 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: setting up strategy environment
2025-07-23 13:32:05,172 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: Initializing trainer with parameters: {'self': <lightning.pytorch.trainer.trainer.Trainer object at 0x7f3533832690>, 'accelerator': 'gpu', 'strategy': <internal.mp_strategy.MPStrategy object at 0x7f353384ed20>, 'devices': -1, 'num_nodes': 1, 'precision': None, 'logger': <lightning.pytorch.loggers.wandb.WandbLogger object at 0x7f353360b470>, 'callbacks': [<internal.entrypoints.gspl.LazyInstance_SaveGaussian object at 0x7f371340cd10>, <internal.entrypoints.gspl.LazyInstance_ValidateOnTrainEnd object at 0x7f3533c657f0>, <internal.entrypoints.gspl.LazyInstance_KeepRunningIfWebViewerEnabled object at 0x7f35338b3260>, <internal.entrypoints.gspl.LazyInstance_StopImageSavingThreads object at 0x7f3533953ef0>, <internal.entrypoints.gspl.LazyInstance_ProgressBar object at 0x7f3533923ad0>, <internal.entrypoints.gspl.LazyInstance_StopDataLoaderCacheThread object at 0x7f3533921430>, <internal.callbacks.MySaveConfigCallback object at 0x7f3532691b50>], 'fast_dev_run': False, 'max_epochs': None, 'min_epochs': None, 'max_steps': 90000, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'overfit_batches': 0.0, 'val_check_interval': None, 'check_val_every_n_epoch': 999999, 'num_sanity_val_steps': 1, 'log_every_n_steps': None, 'enable_checkpointing': False, 'enable_progress_bar': None, 'enable_model_summary': None, 'accumulate_grad_batches': 1, 'gradient_clip_val': None, 'gradient_clip_algorithm': None, 'deterministic': None, 'benchmark': None, 'inference_mode': True, 'use_distributed_sampler': False, 'profiler': None, 'detect_anomaly': False, 'barebones': False, 'plugins': None, 'sync_batchnorm': False, 'reload_dataloaders_every_n_epochs': 0, 'default_root_dir': None, 'model_registry': None, '__class__': <class 'lightning.pytorch.trainer.trainer.Trainer'>}
2025-07-23 13:32:05,252 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: trainer fit stage
2025-07-23 13:32:05,252 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_callbacks
2025-07-23 13:32:05,252 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: setting up strategy environment
2025-07-23 13:32:05,372 - lightning.pytorch.utilities.rank_zero - INFO - ----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 2 processes
----------------------------------------------------------------------------------------------------

2025-07-23 13:32:05,377 - lightning.pytorch.utilities.rank_zero - INFO - You are using a CUDA device ('NVIDIA GeForce RTX 3090 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
2025-07-23 13:32:05,992 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: preparing data
2025-07-23 13:32:06,030 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: preparing data
2025-07-23 13:32:08,741 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: setup
2025-07-23 13:32:08,741 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: setup
2025-07-23 13:32:11,364 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: setup
2025-07-23 13:32:24,971 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: setup
2025-07-23 13:32:26,110 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: setup
2025-07-23 13:32:26,110 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: setup
2025-07-23 13:32:27,603 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: configuring model
2025-07-23 13:32:27,604 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring module and callbacks from checkpoint path: None
2025-07-23 13:32:27,604 - lightning.pytorch.trainer.connectors.checkpoint_connector - DEBUG - `checkpoint_path` not specified. Skipping checkpoint loading.
2025-07-23 13:32:27,736 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: configuring model
2025-07-23 13:32:27,736 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring module and callbacks from checkpoint path: None
2025-07-23 13:32:27,736 - lightning.pytorch.trainer.connectors.checkpoint_connector - DEBUG - `checkpoint_path` not specified. Skipping checkpoint loading.
2025-07-23 13:32:27,933 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [2,7]
2025-07-23 13:32:27,934 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_optimizers
2025-07-23 13:32:27,937 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_fit_start
2025-07-23 13:32:27,937 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_fit_start
2025-07-23 13:32:27,938 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring training state
2025-07-23 13:32:28,086 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2,7]
2025-07-23 13:32:28,087 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_optimizers
2025-07-23 13:32:28,092 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_fit_start
2025-07-23 13:32:28,094 - lightning.pytorch.callbacks.model_summary - INFO - 
  | Name               | Type                                    | Params | Mode 
---------------------------------------------------------------------------------------
0 | gaussian_model     | VanillaGaussianModel                    | 124 M  | train
1 | renderer           | GSplatDistributedRendererImpl           | 0      | train
2 | density_controller | DistributedVanillaDensityControllerImpl | 0      | train
3 | metric             | HasInverseDepthMetricsModule            | 0      | train
---------------------------------------------------------------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
497.487   Total estimated model params size (MB)
6         Modules in train mode
0         Modules in eval mode
2025-07-23 13:32:28,094 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_fit_start
2025-07-23 13:32:28,096 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring training state
2025-07-23 13:32:28,098 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_sanity_check_start
2025-07-23 13:32:28,098 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_sanity_check_start
2025-07-23 13:32:28,100 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: val_dataloader
2025-07-23 13:32:28,101 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: val_dataloader
2025-07-23 13:32:28,189 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_model_eval
2025-07-23 13:32:28,190 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_start
2025-07-23 13:32:28,190 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_start
2025-07-23 13:32:28,190 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: on_validation_start
2025-07-23 13:32:28,190 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_epoch_start
2025-07-23 13:32:28,190 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_epoch_start
2025-07-23 13:32:28,195 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_model_eval
2025-07-23 13:32:28,196 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_start
2025-07-23 13:32:28,196 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_start
2025-07-23 13:32:28,196 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: on_validation_start
2025-07-23 13:32:28,196 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_epoch_start
2025-07-23 13:32:28,196 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_epoch_start
2025-07-23 13:32:29,351 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_before_batch_transfer
2025-07-23 13:32:29,352 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: batch_to_device
2025-07-23 13:32:29,352 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: transfer_batch_to_device
2025-07-23 13:32:29,358 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: on_after_batch_transfer
2025-07-23 13:32:29,361 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_batch_start
2025-07-23 13:32:29,365 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_batch_start
2025-07-23 13:32:29,365 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: validation_step
2025-07-23 13:32:29,535 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_before_batch_transfer
2025-07-23 13:32:29,535 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: batch_to_device
2025-07-23 13:32:29,536 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: transfer_batch_to_device
2025-07-23 13:32:29,540 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: on_after_batch_transfer
2025-07-23 13:32:29,541 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_batch_start
2025-07-23 13:32:29,541 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_batch_start
2025-07-23 13:32:29,541 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: validation_step
2025-07-23 13:35:48,204 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: Initializing trainer with parameters: {'self': <lightning.pytorch.trainer.trainer.Trainer object at 0x772c8b003800>, 'accelerator': 'gpu', 'strategy': <internal.mp_strategy.MPStrategy object at 0x772c8aeba090>, 'devices': -1, 'num_nodes': 1, 'precision': None, 'logger': <lightning.pytorch.loggers.wandb.WandbLogger object at 0x772c8ae20920>, 'callbacks': [<internal.entrypoints.gspl.LazyInstance_SaveGaussian object at 0x772e6ac30b00>, <internal.entrypoints.gspl.LazyInstance_ValidateOnTrainEnd object at 0x772c8b424800>, <internal.entrypoints.gspl.LazyInstance_KeepRunningIfWebViewerEnabled object at 0x772c8b4a76b0>, <internal.entrypoints.gspl.LazyInstance_StopImageSavingThreads object at 0x772c969fff20>, <internal.entrypoints.gspl.LazyInstance_ProgressBar object at 0x772c8af5bc20>, <internal.entrypoints.gspl.LazyInstance_StopDataLoaderCacheThread object at 0x772c96977800>, <internal.callbacks.MySaveConfigCallback object at 0x772c8ae5aa50>], 'fast_dev_run': False, 'max_epochs': None, 'min_epochs': None, 'max_steps': 90000, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'overfit_batches': 0.0, 'val_check_interval': None, 'check_val_every_n_epoch': 999999, 'num_sanity_val_steps': 1, 'log_every_n_steps': None, 'enable_checkpointing': False, 'enable_progress_bar': None, 'enable_model_summary': None, 'accumulate_grad_batches': 1, 'gradient_clip_val': None, 'gradient_clip_algorithm': None, 'deterministic': None, 'benchmark': None, 'inference_mode': True, 'use_distributed_sampler': False, 'profiler': None, 'detect_anomaly': False, 'barebones': False, 'plugins': None, 'sync_batchnorm': False, 'reload_dataloaders_every_n_epochs': 0, 'default_root_dir': None, 'model_registry': None, '__class__': <class 'lightning.pytorch.trainer.trainer.Trainer'>}
2025-07-23 13:35:48,273 - lightning.pytorch.utilities.rank_zero - INFO - GPU available: True (cuda), used: True
2025-07-23 13:35:48,273 - lightning.pytorch.utilities.rank_zero - INFO - TPU available: False, using: 0 TPU cores
2025-07-23 13:35:48,273 - lightning.pytorch.utilities.rank_zero - INFO - HPU available: False, using: 0 HPUs
2025-07-23 13:35:48,356 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: trainer fit stage
2025-07-23 13:35:48,357 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_callbacks
2025-07-23 13:35:48,357 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: setting up strategy environment
2025-07-23 13:35:55,929 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: Initializing trainer with parameters: {'self': <lightning.pytorch.trainer.trainer.Trainer object at 0x78aef1c09430>, 'accelerator': 'gpu', 'strategy': <internal.mp_strategy.MPStrategy object at 0x78aef19e3980>, 'devices': -1, 'num_nodes': 1, 'precision': None, 'logger': <lightning.pytorch.loggers.wandb.WandbLogger object at 0x78aef18f4d70>, 'callbacks': [<internal.entrypoints.gspl.LazyInstance_SaveGaussian object at 0x78b0d18315b0>, <internal.entrypoints.gspl.LazyInstance_ValidateOnTrainEnd object at 0x78aefd556300>, <internal.entrypoints.gspl.LazyInstance_KeepRunningIfWebViewerEnabled object at 0x78aef1dd76b0>, <internal.entrypoints.gspl.LazyInstance_StopImageSavingThreads object at 0x78aef1dd5c10>, <internal.entrypoints.gspl.LazyInstance_ProgressBar object at 0x78aef1e00b90>, <internal.entrypoints.gspl.LazyInstance_StopDataLoaderCacheThread object at 0x78aef1b33ad0>, <internal.callbacks.MySaveConfigCallback object at 0x78aef0b15190>], 'fast_dev_run': False, 'max_epochs': None, 'min_epochs': None, 'max_steps': 90000, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'overfit_batches': 0.0, 'val_check_interval': None, 'check_val_every_n_epoch': 999999, 'num_sanity_val_steps': 1, 'log_every_n_steps': None, 'enable_checkpointing': False, 'enable_progress_bar': None, 'enable_model_summary': None, 'accumulate_grad_batches': 1, 'gradient_clip_val': None, 'gradient_clip_algorithm': None, 'deterministic': None, 'benchmark': None, 'inference_mode': True, 'use_distributed_sampler': False, 'profiler': None, 'detect_anomaly': False, 'barebones': False, 'plugins': None, 'sync_batchnorm': False, 'reload_dataloaders_every_n_epochs': 0, 'default_root_dir': None, 'model_registry': None, '__class__': <class 'lightning.pytorch.trainer.trainer.Trainer'>}
2025-07-23 13:35:56,006 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: trainer fit stage
2025-07-23 13:35:56,007 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_callbacks
2025-07-23 13:35:56,007 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: setting up strategy environment
2025-07-23 13:35:56,104 - lightning.pytorch.utilities.rank_zero - INFO - ----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 2 processes
----------------------------------------------------------------------------------------------------

2025-07-23 13:35:56,109 - lightning.pytorch.utilities.rank_zero - INFO - You are using a CUDA device ('NVIDIA GeForce RTX 3090 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
2025-07-23 13:35:56,634 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: preparing data
2025-07-23 13:35:56,668 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: preparing data
2025-07-23 13:35:59,268 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: setup
2025-07-23 13:35:59,268 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: setup
2025-07-23 13:36:01,648 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: setup
2025-07-23 13:36:15,023 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: setup
2025-07-23 13:36:15,269 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: setup
2025-07-23 13:36:15,270 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: setup
2025-07-23 13:36:17,150 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: configuring model
2025-07-23 13:36:17,150 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring module and callbacks from checkpoint path: None
2025-07-23 13:36:17,150 - lightning.pytorch.trainer.connectors.checkpoint_connector - DEBUG - `checkpoint_path` not specified. Skipping checkpoint loading.
2025-07-23 13:36:17,184 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: configuring model
2025-07-23 13:36:17,185 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring module and callbacks from checkpoint path: None
2025-07-23 13:36:17,185 - lightning.pytorch.trainer.connectors.checkpoint_connector - DEBUG - `checkpoint_path` not specified. Skipping checkpoint loading.
2025-07-23 13:36:17,605 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [2,7]
2025-07-23 13:36:17,606 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_optimizers
2025-07-23 13:36:17,611 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_fit_start
2025-07-23 13:36:17,611 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_fit_start
2025-07-23 13:36:17,612 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring training state
2025-07-23 13:36:17,614 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2,7]
2025-07-23 13:36:17,615 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_optimizers
2025-07-23 13:36:17,620 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_fit_start
2025-07-23 13:36:17,621 - lightning.pytorch.callbacks.model_summary - INFO - 
  | Name               | Type                                    | Params | Mode 
---------------------------------------------------------------------------------------
0 | gaussian_model     | VanillaGaussianModel                    | 124 M  | train
1 | renderer           | GSplatDistributedRendererImpl           | 0      | train
2 | density_controller | DistributedVanillaDensityControllerImpl | 0      | train
3 | metric             | HasInverseDepthMetricsModule            | 0      | train
---------------------------------------------------------------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
497.487   Total estimated model params size (MB)
6         Modules in train mode
0         Modules in eval mode
2025-07-23 13:36:17,621 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_fit_start
2025-07-23 13:36:17,623 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring training state
2025-07-23 13:36:17,626 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_sanity_check_start
2025-07-23 13:36:17,626 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_sanity_check_start
2025-07-23 13:36:17,628 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: val_dataloader
2025-07-23 13:36:17,629 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: val_dataloader
2025-07-23 13:36:17,704 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_model_eval
2025-07-23 13:36:17,705 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_start
2025-07-23 13:36:17,705 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_start
2025-07-23 13:36:17,705 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: on_validation_start
2025-07-23 13:36:17,705 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_epoch_start
2025-07-23 13:36:17,705 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_epoch_start
2025-07-23 13:36:17,713 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_model_eval
2025-07-23 13:36:17,714 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_start
2025-07-23 13:36:17,714 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_start
2025-07-23 13:36:17,714 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: on_validation_start
2025-07-23 13:36:17,714 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_epoch_start
2025-07-23 13:36:17,714 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_epoch_start
2025-07-23 13:36:18,752 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_before_batch_transfer
2025-07-23 13:36:18,753 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: batch_to_device
2025-07-23 13:36:18,753 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: transfer_batch_to_device
2025-07-23 13:36:18,758 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: on_after_batch_transfer
2025-07-23 13:36:18,758 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_batch_start
2025-07-23 13:36:18,758 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_batch_start
2025-07-23 13:36:18,759 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: validation_step
2025-07-23 13:36:18,812 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_before_batch_transfer
2025-07-23 13:36:18,812 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: batch_to_device
2025-07-23 13:36:18,813 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: transfer_batch_to_device
2025-07-23 13:36:18,817 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: on_after_batch_transfer
2025-07-23 13:36:18,818 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_batch_start
2025-07-23 13:36:18,819 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_batch_start
2025-07-23 13:36:18,819 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: validation_step
2025-07-23 13:37:39,852 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: Initializing trainer with parameters: {'self': <lightning.pytorch.trainer.trainer.Trainer object at 0x7f5ac0fc6a80>, 'accelerator': 'gpu', 'strategy': <internal.mp_strategy.MPStrategy object at 0x7f5ac1042120>, 'devices': -1, 'num_nodes': 1, 'precision': None, 'logger': <lightning.pytorch.loggers.wandb.WandbLogger object at 0x7f5ac0cf0a40>, 'callbacks': [<internal.entrypoints.gspl.LazyInstance_SaveGaussian object at 0x7f5ca0bf4bf0>, <internal.entrypoints.gspl.LazyInstance_ValidateOnTrainEnd object at 0x7f5ac12bc320>, <internal.entrypoints.gspl.LazyInstance_KeepRunningIfWebViewerEnabled object at 0x7f5ac12ef5f0>, <internal.entrypoints.gspl.LazyInstance_StopImageSavingThreads object at 0x7f5ac12efda0>, <internal.entrypoints.gspl.LazyInstance_ProgressBar object at 0x7f5ac12bf9b0>, <internal.entrypoints.gspl.LazyInstance_StopDataLoaderCacheThread object at 0x7f5ac142e6c0>, <internal.callbacks.MySaveConfigCallback object at 0x7f5ac0e05d00>], 'fast_dev_run': False, 'max_epochs': None, 'min_epochs': None, 'max_steps': 90000, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'overfit_batches': 0.0, 'val_check_interval': None, 'check_val_every_n_epoch': 999999, 'num_sanity_val_steps': 1, 'log_every_n_steps': None, 'enable_checkpointing': False, 'enable_progress_bar': None, 'enable_model_summary': None, 'accumulate_grad_batches': 1, 'gradient_clip_val': None, 'gradient_clip_algorithm': None, 'deterministic': None, 'benchmark': None, 'inference_mode': True, 'use_distributed_sampler': False, 'profiler': None, 'detect_anomaly': False, 'barebones': False, 'plugins': None, 'sync_batchnorm': False, 'reload_dataloaders_every_n_epochs': 0, 'default_root_dir': None, 'model_registry': None, '__class__': <class 'lightning.pytorch.trainer.trainer.Trainer'>}
2025-07-23 13:37:39,919 - lightning.pytorch.utilities.rank_zero - INFO - GPU available: True (cuda), used: True
2025-07-23 13:37:39,920 - lightning.pytorch.utilities.rank_zero - INFO - TPU available: False, using: 0 TPU cores
2025-07-23 13:37:39,920 - lightning.pytorch.utilities.rank_zero - INFO - HPU available: False, using: 0 HPUs
2025-07-23 13:37:39,999 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: trainer fit stage
2025-07-23 13:37:40,000 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_callbacks
2025-07-23 13:37:40,000 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: setting up strategy environment
2025-07-23 13:37:45,833 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: Initializing trainer with parameters: {'self': <lightning.pytorch.trainer.trainer.Trainer object at 0x7c43f030b4d0>, 'accelerator': 'gpu', 'strategy': <internal.mp_strategy.MPStrategy object at 0x7c43efee3d40>, 'devices': -1, 'num_nodes': 1, 'precision': None, 'logger': <lightning.pytorch.loggers.wandb.WandbLogger object at 0x7c43efee25d0>, 'callbacks': [<internal.entrypoints.gspl.LazyInstance_SaveGaussian object at 0x7c43fba47ef0>, <internal.entrypoints.gspl.LazyInstance_ValidateOnTrainEnd object at 0x7c43f0341130>, <internal.entrypoints.gspl.LazyInstance_KeepRunningIfWebViewerEnabled object at 0x7c43fba47aa0>, <internal.entrypoints.gspl.LazyInstance_StopImageSavingThreads object at 0x7c43fd4b6ae0>, <internal.entrypoints.gspl.LazyInstance_ProgressBar object at 0x7c43f03a7fe0>, <internal.entrypoints.gspl.LazyInstance_StopDataLoaderCacheThread object at 0x7c43f065fc80>, <internal.callbacks.MySaveConfigCallback object at 0x7c43efee3fe0>], 'fast_dev_run': False, 'max_epochs': None, 'min_epochs': None, 'max_steps': 90000, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'overfit_batches': 0.0, 'val_check_interval': None, 'check_val_every_n_epoch': 999999, 'num_sanity_val_steps': 1, 'log_every_n_steps': None, 'enable_checkpointing': False, 'enable_progress_bar': None, 'enable_model_summary': None, 'accumulate_grad_batches': 1, 'gradient_clip_val': None, 'gradient_clip_algorithm': None, 'deterministic': None, 'benchmark': None, 'inference_mode': True, 'use_distributed_sampler': False, 'profiler': None, 'detect_anomaly': False, 'barebones': False, 'plugins': None, 'sync_batchnorm': False, 'reload_dataloaders_every_n_epochs': 0, 'default_root_dir': None, 'model_registry': None, '__class__': <class 'lightning.pytorch.trainer.trainer.Trainer'>}
2025-07-23 13:37:45,898 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: trainer fit stage
2025-07-23 13:37:45,898 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_callbacks
2025-07-23 13:37:45,898 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: setting up strategy environment
2025-07-23 13:37:45,970 - lightning.pytorch.utilities.rank_zero - INFO - ----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 2 processes
----------------------------------------------------------------------------------------------------

2025-07-23 13:37:45,974 - lightning.pytorch.utilities.rank_zero - INFO - You are using a CUDA device ('NVIDIA GeForce RTX 3090 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
2025-07-23 13:37:46,388 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: preparing data
2025-07-23 13:37:46,421 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: preparing data
2025-07-23 13:37:49,115 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: setup
2025-07-23 13:37:49,116 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: setup
2025-07-23 13:37:52,747 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: setup
2025-07-23 13:38:03,450 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: setup
2025-07-23 13:38:04,031 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: setup
2025-07-23 13:38:04,031 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: setup
2025-07-23 13:38:05,953 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: configuring model
2025-07-23 13:38:05,954 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring module and callbacks from checkpoint path: None
2025-07-23 13:38:05,954 - lightning.pytorch.trainer.connectors.checkpoint_connector - DEBUG - `checkpoint_path` not specified. Skipping checkpoint loading.
2025-07-23 13:38:05,983 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: configuring model
2025-07-23 13:38:05,983 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring module and callbacks from checkpoint path: None
2025-07-23 13:38:05,983 - lightning.pytorch.trainer.connectors.checkpoint_connector - DEBUG - `checkpoint_path` not specified. Skipping checkpoint loading.
2025-07-23 13:38:06,293 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [2,7]
2025-07-23 13:38:06,294 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_optimizers
2025-07-23 13:38:06,297 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_fit_start
2025-07-23 13:38:06,298 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_fit_start
2025-07-23 13:38:06,298 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring training state
2025-07-23 13:38:06,314 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2,7]
2025-07-23 13:38:06,316 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_optimizers
2025-07-23 13:38:06,319 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_fit_start
2025-07-23 13:38:06,319 - lightning.pytorch.callbacks.model_summary - INFO - 
  | Name               | Type                                    | Params | Mode 
---------------------------------------------------------------------------------------
0 | gaussian_model     | VanillaGaussianModel                    | 124 M  | train
1 | renderer           | GSplatDistributedRendererImpl           | 0      | train
2 | density_controller | DistributedVanillaDensityControllerImpl | 0      | train
3 | metric             | HasInverseDepthMetricsModule            | 0      | train
---------------------------------------------------------------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
497.487   Total estimated model params size (MB)
6         Modules in train mode
0         Modules in eval mode
2025-07-23 13:38:06,320 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_fit_start
2025-07-23 13:38:06,321 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring training state
2025-07-23 13:38:06,323 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_sanity_check_start
2025-07-23 13:38:06,323 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_sanity_check_start
2025-07-23 13:38:06,325 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: val_dataloader
2025-07-23 13:38:06,325 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: val_dataloader
2025-07-23 13:38:06,379 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_model_eval
2025-07-23 13:38:06,379 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_start
2025-07-23 13:38:06,379 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_start
2025-07-23 13:38:06,379 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: on_validation_start
2025-07-23 13:38:06,379 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_epoch_start
2025-07-23 13:38:06,379 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_epoch_start
2025-07-23 13:38:06,380 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_model_eval
2025-07-23 13:38:06,381 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_start
2025-07-23 13:38:06,381 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_start
2025-07-23 13:38:06,381 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: on_validation_start
2025-07-23 13:38:06,381 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_epoch_start
2025-07-23 13:38:06,381 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_epoch_start
2025-07-23 13:38:07,321 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_before_batch_transfer
2025-07-23 13:38:07,322 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: batch_to_device
2025-07-23 13:38:07,323 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: transfer_batch_to_device
2025-07-23 13:38:07,329 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: on_after_batch_transfer
2025-07-23 13:38:07,330 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_batch_start
2025-07-23 13:38:07,332 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_batch_start
2025-07-23 13:38:07,332 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_before_batch_transfer
2025-07-23 13:38:07,333 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: batch_to_device
2025-07-23 13:38:07,333 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: transfer_batch_to_device
2025-07-23 13:38:07,333 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: validation_step
2025-07-23 13:38:07,337 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: on_after_batch_transfer
2025-07-23 13:38:07,337 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_batch_start
2025-07-23 13:38:07,338 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_batch_start
2025-07-23 13:38:07,338 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: validation_step
2025-07-23 13:40:20,877 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: Initializing trainer with parameters: {'self': <lightning.pytorch.trainer.trainer.Trainer object at 0x7ae0aaeba210>, 'accelerator': 'gpu', 'strategy': <internal.mp_strategy.MPStrategy object at 0x7ae0aada5e50>, 'devices': -1, 'num_nodes': 1, 'precision': None, 'logger': <lightning.pytorch.loggers.wandb.WandbLogger object at 0x7ae0a9fc2840>, 'callbacks': [<internal.entrypoints.gspl.LazyInstance_SaveGaussian object at 0x7ae0b6dafef0>, <internal.entrypoints.gspl.LazyInstance_ValidateOnTrainEnd object at 0x7ae0ab12bad0>, <internal.entrypoints.gspl.LazyInstance_KeepRunningIfWebViewerEnabled object at 0x7ae0b6a1a3f0>, <internal.entrypoints.gspl.LazyInstance_StopImageSavingThreads object at 0x7ae0ab12a120>, <internal.entrypoints.gspl.LazyInstance_ProgressBar object at 0x7ae0b6daf440>, <internal.entrypoints.gspl.LazyInstance_StopDataLoaderCacheThread object at 0x7ae0b6f95700>, <internal.callbacks.MySaveConfigCallback object at 0x7ae0aaeb9ac0>], 'fast_dev_run': False, 'max_epochs': None, 'min_epochs': None, 'max_steps': 90000, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'overfit_batches': 0.0, 'val_check_interval': None, 'check_val_every_n_epoch': 999999, 'num_sanity_val_steps': 1, 'log_every_n_steps': None, 'enable_checkpointing': False, 'enable_progress_bar': None, 'enable_model_summary': None, 'accumulate_grad_batches': 1, 'gradient_clip_val': None, 'gradient_clip_algorithm': None, 'deterministic': None, 'benchmark': None, 'inference_mode': True, 'use_distributed_sampler': False, 'profiler': None, 'detect_anomaly': False, 'barebones': False, 'plugins': None, 'sync_batchnorm': False, 'reload_dataloaders_every_n_epochs': 0, 'default_root_dir': None, 'model_registry': None, '__class__': <class 'lightning.pytorch.trainer.trainer.Trainer'>}
2025-07-23 13:40:20,944 - lightning.pytorch.utilities.rank_zero - INFO - GPU available: True (cuda), used: True
2025-07-23 13:40:20,945 - lightning.pytorch.utilities.rank_zero - INFO - TPU available: False, using: 0 TPU cores
2025-07-23 13:40:20,945 - lightning.pytorch.utilities.rank_zero - INFO - HPU available: False, using: 0 HPUs
2025-07-23 13:40:21,041 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: trainer fit stage
2025-07-23 13:40:21,041 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_callbacks
2025-07-23 13:40:21,042 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: setting up strategy environment
2025-07-23 13:40:27,734 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: Initializing trainer with parameters: {'self': <lightning.pytorch.trainer.trainer.Trainer object at 0x7ade5fa79b50>, 'accelerator': 'gpu', 'strategy': <internal.mp_strategy.MPStrategy object at 0x7ade5f9f1d60>, 'devices': -1, 'num_nodes': 1, 'precision': None, 'logger': <lightning.pytorch.loggers.wandb.WandbLogger object at 0x7ade5fa1bc80>, 'callbacks': [<internal.entrypoints.gspl.LazyInstance_SaveGaussian object at 0x7ae03f814aa0>, <internal.entrypoints.gspl.LazyInstance_ValidateOnTrainEnd object at 0x7ade6b5b7d70>, <internal.entrypoints.gspl.LazyInstance_KeepRunningIfWebViewerEnabled object at 0x7ade60186270>, <internal.entrypoints.gspl.LazyInstance_StopImageSavingThreads object at 0x7ade6b9cfda0>, <internal.entrypoints.gspl.LazyInstance_ProgressBar object at 0x7ade601dc5f0>, <internal.entrypoints.gspl.LazyInstance_StopDataLoaderCacheThread object at 0x7ade6b566b40>, <internal.callbacks.MySaveConfigCallback object at 0x7ade5ebc5a00>], 'fast_dev_run': False, 'max_epochs': None, 'min_epochs': None, 'max_steps': 90000, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'overfit_batches': 0.0, 'val_check_interval': None, 'check_val_every_n_epoch': 999999, 'num_sanity_val_steps': 1, 'log_every_n_steps': None, 'enable_checkpointing': False, 'enable_progress_bar': None, 'enable_model_summary': None, 'accumulate_grad_batches': 1, 'gradient_clip_val': None, 'gradient_clip_algorithm': None, 'deterministic': None, 'benchmark': None, 'inference_mode': True, 'use_distributed_sampler': False, 'profiler': None, 'detect_anomaly': False, 'barebones': False, 'plugins': None, 'sync_batchnorm': False, 'reload_dataloaders_every_n_epochs': 0, 'default_root_dir': None, 'model_registry': None, '__class__': <class 'lightning.pytorch.trainer.trainer.Trainer'>}
2025-07-23 13:40:27,831 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: trainer fit stage
2025-07-23 13:40:27,832 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_callbacks
2025-07-23 13:40:27,832 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: setting up strategy environment
2025-07-23 13:40:27,925 - lightning.pytorch.utilities.rank_zero - INFO - ----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 2 processes
----------------------------------------------------------------------------------------------------

2025-07-23 13:40:27,931 - lightning.pytorch.utilities.rank_zero - INFO - You are using a CUDA device ('NVIDIA GeForce RTX 3090 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
2025-07-23 13:40:28,533 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: preparing data
2025-07-23 13:40:28,566 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: preparing data
2025-07-23 13:40:31,407 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: setup
2025-07-23 13:40:31,407 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: setup
2025-07-23 13:40:33,905 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: setup
2025-07-23 13:40:48,411 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: setup
2025-07-23 13:40:48,815 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: setup
2025-07-23 13:40:49,020 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: setup
2025-07-23 13:40:50,459 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: configuring model
2025-07-23 13:40:50,459 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring module and callbacks from checkpoint path: None
2025-07-23 13:40:50,459 - lightning.pytorch.trainer.connectors.checkpoint_connector - DEBUG - `checkpoint_path` not specified. Skipping checkpoint loading.
2025-07-23 13:40:50,592 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: configuring model
2025-07-23 13:40:50,593 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring module and callbacks from checkpoint path: None
2025-07-23 13:40:50,593 - lightning.pytorch.trainer.connectors.checkpoint_connector - DEBUG - `checkpoint_path` not specified. Skipping checkpoint loading.
2025-07-23 13:40:50,815 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [2,7]
2025-07-23 13:40:50,816 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_optimizers
2025-07-23 13:40:50,819 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_fit_start
2025-07-23 13:40:50,820 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_fit_start
2025-07-23 13:40:50,820 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring training state
2025-07-23 13:40:50,926 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2,7]
2025-07-23 13:40:50,928 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_optimizers
2025-07-23 13:40:50,931 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_fit_start
2025-07-23 13:40:50,932 - lightning.pytorch.callbacks.model_summary - INFO - 
  | Name               | Type                                    | Params | Mode 
---------------------------------------------------------------------------------------
0 | gaussian_model     | VanillaGaussianModel                    | 124 M  | train
1 | renderer           | GSplatDistributedRendererImpl           | 0      | train
2 | density_controller | DistributedVanillaDensityControllerImpl | 0      | train
3 | metric             | HasInverseDepthMetricsModule            | 0      | train
---------------------------------------------------------------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
497.487   Total estimated model params size (MB)
6         Modules in train mode
0         Modules in eval mode
2025-07-23 13:40:50,932 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_fit_start
2025-07-23 13:40:50,934 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring training state
2025-07-23 13:40:50,935 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_sanity_check_start
2025-07-23 13:40:50,935 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_sanity_check_start
2025-07-23 13:40:50,938 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: val_dataloader
2025-07-23 13:40:50,938 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: val_dataloader
2025-07-23 13:40:50,985 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_model_eval
2025-07-23 13:40:50,985 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_start
2025-07-23 13:40:50,985 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_start
2025-07-23 13:40:50,985 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: on_validation_start
2025-07-23 13:40:50,985 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_epoch_start
2025-07-23 13:40:50,985 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_epoch_start
2025-07-23 13:40:50,986 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_model_eval
2025-07-23 13:40:50,986 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_start
2025-07-23 13:40:50,986 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_start
2025-07-23 13:40:50,986 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: on_validation_start
2025-07-23 13:40:50,986 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_epoch_start
2025-07-23 13:40:50,987 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_epoch_start
2025-07-23 13:40:52,128 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_before_batch_transfer
2025-07-23 13:40:52,129 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: batch_to_device
2025-07-23 13:40:52,129 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: transfer_batch_to_device
2025-07-23 13:40:52,136 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: on_after_batch_transfer
2025-07-23 13:40:52,136 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_batch_start
2025-07-23 13:40:52,137 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_batch_start
2025-07-23 13:40:52,137 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: validation_step
2025-07-23 13:40:52,139 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_before_batch_transfer
2025-07-23 13:40:52,140 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: batch_to_device
2025-07-23 13:40:52,141 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: transfer_batch_to_device
2025-07-23 13:40:52,150 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: on_after_batch_transfer
2025-07-23 13:40:52,150 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_batch_start
2025-07-23 13:40:52,151 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_batch_start
2025-07-23 13:40:52,152 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: validation_step
2025-07-23 13:42:42,466 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: Initializing trainer with parameters: {'self': <lightning.pytorch.trainer.trainer.Trainer object at 0x7f275a832a50>, 'accelerator': 'gpu', 'strategy': <internal.mp_strategy.MPStrategy object at 0x7f275aa0b440>, 'devices': -1, 'num_nodes': 1, 'precision': None, 'logger': <lightning.pytorch.loggers.wandb.WandbLogger object at 0x7f275a823d40>, 'callbacks': [<internal.entrypoints.gspl.LazyInstance_SaveGaussian object at 0x7f293a638c20>, <internal.entrypoints.gspl.LazyInstance_ValidateOnTrainEnd object at 0x7f275a962f60>, <internal.entrypoints.gspl.LazyInstance_KeepRunningIfWebViewerEnabled object at 0x7f275ac2b2f0>, <internal.entrypoints.gspl.LazyInstance_StopImageSavingThreads object at 0x7f275a963e30>, <internal.entrypoints.gspl.LazyInstance_ProgressBar object at 0x7f275ae55b80>, <internal.entrypoints.gspl.LazyInstance_StopDataLoaderCacheThread object at 0x7f275ac86720>, <internal.callbacks.MySaveConfigCallback object at 0x7f2759abbf20>], 'fast_dev_run': False, 'max_epochs': None, 'min_epochs': None, 'max_steps': 90000, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'overfit_batches': 0.0, 'val_check_interval': None, 'check_val_every_n_epoch': 999999, 'num_sanity_val_steps': 1, 'log_every_n_steps': None, 'enable_checkpointing': False, 'enable_progress_bar': None, 'enable_model_summary': None, 'accumulate_grad_batches': 1, 'gradient_clip_val': None, 'gradient_clip_algorithm': None, 'deterministic': None, 'benchmark': None, 'inference_mode': True, 'use_distributed_sampler': False, 'profiler': None, 'detect_anomaly': False, 'barebones': False, 'plugins': None, 'sync_batchnorm': False, 'reload_dataloaders_every_n_epochs': 0, 'default_root_dir': None, 'model_registry': None, '__class__': <class 'lightning.pytorch.trainer.trainer.Trainer'>}
2025-07-23 13:42:42,556 - lightning.pytorch.utilities.rank_zero - INFO - GPU available: True (cuda), used: True
2025-07-23 13:42:42,556 - lightning.pytorch.utilities.rank_zero - INFO - TPU available: False, using: 0 TPU cores
2025-07-23 13:42:42,556 - lightning.pytorch.utilities.rank_zero - INFO - HPU available: False, using: 0 HPUs
2025-07-23 13:42:42,687 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: trainer fit stage
2025-07-23 13:42:42,688 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_callbacks
2025-07-23 13:42:42,688 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: setting up strategy environment
2025-07-23 13:42:49,664 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: Initializing trainer with parameters: {'self': <lightning.pytorch.trainer.trainer.Trainer object at 0x71507884e690>, 'accelerator': 'gpu', 'strategy': <internal.mp_strategy.MPStrategy object at 0x715078627140>, 'devices': -1, 'num_nodes': 1, 'precision': None, 'logger': <lightning.pytorch.loggers.wandb.WandbLogger object at 0x7150787fd850>, 'callbacks': [<internal.entrypoints.gspl.LazyInstance_SaveGaussian object at 0x715258408c80>, <internal.entrypoints.gspl.LazyInstance_ValidateOnTrainEnd object at 0x715078bc4800>, <internal.entrypoints.gspl.LazyInstance_KeepRunningIfWebViewerEnabled object at 0x715078d66270>, <internal.entrypoints.gspl.LazyInstance_StopImageSavingThreads object at 0x715084146ae0>, <internal.entrypoints.gspl.LazyInstance_ProgressBar object at 0x715078953fb0>, <internal.entrypoints.gspl.LazyInstance_StopDataLoaderCacheThread object at 0x715084189a30>, <internal.callbacks.MySaveConfigCallback object at 0x71507884e270>], 'fast_dev_run': False, 'max_epochs': None, 'min_epochs': None, 'max_steps': 90000, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'overfit_batches': 0.0, 'val_check_interval': None, 'check_val_every_n_epoch': 999999, 'num_sanity_val_steps': 1, 'log_every_n_steps': None, 'enable_checkpointing': False, 'enable_progress_bar': None, 'enable_model_summary': None, 'accumulate_grad_batches': 1, 'gradient_clip_val': None, 'gradient_clip_algorithm': None, 'deterministic': None, 'benchmark': None, 'inference_mode': True, 'use_distributed_sampler': False, 'profiler': None, 'detect_anomaly': False, 'barebones': False, 'plugins': None, 'sync_batchnorm': False, 'reload_dataloaders_every_n_epochs': 0, 'default_root_dir': None, 'model_registry': None, '__class__': <class 'lightning.pytorch.trainer.trainer.Trainer'>}
2025-07-23 13:42:49,756 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: trainer fit stage
2025-07-23 13:42:49,757 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_callbacks
2025-07-23 13:42:49,757 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: setting up strategy environment
2025-07-23 13:42:49,880 - lightning.pytorch.utilities.rank_zero - INFO - ----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 2 processes
----------------------------------------------------------------------------------------------------

2025-07-23 13:42:49,894 - lightning.pytorch.utilities.rank_zero - INFO - You are using a CUDA device ('NVIDIA GeForce RTX 3090 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
2025-07-23 13:42:50,524 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: preparing data
2025-07-23 13:42:50,581 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: preparing data
2025-07-23 13:42:53,297 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: setup
2025-07-23 13:42:53,297 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: setup
2025-07-23 13:42:55,603 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: setup
2025-07-23 13:43:07,228 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: setup
2025-07-23 13:43:07,751 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: setup
2025-07-23 13:43:07,751 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: setup
2025-07-23 13:43:09,340 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: configuring model
2025-07-23 13:43:09,340 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring module and callbacks from checkpoint path: None
2025-07-23 13:43:09,340 - lightning.pytorch.trainer.connectors.checkpoint_connector - DEBUG - `checkpoint_path` not specified. Skipping checkpoint loading.
2025-07-23 13:43:09,347 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: configuring model
2025-07-23 13:43:09,347 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring module and callbacks from checkpoint path: None
2025-07-23 13:43:09,347 - lightning.pytorch.trainer.connectors.checkpoint_connector - DEBUG - `checkpoint_path` not specified. Skipping checkpoint loading.
2025-07-23 13:43:09,657 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [2,7]
2025-07-23 13:43:09,658 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_optimizers
2025-07-23 13:43:09,661 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_fit_start
2025-07-23 13:43:09,662 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_fit_start
2025-07-23 13:43:09,662 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring training state
2025-07-23 13:43:09,672 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2,7]
2025-07-23 13:43:09,673 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_optimizers
2025-07-23 13:43:09,676 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_fit_start
2025-07-23 13:43:09,676 - lightning.pytorch.callbacks.model_summary - INFO - 
  | Name               | Type                                    | Params | Mode 
---------------------------------------------------------------------------------------
0 | gaussian_model     | VanillaGaussianModel                    | 124 M  | train
1 | renderer           | GSplatDistributedRendererImpl           | 0      | train
2 | density_controller | DistributedVanillaDensityControllerImpl | 0      | train
3 | metric             | HasInverseDepthMetricsModule            | 0      | train
---------------------------------------------------------------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
497.487   Total estimated model params size (MB)
6         Modules in train mode
0         Modules in eval mode
2025-07-23 13:43:09,676 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_fit_start
2025-07-23 13:43:09,678 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring training state
2025-07-23 13:43:09,679 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_sanity_check_start
2025-07-23 13:43:09,679 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_sanity_check_start
2025-07-23 13:43:09,681 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: val_dataloader
2025-07-23 13:43:09,681 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: val_dataloader
2025-07-23 13:43:09,725 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_model_eval
2025-07-23 13:43:09,725 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_start
2025-07-23 13:43:09,726 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_start
2025-07-23 13:43:09,726 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: on_validation_start
2025-07-23 13:43:09,726 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_epoch_start
2025-07-23 13:43:09,726 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_epoch_start
2025-07-23 13:43:09,727 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_model_eval
2025-07-23 13:43:09,727 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_start
2025-07-23 13:43:09,727 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_start
2025-07-23 13:43:09,727 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: on_validation_start
2025-07-23 13:43:09,727 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_epoch_start
2025-07-23 13:43:09,728 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_epoch_start
2025-07-23 13:43:10,643 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_before_batch_transfer
2025-07-23 13:43:10,643 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: batch_to_device
2025-07-23 13:43:10,644 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: transfer_batch_to_device
2025-07-23 13:43:10,647 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_before_batch_transfer
2025-07-23 13:43:10,648 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: batch_to_device
2025-07-23 13:43:10,648 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: transfer_batch_to_device
2025-07-23 13:43:10,654 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: on_after_batch_transfer
2025-07-23 13:43:10,655 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_batch_start
2025-07-23 13:43:10,655 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_batch_start
2025-07-23 13:43:10,656 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: validation_step
2025-07-23 13:43:10,656 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: on_after_batch_transfer
2025-07-23 13:43:10,657 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_batch_start
2025-07-23 13:43:10,658 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_batch_start
2025-07-23 13:43:10,659 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: validation_step
2025-07-23 13:46:08,766 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: Initializing trainer with parameters: {'self': <lightning.pytorch.trainer.trainer.Trainer object at 0x7ddfbde36c90>, 'accelerator': 'gpu', 'strategy': <internal.mp_strategy.MPStrategy object at 0x7ddfbdc09b80>, 'devices': -1, 'num_nodes': 1, 'precision': None, 'logger': <lightning.pytorch.loggers.wandb.WandbLogger object at 0x7ddfbde0d160>, 'callbacks': [<internal.entrypoints.gspl.LazyInstance_SaveGaussian object at 0x7de19da44bf0>, <internal.entrypoints.gspl.LazyInstance_ValidateOnTrainEnd object at 0x7ddfc9ebba70>, <internal.entrypoints.gspl.LazyInstance_KeepRunningIfWebViewerEnabled object at 0x7ddfc98366f0>, <internal.entrypoints.gspl.LazyInstance_StopImageSavingThreads object at 0x7ddfbe0ebf20>, <internal.entrypoints.gspl.LazyInstance_ProgressBar object at 0x7ddfbe02e690>, <internal.entrypoints.gspl.LazyInstance_StopDataLoaderCacheThread object at 0x7ddfbe00a0c0>, <internal.callbacks.MySaveConfigCallback object at 0x7ddfbde6b8c0>], 'fast_dev_run': False, 'max_epochs': None, 'min_epochs': None, 'max_steps': 90000, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'overfit_batches': 0.0, 'val_check_interval': None, 'check_val_every_n_epoch': 999999, 'num_sanity_val_steps': 1, 'log_every_n_steps': None, 'enable_checkpointing': False, 'enable_progress_bar': None, 'enable_model_summary': None, 'accumulate_grad_batches': 1, 'gradient_clip_val': None, 'gradient_clip_algorithm': None, 'deterministic': None, 'benchmark': None, 'inference_mode': True, 'use_distributed_sampler': False, 'profiler': None, 'detect_anomaly': False, 'barebones': False, 'plugins': None, 'sync_batchnorm': False, 'reload_dataloaders_every_n_epochs': 0, 'default_root_dir': None, 'model_registry': None, '__class__': <class 'lightning.pytorch.trainer.trainer.Trainer'>}
2025-07-23 13:46:08,852 - lightning.pytorch.utilities.rank_zero - INFO - GPU available: True (cuda), used: True
2025-07-23 13:46:08,853 - lightning.pytorch.utilities.rank_zero - INFO - TPU available: False, using: 0 TPU cores
2025-07-23 13:46:08,853 - lightning.pytorch.utilities.rank_zero - INFO - HPU available: False, using: 0 HPUs
2025-07-23 13:46:08,999 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: trainer fit stage
2025-07-23 13:46:09,000 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_callbacks
2025-07-23 13:46:09,000 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: setting up strategy environment
2025-07-23 13:46:15,484 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: Initializing trainer with parameters: {'self': <lightning.pytorch.trainer.trainer.Trainer object at 0x75be8daa3410>, 'accelerator': 'gpu', 'strategy': <internal.mp_strategy.MPStrategy object at 0x75be8d8c9340>, 'devices': -1, 'num_nodes': 1, 'precision': None, 'logger': <lightning.pytorch.loggers.wandb.WandbLogger object at 0x75be8d878bc0>, 'callbacks': [<internal.entrypoints.gspl.LazyInstance_SaveGaussian object at 0x75be99677ef0>, <internal.entrypoints.gspl.LazyInstance_ValidateOnTrainEnd object at 0x75be8dbc9130>, <internal.entrypoints.gspl.LazyInstance_KeepRunningIfWebViewerEnabled object at 0x75be996d78f0>, <internal.entrypoints.gspl.LazyInstance_StopImageSavingThreads object at 0x75be8dbf78c0>, <internal.entrypoints.gspl.LazyInstance_ProgressBar object at 0x75be8dbf7fb0>, <internal.entrypoints.gspl.LazyInstance_StopDataLoaderCacheThread object at 0x75be99947200>, <internal.callbacks.MySaveConfigCallback object at 0x75be8cac0590>], 'fast_dev_run': False, 'max_epochs': None, 'min_epochs': None, 'max_steps': 90000, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'overfit_batches': 0.0, 'val_check_interval': None, 'check_val_every_n_epoch': 999999, 'num_sanity_val_steps': 1, 'log_every_n_steps': None, 'enable_checkpointing': False, 'enable_progress_bar': None, 'enable_model_summary': None, 'accumulate_grad_batches': 1, 'gradient_clip_val': None, 'gradient_clip_algorithm': None, 'deterministic': None, 'benchmark': None, 'inference_mode': True, 'use_distributed_sampler': False, 'profiler': None, 'detect_anomaly': False, 'barebones': False, 'plugins': None, 'sync_batchnorm': False, 'reload_dataloaders_every_n_epochs': 0, 'default_root_dir': None, 'model_registry': None, '__class__': <class 'lightning.pytorch.trainer.trainer.Trainer'>}
2025-07-23 13:46:15,562 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: trainer fit stage
2025-07-23 13:46:15,562 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_callbacks
2025-07-23 13:46:15,562 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: setting up strategy environment
2025-07-23 13:46:15,604 - lightning.pytorch.utilities.rank_zero - INFO - ----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 2 processes
----------------------------------------------------------------------------------------------------

2025-07-23 13:46:15,611 - lightning.pytorch.utilities.rank_zero - INFO - You are using a CUDA device ('NVIDIA GeForce RTX 3090 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
2025-07-23 13:46:16,244 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: preparing data
2025-07-23 13:46:16,273 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: preparing data
2025-07-23 13:46:18,903 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: setup
2025-07-23 13:46:18,903 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: setup
2025-07-23 13:46:21,187 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: setup
2025-07-23 13:46:32,887 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: setup
2025-07-23 13:46:33,503 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: setup
2025-07-23 13:46:33,503 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: setup
2025-07-23 13:46:35,127 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: configuring model
2025-07-23 13:46:35,128 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring module and callbacks from checkpoint path: None
2025-07-23 13:46:35,128 - lightning.pytorch.trainer.connectors.checkpoint_connector - DEBUG - `checkpoint_path` not specified. Skipping checkpoint loading.
2025-07-23 13:46:35,159 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: configuring model
2025-07-23 13:46:35,160 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring module and callbacks from checkpoint path: None
2025-07-23 13:46:35,160 - lightning.pytorch.trainer.connectors.checkpoint_connector - DEBUG - `checkpoint_path` not specified. Skipping checkpoint loading.
2025-07-23 13:46:35,461 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [2,7]
2025-07-23 13:46:35,462 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_optimizers
2025-07-23 13:46:35,464 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_fit_start
2025-07-23 13:46:35,465 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_fit_start
2025-07-23 13:46:35,465 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring training state
2025-07-23 13:46:35,485 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2,7]
2025-07-23 13:46:35,486 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_optimizers
2025-07-23 13:46:35,489 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_fit_start
2025-07-23 13:46:35,489 - lightning.pytorch.callbacks.model_summary - INFO - 
  | Name               | Type                                    | Params | Mode 
---------------------------------------------------------------------------------------
0 | gaussian_model     | VanillaGaussianModel                    | 124 M  | train
1 | renderer           | GSplatDistributedRendererImpl           | 0      | train
2 | density_controller | DistributedVanillaDensityControllerImpl | 0      | train
3 | metric             | HasInverseDepthMetricsModule            | 0      | train
---------------------------------------------------------------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
497.487   Total estimated model params size (MB)
6         Modules in train mode
0         Modules in eval mode
2025-07-23 13:46:35,489 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_fit_start
2025-07-23 13:46:35,491 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring training state
2025-07-23 13:46:35,492 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_sanity_check_start
2025-07-23 13:46:35,492 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_sanity_check_start
2025-07-23 13:46:35,494 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: val_dataloader
2025-07-23 13:46:35,494 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: val_dataloader
2025-07-23 13:46:35,539 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_model_eval
2025-07-23 13:46:35,539 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_start
2025-07-23 13:46:35,539 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_start
2025-07-23 13:46:35,540 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: on_validation_start
2025-07-23 13:46:35,540 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_epoch_start
2025-07-23 13:46:35,539 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_model_eval
2025-07-23 13:46:35,540 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_epoch_start
2025-07-23 13:46:35,540 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_start
2025-07-23 13:46:35,540 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_start
2025-07-23 13:46:35,540 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: on_validation_start
2025-07-23 13:46:35,540 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_epoch_start
2025-07-23 13:46:35,540 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_epoch_start
2025-07-23 13:46:36,374 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_before_batch_transfer
2025-07-23 13:46:36,375 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: batch_to_device
2025-07-23 13:46:36,375 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: transfer_batch_to_device
2025-07-23 13:46:36,380 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: on_after_batch_transfer
2025-07-23 13:46:36,381 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_before_batch_transfer
2025-07-23 13:46:36,381 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: batch_to_device
2025-07-23 13:46:36,381 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_batch_start
2025-07-23 13:46:36,381 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: transfer_batch_to_device
2025-07-23 13:46:36,383 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_batch_start
2025-07-23 13:46:36,383 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: validation_step
2025-07-23 13:46:36,385 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: on_after_batch_transfer
2025-07-23 13:46:36,385 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_batch_start
2025-07-23 13:46:36,385 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_batch_start
2025-07-23 13:46:36,386 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: validation_step
2025-07-23 13:47:43,714 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: Initializing trainer with parameters: {'self': <lightning.pytorch.trainer.trainer.Trainer object at 0x7789228c5010>, 'accelerator': 'gpu', 'strategy': <internal.mp_strategy.MPStrategy object at 0x7789226ecc20>, 'devices': -1, 'num_nodes': 1, 'precision': None, 'logger': <lightning.pytorch.loggers.wandb.WandbLogger object at 0x7789228c73b0>, 'callbacks': [<internal.entrypoints.gspl.LazyInstance_SaveGaussian object at 0x778b0249cbf0>, <internal.entrypoints.gspl.LazyInstance_ValidateOnTrainEnd object at 0x778922c91220>, <internal.entrypoints.gspl.LazyInstance_KeepRunningIfWebViewerEnabled object at 0x77892e2366f0>, <internal.entrypoints.gspl.LazyInstance_StopImageSavingThreads object at 0x77892fc8fce0>, <internal.entrypoints.gspl.LazyInstance_ProgressBar object at 0x778922ba7ef0>, <internal.entrypoints.gspl.LazyInstance_StopDataLoaderCacheThread object at 0x778922d12870>, <internal.callbacks.MySaveConfigCallback object at 0x7789226c3740>], 'fast_dev_run': False, 'max_epochs': None, 'min_epochs': None, 'max_steps': 90000, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'overfit_batches': 0.0, 'val_check_interval': None, 'check_val_every_n_epoch': 999999, 'num_sanity_val_steps': 1, 'log_every_n_steps': None, 'enable_checkpointing': False, 'enable_progress_bar': None, 'enable_model_summary': None, 'accumulate_grad_batches': 1, 'gradient_clip_val': None, 'gradient_clip_algorithm': None, 'deterministic': None, 'benchmark': None, 'inference_mode': True, 'use_distributed_sampler': False, 'profiler': None, 'detect_anomaly': False, 'barebones': False, 'plugins': None, 'sync_batchnorm': False, 'reload_dataloaders_every_n_epochs': 0, 'default_root_dir': None, 'model_registry': None, '__class__': <class 'lightning.pytorch.trainer.trainer.Trainer'>}
2025-07-23 13:47:43,790 - lightning.pytorch.utilities.rank_zero - INFO - GPU available: True (cuda), used: True
2025-07-23 13:47:43,791 - lightning.pytorch.utilities.rank_zero - INFO - TPU available: False, using: 0 TPU cores
2025-07-23 13:47:43,791 - lightning.pytorch.utilities.rank_zero - INFO - HPU available: False, using: 0 HPUs
2025-07-23 13:47:43,879 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: trainer fit stage
2025-07-23 13:47:43,879 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_callbacks
2025-07-23 13:47:43,880 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: setting up strategy environment
2025-07-23 13:47:50,250 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: Initializing trainer with parameters: {'self': <lightning.pytorch.trainer.trainer.Trainer object at 0x77974040ccb0>, 'accelerator': 'gpu', 'strategy': <internal.mp_strategy.MPStrategy object at 0x7797404295b0>, 'devices': -1, 'num_nodes': 1, 'precision': None, 'logger': <lightning.pytorch.loggers.wandb.WandbLogger object at 0x7797403e5460>, 'callbacks': [<internal.entrypoints.gspl.LazyInstance_SaveGaussian object at 0x7799201f8c50>, <internal.entrypoints.gspl.LazyInstance_ValidateOnTrainEnd object at 0x7797408f3020>, <internal.entrypoints.gspl.LazyInstance_KeepRunningIfWebViewerEnabled object at 0x7797409dc530>, <internal.entrypoints.gspl.LazyInstance_StopImageSavingThreads object at 0x779740a7f7a0>, <internal.entrypoints.gspl.LazyInstance_ProgressBar object at 0x77974c19c710>, <internal.entrypoints.gspl.LazyInstance_StopDataLoaderCacheThread object at 0x779740aa9430>, <internal.callbacks.MySaveConfigCallback object at 0x7797403bf2f0>], 'fast_dev_run': False, 'max_epochs': None, 'min_epochs': None, 'max_steps': 90000, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'overfit_batches': 0.0, 'val_check_interval': None, 'check_val_every_n_epoch': 999999, 'num_sanity_val_steps': 1, 'log_every_n_steps': None, 'enable_checkpointing': False, 'enable_progress_bar': None, 'enable_model_summary': None, 'accumulate_grad_batches': 1, 'gradient_clip_val': None, 'gradient_clip_algorithm': None, 'deterministic': None, 'benchmark': None, 'inference_mode': True, 'use_distributed_sampler': False, 'profiler': None, 'detect_anomaly': False, 'barebones': False, 'plugins': None, 'sync_batchnorm': False, 'reload_dataloaders_every_n_epochs': 0, 'default_root_dir': None, 'model_registry': None, '__class__': <class 'lightning.pytorch.trainer.trainer.Trainer'>}
2025-07-23 13:47:50,324 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: trainer fit stage
2025-07-23 13:47:50,324 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_callbacks
2025-07-23 13:47:50,325 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: setting up strategy environment
2025-07-23 13:47:50,428 - lightning.pytorch.utilities.rank_zero - INFO - ----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 2 processes
----------------------------------------------------------------------------------------------------

2025-07-23 13:47:50,434 - lightning.pytorch.utilities.rank_zero - INFO - You are using a CUDA device ('NVIDIA GeForce RTX 3090 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
2025-07-23 13:47:50,954 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: preparing data
2025-07-23 13:47:50,987 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: preparing data
2025-07-23 13:47:53,526 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: setup
2025-07-23 13:47:53,526 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: setup
2025-07-23 13:47:56,480 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: setup
2025-07-23 13:48:07,557 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: setup
2025-07-23 13:48:08,123 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: setup
2025-07-23 13:48:08,123 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: setup
2025-07-23 13:48:09,655 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: configuring model
2025-07-23 13:48:09,655 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring module and callbacks from checkpoint path: None
2025-07-23 13:48:09,655 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: configuring model
2025-07-23 13:48:09,655 - lightning.pytorch.trainer.connectors.checkpoint_connector - DEBUG - `checkpoint_path` not specified. Skipping checkpoint loading.
2025-07-23 13:48:09,655 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring module and callbacks from checkpoint path: None
2025-07-23 13:48:09,655 - lightning.pytorch.trainer.connectors.checkpoint_connector - DEBUG - `checkpoint_path` not specified. Skipping checkpoint loading.
2025-07-23 13:48:09,918 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2,7]
2025-07-23 13:48:09,919 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_optimizers
2025-07-23 13:48:09,922 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_fit_start
2025-07-23 13:48:09,922 - lightning.pytorch.callbacks.model_summary - INFO - 
  | Name               | Type                                    | Params | Mode 
---------------------------------------------------------------------------------------
0 | gaussian_model     | VanillaGaussianModel                    | 124 M  | train
1 | renderer           | GSplatDistributedRendererImpl           | 0      | train
2 | density_controller | DistributedVanillaDensityControllerImpl | 0      | train
3 | metric             | HasInverseDepthMetricsModule            | 0      | train
---------------------------------------------------------------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
497.487   Total estimated model params size (MB)
6         Modules in train mode
0         Modules in eval mode
2025-07-23 13:48:09,923 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_fit_start
2025-07-23 13:48:09,925 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring training state
2025-07-23 13:48:10,009 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [2,7]
2025-07-23 13:48:10,009 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_optimizers
2025-07-23 13:48:10,012 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_fit_start
2025-07-23 13:48:10,012 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_fit_start
2025-07-23 13:48:10,013 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring training state
2025-07-23 13:48:10,014 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_sanity_check_start
2025-07-23 13:48:10,014 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_sanity_check_start
2025-07-23 13:48:10,016 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: val_dataloader
2025-07-23 13:48:10,016 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: val_dataloader
2025-07-23 13:48:10,062 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_model_eval
2025-07-23 13:48:10,062 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_start
2025-07-23 13:48:10,062 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_start
2025-07-23 13:48:10,062 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: on_validation_start
2025-07-23 13:48:10,063 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_epoch_start
2025-07-23 13:48:10,063 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_model_eval
2025-07-23 13:48:10,063 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_epoch_start
2025-07-23 13:48:10,063 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_start
2025-07-23 13:48:10,063 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_start
2025-07-23 13:48:10,063 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: on_validation_start
2025-07-23 13:48:10,063 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_epoch_start
2025-07-23 13:48:10,063 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_epoch_start
2025-07-23 13:48:10,900 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_before_batch_transfer
2025-07-23 13:48:10,900 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: batch_to_device
2025-07-23 13:48:10,901 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: transfer_batch_to_device
2025-07-23 13:48:10,905 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: on_after_batch_transfer
2025-07-23 13:48:10,905 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_batch_start
2025-07-23 13:48:10,907 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_batch_start
2025-07-23 13:48:10,907 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: validation_step
2025-07-23 13:48:10,926 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_before_batch_transfer
2025-07-23 13:48:10,926 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: batch_to_device
2025-07-23 13:48:10,927 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: transfer_batch_to_device
2025-07-23 13:48:10,931 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: on_after_batch_transfer
2025-07-23 13:48:10,931 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_batch_start
2025-07-23 13:48:10,931 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_batch_start
2025-07-23 13:48:10,932 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: validation_step
2025-07-23 13:51:56,666 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: Initializing trainer with parameters: {'self': <lightning.pytorch.trainer.trainer.Trainer object at 0x721d64b7db20>, 'accelerator': 'gpu', 'strategy': <internal.mp_strategy.MPStrategy object at 0x721d658c8320>, 'devices': -1, 'num_nodes': 1, 'precision': None, 'logger': <lightning.pytorch.loggers.wandb.WandbLogger object at 0x721d658c9d90>, 'callbacks': [<internal.entrypoints.gspl.LazyInstance_SaveGaussian object at 0x721f4570cbf0>, <internal.entrypoints.gspl.LazyInstance_ValidateOnTrainEnd object at 0x721d65daac90>, <internal.entrypoints.gspl.LazyInstance_KeepRunningIfWebViewerEnabled object at 0x721d7149e570>, <internal.entrypoints.gspl.LazyInstance_StopImageSavingThreads object at 0x721d65ddeae0>, <internal.entrypoints.gspl.LazyInstance_ProgressBar object at 0x721d65dabb30>, <internal.entrypoints.gspl.LazyInstance_StopDataLoaderCacheThread object at 0x721d65ee5ac0>, <internal.callbacks.MySaveConfigCallback object at 0x721d658a0380>], 'fast_dev_run': False, 'max_epochs': None, 'min_epochs': None, 'max_steps': 90000, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'overfit_batches': 0.0, 'val_check_interval': None, 'check_val_every_n_epoch': 999999, 'num_sanity_val_steps': 1, 'log_every_n_steps': None, 'enable_checkpointing': False, 'enable_progress_bar': None, 'enable_model_summary': None, 'accumulate_grad_batches': 1, 'gradient_clip_val': None, 'gradient_clip_algorithm': None, 'deterministic': None, 'benchmark': None, 'inference_mode': True, 'use_distributed_sampler': False, 'profiler': None, 'detect_anomaly': False, 'barebones': False, 'plugins': None, 'sync_batchnorm': False, 'reload_dataloaders_every_n_epochs': 0, 'default_root_dir': None, 'model_registry': None, '__class__': <class 'lightning.pytorch.trainer.trainer.Trainer'>}
2025-07-23 13:51:56,731 - lightning.pytorch.utilities.rank_zero - INFO - GPU available: True (cuda), used: True
2025-07-23 13:51:56,732 - lightning.pytorch.utilities.rank_zero - INFO - TPU available: False, using: 0 TPU cores
2025-07-23 13:51:56,732 - lightning.pytorch.utilities.rank_zero - INFO - HPU available: False, using: 0 HPUs
2025-07-23 13:51:56,810 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: trainer fit stage
2025-07-23 13:51:56,810 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_callbacks
2025-07-23 13:51:56,811 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: setting up strategy environment
2025-07-23 13:52:02,411 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: Initializing trainer with parameters: {'self': <lightning.pytorch.trainer.trainer.Trainer object at 0x7ef140096c90>, 'accelerator': 'gpu', 'strategy': <internal.mp_strategy.MPStrategy object at 0x7ef140096f90>, 'devices': -1, 'num_nodes': 1, 'precision': None, 'logger': <lightning.pytorch.loggers.wandb.WandbLogger object at 0x7ef1400185f0>, 'callbacks': [<internal.entrypoints.gspl.LazyInstance_SaveGaussian object at 0x7ef31ff4cd10>, <internal.entrypoints.gspl.LazyInstance_ValidateOnTrainEnd object at 0x7ef1406e2300>, <internal.entrypoints.gspl.LazyInstance_KeepRunningIfWebViewerEnabled object at 0x7ef140691220>, <internal.entrypoints.gspl.LazyInstance_StopImageSavingThreads object at 0x7ef1407a07a0>, <internal.entrypoints.gspl.LazyInstance_ProgressBar object at 0x7ef1405a7d40>, <internal.entrypoints.gspl.LazyInstance_StopDataLoaderCacheThread object at 0x7ef14bdc2600>, <internal.callbacks.MySaveConfigCallback object at 0x7ef140095190>], 'fast_dev_run': False, 'max_epochs': None, 'min_epochs': None, 'max_steps': 90000, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'overfit_batches': 0.0, 'val_check_interval': None, 'check_val_every_n_epoch': 999999, 'num_sanity_val_steps': 1, 'log_every_n_steps': None, 'enable_checkpointing': False, 'enable_progress_bar': None, 'enable_model_summary': None, 'accumulate_grad_batches': 1, 'gradient_clip_val': None, 'gradient_clip_algorithm': None, 'deterministic': None, 'benchmark': None, 'inference_mode': True, 'use_distributed_sampler': False, 'profiler': None, 'detect_anomaly': False, 'barebones': False, 'plugins': None, 'sync_batchnorm': False, 'reload_dataloaders_every_n_epochs': 0, 'default_root_dir': None, 'model_registry': None, '__class__': <class 'lightning.pytorch.trainer.trainer.Trainer'>}
2025-07-23 13:52:02,476 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: trainer fit stage
2025-07-23 13:52:02,476 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_callbacks
2025-07-23 13:52:02,477 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: setting up strategy environment
2025-07-23 13:52:02,592 - lightning.pytorch.utilities.rank_zero - INFO - ----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 2 processes
----------------------------------------------------------------------------------------------------

2025-07-23 13:52:02,597 - lightning.pytorch.utilities.rank_zero - INFO - You are using a CUDA device ('NVIDIA GeForce RTX 3090 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
2025-07-23 13:52:03,013 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: preparing data
2025-07-23 13:52:03,071 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: preparing data
2025-07-23 13:52:05,785 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: setup
2025-07-23 13:52:05,785 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: setup
2025-07-23 13:52:08,180 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: setup
2025-07-23 13:52:23,278 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: setup
2025-07-23 13:52:23,898 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: setup
2025-07-23 13:52:23,899 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: setup
2025-07-23 13:52:25,715 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: configuring model
2025-07-23 13:52:25,715 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring module and callbacks from checkpoint path: None
2025-07-23 13:52:25,716 - lightning.pytorch.trainer.connectors.checkpoint_connector - DEBUG - `checkpoint_path` not specified. Skipping checkpoint loading.
2025-07-23 13:52:25,743 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: configuring model
2025-07-23 13:52:25,743 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring module and callbacks from checkpoint path: None
2025-07-23 13:52:25,744 - lightning.pytorch.trainer.connectors.checkpoint_connector - DEBUG - `checkpoint_path` not specified. Skipping checkpoint loading.
2025-07-23 13:52:26,147 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [2,7]
2025-07-23 13:52:26,149 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_optimizers
2025-07-23 13:52:26,156 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_fit_start
2025-07-23 13:52:26,158 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_fit_start
2025-07-23 13:52:26,159 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring training state
2025-07-23 13:52:26,171 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2,7]
2025-07-23 13:52:26,173 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_optimizers
2025-07-23 13:52:26,177 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_fit_start
2025-07-23 13:52:26,178 - lightning.pytorch.callbacks.model_summary - INFO - 
  | Name               | Type                                    | Params | Mode 
---------------------------------------------------------------------------------------
0 | gaussian_model     | VanillaGaussianModel                    | 124 M  | train
1 | renderer           | GSplatDistributedRendererImpl           | 0      | train
2 | density_controller | DistributedVanillaDensityControllerImpl | 0      | train
3 | metric             | HasInverseDepthMetricsModule            | 0      | train
---------------------------------------------------------------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
497.487   Total estimated model params size (MB)
6         Modules in train mode
0         Modules in eval mode
2025-07-23 13:52:26,178 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_fit_start
2025-07-23 13:52:26,181 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring training state
2025-07-23 13:52:26,182 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_sanity_check_start
2025-07-23 13:52:26,183 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_sanity_check_start
2025-07-23 13:52:26,184 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: val_dataloader
2025-07-23 13:52:26,185 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: val_dataloader
2025-07-23 13:52:26,254 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_model_eval
2025-07-23 13:52:26,254 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_start
2025-07-23 13:52:26,255 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_start
2025-07-23 13:52:26,255 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: on_validation_start
2025-07-23 13:52:26,255 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_epoch_start
2025-07-23 13:52:26,255 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_epoch_start
2025-07-23 13:52:26,264 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_model_eval
2025-07-23 13:52:26,264 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_start
2025-07-23 13:52:26,264 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_start
2025-07-23 13:52:26,264 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: on_validation_start
2025-07-23 13:52:26,264 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_epoch_start
2025-07-23 13:52:26,264 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_epoch_start
2025-07-23 13:52:27,426 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_before_batch_transfer
2025-07-23 13:52:27,426 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_before_batch_transfer
2025-07-23 13:52:27,427 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: batch_to_device
2025-07-23 13:52:27,427 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: batch_to_device
2025-07-23 13:52:27,427 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: transfer_batch_to_device
2025-07-23 13:52:27,428 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: transfer_batch_to_device
2025-07-23 13:52:27,432 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: on_after_batch_transfer
2025-07-23 13:52:27,433 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_batch_start
2025-07-23 13:52:27,433 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: on_after_batch_transfer
2025-07-23 13:52:27,434 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_batch_start
2025-07-23 13:52:27,434 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_batch_start
2025-07-23 13:52:27,434 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_batch_start
2025-07-23 13:52:27,434 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: validation_step
2025-07-23 13:52:27,434 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: validation_step
2025-07-23 13:53:00,346 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: Initializing trainer with parameters: {'self': <lightning.pytorch.trainer.trainer.Trainer object at 0x70d7dc930f50>, 'accelerator': 'gpu', 'strategy': <internal.mp_strategy.MPStrategy object at 0x70d7dd935850>, 'devices': -1, 'num_nodes': 1, 'precision': None, 'logger': <lightning.pytorch.loggers.wandb.WandbLogger object at 0x70d7dd8cb2f0>, 'callbacks': [<internal.entrypoints.gspl.LazyInstance_SaveGaussian object at 0x70d9bd7b4bf0>, <internal.entrypoints.gspl.LazyInstance_ValidateOnTrainEnd object at 0x70d7ddfa8da0>, <internal.entrypoints.gspl.LazyInstance_KeepRunningIfWebViewerEnabled object at 0x70d7dde12750>, <internal.entrypoints.gspl.LazyInstance_StopImageSavingThreads object at 0x70d7ddf66060>, <internal.entrypoints.gspl.LazyInstance_ProgressBar object at 0x70d7ddd17890>, <internal.entrypoints.gspl.LazyInstance_StopDataLoaderCacheThread object at 0x70d7e94fa870>, <internal.callbacks.MySaveConfigCallback object at 0x70d7dd8c8cb0>], 'fast_dev_run': False, 'max_epochs': None, 'min_epochs': None, 'max_steps': 90000, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'overfit_batches': 0.0, 'val_check_interval': None, 'check_val_every_n_epoch': 999999, 'num_sanity_val_steps': 1, 'log_every_n_steps': None, 'enable_checkpointing': False, 'enable_progress_bar': None, 'enable_model_summary': None, 'accumulate_grad_batches': 1, 'gradient_clip_val': None, 'gradient_clip_algorithm': None, 'deterministic': None, 'benchmark': None, 'inference_mode': True, 'use_distributed_sampler': False, 'profiler': None, 'detect_anomaly': False, 'barebones': False, 'plugins': None, 'sync_batchnorm': False, 'reload_dataloaders_every_n_epochs': 0, 'default_root_dir': None, 'model_registry': None, '__class__': <class 'lightning.pytorch.trainer.trainer.Trainer'>}
2025-07-23 13:53:00,413 - lightning.pytorch.utilities.rank_zero - INFO - GPU available: True (cuda), used: True
2025-07-23 13:53:00,414 - lightning.pytorch.utilities.rank_zero - INFO - TPU available: False, using: 0 TPU cores
2025-07-23 13:53:00,414 - lightning.pytorch.utilities.rank_zero - INFO - HPU available: False, using: 0 HPUs
2025-07-23 13:53:00,491 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: trainer fit stage
2025-07-23 13:53:00,491 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_callbacks
2025-07-23 13:53:00,492 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: setting up strategy environment
2025-07-23 13:53:07,492 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: Initializing trainer with parameters: {'self': <lightning.pytorch.trainer.trainer.Trainer object at 0x7696d869faa0>, 'accelerator': 'gpu', 'strategy': <internal.mp_strategy.MPStrategy object at 0x7696d869d0a0>, 'devices': -1, 'num_nodes': 1, 'precision': None, 'logger': <lightning.pytorch.loggers.wandb.WandbLogger object at 0x7696d869eae0>, 'callbacks': [<internal.entrypoints.gspl.LazyInstance_SaveGaussian object at 0x7698b84ccb90>, <internal.entrypoints.gspl.LazyInstance_ValidateOnTrainEnd object at 0x7696d8e32300>, <internal.entrypoints.gspl.LazyInstance_KeepRunningIfWebViewerEnabled object at 0x7696d8c11220>, <internal.entrypoints.gspl.LazyInstance_StopImageSavingThreads object at 0x7696d8b803e0>, <internal.entrypoints.gspl.LazyInstance_ProgressBar object at 0x7696d8babfb0>, <internal.entrypoints.gspl.LazyInstance_StopDataLoaderCacheThread object at 0x7696d8e32240>, <internal.callbacks.MySaveConfigCallback object at 0x7696d86cc4d0>], 'fast_dev_run': False, 'max_epochs': None, 'min_epochs': None, 'max_steps': 90000, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'overfit_batches': 0.0, 'val_check_interval': None, 'check_val_every_n_epoch': 999999, 'num_sanity_val_steps': 1, 'log_every_n_steps': None, 'enable_checkpointing': False, 'enable_progress_bar': None, 'enable_model_summary': None, 'accumulate_grad_batches': 1, 'gradient_clip_val': None, 'gradient_clip_algorithm': None, 'deterministic': None, 'benchmark': None, 'inference_mode': True, 'use_distributed_sampler': False, 'profiler': None, 'detect_anomaly': False, 'barebones': False, 'plugins': None, 'sync_batchnorm': False, 'reload_dataloaders_every_n_epochs': 0, 'default_root_dir': None, 'model_registry': None, '__class__': <class 'lightning.pytorch.trainer.trainer.Trainer'>}
2025-07-23 13:53:07,579 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: trainer fit stage
2025-07-23 13:53:07,580 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_callbacks
2025-07-23 13:53:07,580 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: setting up strategy environment
2025-07-23 13:53:07,692 - lightning.pytorch.utilities.rank_zero - INFO - ----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 2 processes
----------------------------------------------------------------------------------------------------

2025-07-23 13:53:07,698 - lightning.pytorch.utilities.rank_zero - INFO - You are using a CUDA device ('NVIDIA GeForce RTX 3090 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
2025-07-23 13:53:08,395 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: preparing data
2025-07-23 13:53:08,434 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: preparing data
2025-07-23 13:53:11,008 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: setup
2025-07-23 13:53:11,008 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: setup
2025-07-23 13:53:13,576 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: setup
2025-07-23 13:53:25,950 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: setup
2025-07-23 13:53:26,608 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: setup
2025-07-23 13:53:26,608 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: setup
2025-07-23 13:53:28,505 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: configuring model
2025-07-23 13:53:28,505 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring module and callbacks from checkpoint path: None
2025-07-23 13:53:28,505 - lightning.pytorch.trainer.connectors.checkpoint_connector - DEBUG - `checkpoint_path` not specified. Skipping checkpoint loading.
2025-07-23 13:53:28,509 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: configuring model
2025-07-23 13:53:28,509 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring module and callbacks from checkpoint path: None
2025-07-23 13:53:28,510 - lightning.pytorch.trainer.connectors.checkpoint_connector - DEBUG - `checkpoint_path` not specified. Skipping checkpoint loading.
2025-07-23 13:53:28,845 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [2,7]
2025-07-23 13:53:28,846 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_optimizers
2025-07-23 13:53:28,849 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_fit_start
2025-07-23 13:53:28,850 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_fit_start
2025-07-23 13:53:28,850 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring training state
2025-07-23 13:53:28,854 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2,7]
2025-07-23 13:53:28,855 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_optimizers
2025-07-23 13:53:28,859 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_fit_start
2025-07-23 13:53:28,859 - lightning.pytorch.callbacks.model_summary - INFO - 
  | Name               | Type                                    | Params | Mode 
---------------------------------------------------------------------------------------
0 | gaussian_model     | VanillaGaussianModel                    | 124 M  | train
1 | renderer           | GSplatDistributedRendererImpl           | 0      | train
2 | density_controller | DistributedVanillaDensityControllerImpl | 0      | train
3 | metric             | HasInverseDepthMetricsModule            | 0      | train
---------------------------------------------------------------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
497.487   Total estimated model params size (MB)
6         Modules in train mode
0         Modules in eval mode
2025-07-23 13:53:28,859 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_fit_start
2025-07-23 13:53:28,861 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring training state
2025-07-23 13:53:28,862 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_sanity_check_start
2025-07-23 13:53:28,863 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_sanity_check_start
2025-07-23 13:53:28,864 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: val_dataloader
2025-07-23 13:53:28,865 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: val_dataloader
2025-07-23 13:53:28,915 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_model_eval
2025-07-23 13:53:28,916 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_start
2025-07-23 13:53:28,916 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_start
2025-07-23 13:53:28,916 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: on_validation_start
2025-07-23 13:53:28,916 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_epoch_start
2025-07-23 13:53:28,916 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_epoch_start
2025-07-23 13:53:28,916 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_model_eval
2025-07-23 13:53:28,916 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_start
2025-07-23 13:53:28,917 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_start
2025-07-23 13:53:28,917 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: on_validation_start
2025-07-23 13:53:28,917 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_epoch_start
2025-07-23 13:53:28,917 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_epoch_start
2025-07-23 13:53:29,925 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_before_batch_transfer
2025-07-23 13:53:29,925 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: batch_to_device
2025-07-23 13:53:29,925 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: transfer_batch_to_device
2025-07-23 13:53:29,930 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: on_after_batch_transfer
2025-07-23 13:53:29,931 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_batch_start
2025-07-23 13:53:29,931 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_batch_start
2025-07-23 13:53:29,931 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: validation_step
2025-07-23 13:53:30,057 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_before_batch_transfer
2025-07-23 13:53:30,058 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: batch_to_device
2025-07-23 13:53:30,058 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: transfer_batch_to_device
2025-07-23 13:53:30,063 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: on_after_batch_transfer
2025-07-23 13:53:30,064 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_batch_start
2025-07-23 13:53:30,066 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_batch_start
2025-07-23 13:53:30,066 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: validation_step
2025-07-23 13:57:38,885 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: Initializing trainer with parameters: {'self': <lightning.pytorch.trainer.trainer.Trainer object at 0x750daf692780>, 'accelerator': 'gpu', 'strategy': <internal.mp_strategy.MPStrategy object at 0x750daf7fd8e0>, 'devices': -1, 'num_nodes': 1, 'precision': None, 'logger': <lightning.pytorch.loggers.wandb.WandbLogger object at 0x750daf34e780>, 'callbacks': [<internal.entrypoints.gspl.LazyInstance_SaveGaussian object at 0x750f8f5bcbf0>, <internal.entrypoints.gspl.LazyInstance_ValidateOnTrainEnd object at 0x750dafe349e0>, <internal.entrypoints.gspl.LazyInstance_KeepRunningIfWebViewerEnabled object at 0x750dafb13470>, <internal.entrypoints.gspl.LazyInstance_StopImageSavingThreads object at 0x750daff52120>, <internal.entrypoints.gspl.LazyInstance_ProgressBar object at 0x750dafdb7680>, <internal.entrypoints.gspl.LazyInstance_StopDataLoaderCacheThread object at 0x750dbb76fc80>, <internal.callbacks.MySaveConfigCallback object at 0x750daf9ea750>], 'fast_dev_run': False, 'max_epochs': None, 'min_epochs': None, 'max_steps': 90000, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'overfit_batches': 0.0, 'val_check_interval': None, 'check_val_every_n_epoch': 999999, 'num_sanity_val_steps': 1, 'log_every_n_steps': None, 'enable_checkpointing': False, 'enable_progress_bar': None, 'enable_model_summary': None, 'accumulate_grad_batches': 1, 'gradient_clip_val': None, 'gradient_clip_algorithm': None, 'deterministic': None, 'benchmark': None, 'inference_mode': True, 'use_distributed_sampler': False, 'profiler': None, 'detect_anomaly': False, 'barebones': False, 'plugins': None, 'sync_batchnorm': False, 'reload_dataloaders_every_n_epochs': 0, 'default_root_dir': None, 'model_registry': None, '__class__': <class 'lightning.pytorch.trainer.trainer.Trainer'>}
2025-07-23 13:57:38,956 - lightning.pytorch.utilities.rank_zero - INFO - GPU available: True (cuda), used: True
2025-07-23 13:57:38,956 - lightning.pytorch.utilities.rank_zero - INFO - TPU available: False, using: 0 TPU cores
2025-07-23 13:57:38,956 - lightning.pytorch.utilities.rank_zero - INFO - HPU available: False, using: 0 HPUs
2025-07-23 13:57:39,037 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: trainer fit stage
2025-07-23 13:57:39,037 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_callbacks
2025-07-23 13:57:39,038 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: setting up strategy environment
2025-07-23 13:57:45,963 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: Initializing trainer with parameters: {'self': <lightning.pytorch.trainer.trainer.Trainer object at 0x7161c68d10d0>, 'accelerator': 'gpu', 'strategy': <internal.mp_strategy.MPStrategy object at 0x7161c68bbcb0>, 'devices': -1, 'num_nodes': 1, 'precision': None, 'logger': <lightning.pytorch.loggers.wandb.WandbLogger object at 0x7161c68d1070>, 'callbacks': [<internal.entrypoints.gspl.LazyInstance_SaveGaussian object at 0x7161d27ab380>, <internal.entrypoints.gspl.LazyInstance_ValidateOnTrainEnd object at 0x7161c6e29130>, <internal.entrypoints.gspl.LazyInstance_KeepRunningIfWebViewerEnabled object at 0x7161c6df64b0>, <internal.entrypoints.gspl.LazyInstance_StopImageSavingThreads object at 0x7161d3f87fe0>, <internal.entrypoints.gspl.LazyInstance_ProgressBar object at 0x7161c6df6a50>, <internal.entrypoints.gspl.LazyInstance_StopDataLoaderCacheThread object at 0x7161c6a790a0>, <internal.callbacks.MySaveConfigCallback object at 0x7161c6893f20>], 'fast_dev_run': False, 'max_epochs': None, 'min_epochs': None, 'max_steps': 90000, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'overfit_batches': 0.0, 'val_check_interval': None, 'check_val_every_n_epoch': 999999, 'num_sanity_val_steps': 1, 'log_every_n_steps': None, 'enable_checkpointing': False, 'enable_progress_bar': None, 'enable_model_summary': None, 'accumulate_grad_batches': 1, 'gradient_clip_val': None, 'gradient_clip_algorithm': None, 'deterministic': None, 'benchmark': None, 'inference_mode': True, 'use_distributed_sampler': False, 'profiler': None, 'detect_anomaly': False, 'barebones': False, 'plugins': None, 'sync_batchnorm': False, 'reload_dataloaders_every_n_epochs': 0, 'default_root_dir': None, 'model_registry': None, '__class__': <class 'lightning.pytorch.trainer.trainer.Trainer'>}
2025-07-23 13:57:46,049 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: trainer fit stage
2025-07-23 13:57:46,050 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_callbacks
2025-07-23 13:57:46,051 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: setting up strategy environment
2025-07-23 13:57:46,150 - lightning.pytorch.utilities.rank_zero - INFO - ----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 2 processes
----------------------------------------------------------------------------------------------------

2025-07-23 13:57:46,157 - lightning.pytorch.utilities.rank_zero - INFO - You are using a CUDA device ('NVIDIA GeForce RTX 3090 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
2025-07-23 13:57:46,805 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: preparing data
2025-07-23 13:57:46,850 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: preparing data
2025-07-23 13:57:49,671 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: setup
2025-07-23 13:57:49,671 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: setup
2025-07-23 13:57:52,154 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: setup
2025-07-23 13:58:04,185 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: setup
2025-07-23 13:58:04,855 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: setup
2025-07-23 13:58:04,855 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: setup
2025-07-23 13:58:07,046 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: configuring model
2025-07-23 13:58:07,046 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring module and callbacks from checkpoint path: None
2025-07-23 13:58:07,046 - lightning.pytorch.trainer.connectors.checkpoint_connector - DEBUG - `checkpoint_path` not specified. Skipping checkpoint loading.
2025-07-23 13:58:07,115 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: configuring model
2025-07-23 13:58:07,116 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring module and callbacks from checkpoint path: None
2025-07-23 13:58:07,117 - lightning.pytorch.trainer.connectors.checkpoint_connector - DEBUG - `checkpoint_path` not specified. Skipping checkpoint loading.
2025-07-23 13:58:07,678 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [2,7]
2025-07-23 13:58:07,680 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_optimizers
2025-07-23 13:58:07,684 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_fit_start
2025-07-23 13:58:07,684 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_fit_start
2025-07-23 13:58:07,685 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring training state
2025-07-23 13:58:07,707 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2,7]
2025-07-23 13:58:07,709 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_optimizers
2025-07-23 13:58:07,715 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_fit_start
2025-07-23 13:58:07,716 - lightning.pytorch.callbacks.model_summary - INFO - 
  | Name               | Type                                    | Params | Mode 
---------------------------------------------------------------------------------------
0 | gaussian_model     | VanillaGaussianModel                    | 124 M  | train
1 | renderer           | GSplatDistributedRendererImpl           | 0      | train
2 | density_controller | DistributedVanillaDensityControllerImpl | 0      | train
3 | metric             | HasInverseDepthMetricsModule            | 0      | train
---------------------------------------------------------------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
497.487   Total estimated model params size (MB)
6         Modules in train mode
0         Modules in eval mode
2025-07-23 13:58:07,716 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_fit_start
2025-07-23 13:58:07,718 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring training state
2025-07-23 13:58:07,719 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_sanity_check_start
2025-07-23 13:58:07,719 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_sanity_check_start
2025-07-23 13:58:07,722 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: val_dataloader
2025-07-23 13:58:07,722 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: val_dataloader
2025-07-23 13:58:07,774 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_model_eval
2025-07-23 13:58:07,774 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_start
2025-07-23 13:58:07,774 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_start
2025-07-23 13:58:07,774 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: on_validation_start
2025-07-23 13:58:07,774 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_epoch_start
2025-07-23 13:58:07,774 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_model_eval
2025-07-23 13:58:07,774 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_epoch_start
2025-07-23 13:58:07,775 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_start
2025-07-23 13:58:07,775 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_start
2025-07-23 13:58:07,775 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: on_validation_start
2025-07-23 13:58:07,775 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_epoch_start
2025-07-23 13:58:07,775 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_epoch_start
2025-07-23 13:58:09,162 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_before_batch_transfer
2025-07-23 13:58:09,162 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: batch_to_device
2025-07-23 13:58:09,164 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: transfer_batch_to_device
2025-07-23 13:58:09,171 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: on_after_batch_transfer
2025-07-23 13:58:09,172 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_batch_start
2025-07-23 13:58:09,174 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_batch_start
2025-07-23 13:58:09,176 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: validation_step
2025-07-23 13:58:09,227 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_before_batch_transfer
2025-07-23 13:58:09,227 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: batch_to_device
2025-07-23 13:58:09,228 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: transfer_batch_to_device
2025-07-23 13:58:09,238 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: on_after_batch_transfer
2025-07-23 13:58:09,238 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_batch_start
2025-07-23 13:58:09,238 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_batch_start
2025-07-23 13:58:09,239 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: validation_step
2025-07-23 14:02:31,047 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: Initializing trainer with parameters: {'self': <lightning.pytorch.trainer.trainer.Trainer object at 0x79965d755fa0>, 'accelerator': 'gpu', 'strategy': <internal.mp_strategy.MPStrategy object at 0x7996690032f0>, 'devices': -1, 'num_nodes': 1, 'precision': None, 'logger': <lightning.pytorch.loggers.wandb.WandbLogger object at 0x79965d0e5430>, 'callbacks': [<internal.entrypoints.gspl.LazyInstance_SaveGaussian object at 0x79983cf08b00>, <internal.entrypoints.gspl.LazyInstance_ValidateOnTrainEnd object at 0x79965d684800>, <internal.entrypoints.gspl.LazyInstance_KeepRunningIfWebViewerEnabled object at 0x79965d5ca330>, <internal.entrypoints.gspl.LazyInstance_StopImageSavingThreads object at 0x79965d3ad0a0>, <internal.entrypoints.gspl.LazyInstance_ProgressBar object at 0x79965d6daa50>, <internal.entrypoints.gspl.LazyInstance_StopDataLoaderCacheThread object at 0x79965d709c10>, <internal.callbacks.MySaveConfigCallback object at 0x79965d2bd250>], 'fast_dev_run': False, 'max_epochs': None, 'min_epochs': None, 'max_steps': 90000, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'overfit_batches': 0.0, 'val_check_interval': None, 'check_val_every_n_epoch': 999999, 'num_sanity_val_steps': 1, 'log_every_n_steps': None, 'enable_checkpointing': False, 'enable_progress_bar': None, 'enable_model_summary': None, 'accumulate_grad_batches': 1, 'gradient_clip_val': None, 'gradient_clip_algorithm': None, 'deterministic': None, 'benchmark': None, 'inference_mode': True, 'use_distributed_sampler': False, 'profiler': None, 'detect_anomaly': False, 'barebones': False, 'plugins': None, 'sync_batchnorm': False, 'reload_dataloaders_every_n_epochs': 0, 'default_root_dir': None, 'model_registry': None, '__class__': <class 'lightning.pytorch.trainer.trainer.Trainer'>}
2025-07-23 14:02:31,112 - lightning.pytorch.utilities.rank_zero - INFO - GPU available: True (cuda), used: True
2025-07-23 14:02:31,112 - lightning.pytorch.utilities.rank_zero - INFO - TPU available: False, using: 0 TPU cores
2025-07-23 14:02:31,113 - lightning.pytorch.utilities.rank_zero - INFO - HPU available: False, using: 0 HPUs
2025-07-23 14:02:31,185 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: trainer fit stage
2025-07-23 14:02:31,186 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_callbacks
2025-07-23 14:02:31,186 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: setting up strategy environment
2025-07-23 14:02:37,900 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: Initializing trainer with parameters: {'self': <lightning.pytorch.trainer.trainer.Trainer object at 0x75acee8c8d40>, 'accelerator': 'gpu', 'strategy': <internal.mp_strategy.MPStrategy object at 0x75acee8a3260>, 'devices': -1, 'num_nodes': 1, 'precision': None, 'logger': <lightning.pytorch.loggers.wandb.WandbLogger object at 0x75acee8cab70>, 'callbacks': [<internal.entrypoints.gspl.LazyInstance_SaveGaussian object at 0x75aceed0f3e0>, <internal.entrypoints.gspl.LazyInstance_ValidateOnTrainEnd object at 0x75aece7a0d10>, <internal.entrypoints.gspl.LazyInstance_KeepRunningIfWebViewerEnabled object at 0x75aceed4a810>, <internal.entrypoints.gspl.LazyInstance_StopImageSavingThreads object at 0x75aceed48aa0>, <internal.entrypoints.gspl.LazyInstance_ProgressBar object at 0x75aceef67290>, <internal.entrypoints.gspl.LazyInstance_StopDataLoaderCacheThread object at 0x75aceece9b80>, <internal.callbacks.MySaveConfigCallback object at 0x75acee987980>], 'fast_dev_run': False, 'max_epochs': None, 'min_epochs': None, 'max_steps': 90000, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'overfit_batches': 0.0, 'val_check_interval': None, 'check_val_every_n_epoch': 999999, 'num_sanity_val_steps': 1, 'log_every_n_steps': None, 'enable_checkpointing': False, 'enable_progress_bar': None, 'enable_model_summary': None, 'accumulate_grad_batches': 1, 'gradient_clip_val': None, 'gradient_clip_algorithm': None, 'deterministic': None, 'benchmark': None, 'inference_mode': True, 'use_distributed_sampler': False, 'profiler': None, 'detect_anomaly': False, 'barebones': False, 'plugins': None, 'sync_batchnorm': False, 'reload_dataloaders_every_n_epochs': 0, 'default_root_dir': None, 'model_registry': None, '__class__': <class 'lightning.pytorch.trainer.trainer.Trainer'>}
2025-07-23 14:02:37,986 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: trainer fit stage
2025-07-23 14:02:37,987 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_callbacks
2025-07-23 14:02:37,987 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: setting up strategy environment
2025-07-23 14:02:38,135 - lightning.pytorch.utilities.rank_zero - INFO - ----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 2 processes
----------------------------------------------------------------------------------------------------

2025-07-23 14:02:38,142 - lightning.pytorch.utilities.rank_zero - INFO - You are using a CUDA device ('NVIDIA GeForce RTX 3090 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
2025-07-23 14:02:38,679 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: preparing data
2025-07-23 14:02:38,713 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: preparing data
2025-07-23 14:02:41,338 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: setup
2025-07-23 14:02:41,338 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: setup
2025-07-23 14:02:43,735 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: setup
2025-07-23 14:02:58,582 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: setup
2025-07-23 14:02:59,233 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: setup
2025-07-23 14:02:59,233 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: setup
2025-07-23 14:03:00,977 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: configuring model
2025-07-23 14:03:00,977 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring module and callbacks from checkpoint path: None
2025-07-23 14:03:00,977 - lightning.pytorch.trainer.connectors.checkpoint_connector - DEBUG - `checkpoint_path` not specified. Skipping checkpoint loading.
2025-07-23 14:03:01,096 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: configuring model
2025-07-23 14:03:01,097 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring module and callbacks from checkpoint path: None
2025-07-23 14:03:01,097 - lightning.pytorch.trainer.connectors.checkpoint_connector - DEBUG - `checkpoint_path` not specified. Skipping checkpoint loading.
2025-07-23 14:03:01,322 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [2,7]
2025-07-23 14:03:01,323 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_optimizers
2025-07-23 14:03:01,326 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_fit_start
2025-07-23 14:03:01,327 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_fit_start
2025-07-23 14:03:01,327 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring training state
2025-07-23 14:03:01,400 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2,7]
2025-07-23 14:03:01,401 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_optimizers
2025-07-23 14:03:01,404 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_fit_start
2025-07-23 14:03:01,405 - lightning.pytorch.callbacks.model_summary - INFO - 
  | Name               | Type                                    | Params | Mode 
---------------------------------------------------------------------------------------
0 | gaussian_model     | VanillaGaussianModel                    | 124 M  | train
1 | renderer           | GSplatDistributedRendererImpl           | 0      | train
2 | density_controller | DistributedVanillaDensityControllerImpl | 0      | train
3 | metric             | HasInverseDepthMetricsModule            | 0      | train
---------------------------------------------------------------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
497.487   Total estimated model params size (MB)
6         Modules in train mode
0         Modules in eval mode
2025-07-23 14:03:01,405 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_fit_start
2025-07-23 14:03:01,407 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring training state
2025-07-23 14:03:01,408 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_sanity_check_start
2025-07-23 14:03:01,408 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_sanity_check_start
2025-07-23 14:03:01,411 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: val_dataloader
2025-07-23 14:03:01,411 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: val_dataloader
2025-07-23 14:03:01,458 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_model_eval
2025-07-23 14:03:01,458 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_model_eval
2025-07-23 14:03:01,458 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_start
2025-07-23 14:03:01,458 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_start
2025-07-23 14:03:01,458 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_start
2025-07-23 14:03:01,458 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: on_validation_start
2025-07-23 14:03:01,458 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_epoch_start
2025-07-23 14:03:01,458 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_start
2025-07-23 14:03:01,458 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_epoch_start
2025-07-23 14:03:01,458 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: on_validation_start
2025-07-23 14:03:01,458 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_epoch_start
2025-07-23 14:03:01,459 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_epoch_start
2025-07-23 14:03:02,506 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_before_batch_transfer
2025-07-23 14:03:02,507 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: batch_to_device
2025-07-23 14:03:02,509 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: transfer_batch_to_device
2025-07-23 14:03:02,515 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: on_after_batch_transfer
2025-07-23 14:03:02,516 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_batch_start
2025-07-23 14:03:02,518 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_batch_start
2025-07-23 14:03:02,519 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: validation_step
2025-07-23 14:03:02,581 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_before_batch_transfer
2025-07-23 14:03:02,582 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: batch_to_device
2025-07-23 14:03:02,582 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: transfer_batch_to_device
2025-07-23 14:03:02,588 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: on_after_batch_transfer
2025-07-23 14:03:02,589 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_batch_start
2025-07-23 14:03:02,589 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_batch_start
2025-07-23 14:03:02,590 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: validation_step
2025-07-23 14:06:31,013 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: Initializing trainer with parameters: {'self': <lightning.pytorch.trainer.trainer.Trainer object at 0x75313d87b200>, 'accelerator': 'gpu', 'strategy': <internal.mp_strategy.MPStrategy object at 0x75313e801250>, 'devices': -1, 'num_nodes': 1, 'precision': None, 'logger': <lightning.pytorch.loggers.wandb.WandbLogger object at 0x75313e6da9c0>, 'callbacks': [<internal.entrypoints.gspl.LazyInstance_SaveGaussian object at 0x75331e5d8b90>, <internal.entrypoints.gspl.LazyInstance_ValidateOnTrainEnd object at 0x75313ee54620>, <internal.entrypoints.gspl.LazyInstance_KeepRunningIfWebViewerEnabled object at 0x75313edbb560>, <internal.entrypoints.gspl.LazyInstance_StopImageSavingThreads object at 0x75313ea830e0>, <internal.entrypoints.gspl.LazyInstance_ProgressBar object at 0x75313ee34a40>, <internal.entrypoints.gspl.LazyInstance_StopDataLoaderCacheThread object at 0x75313eb138c0>, <internal.callbacks.MySaveConfigCallback object at 0x75313ea447a0>], 'fast_dev_run': False, 'max_epochs': None, 'min_epochs': None, 'max_steps': 90000, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'overfit_batches': 0.0, 'val_check_interval': None, 'check_val_every_n_epoch': 999999, 'num_sanity_val_steps': 1, 'log_every_n_steps': None, 'enable_checkpointing': False, 'enable_progress_bar': None, 'enable_model_summary': None, 'accumulate_grad_batches': 1, 'gradient_clip_val': None, 'gradient_clip_algorithm': None, 'deterministic': None, 'benchmark': None, 'inference_mode': True, 'use_distributed_sampler': False, 'profiler': None, 'detect_anomaly': False, 'barebones': False, 'plugins': None, 'sync_batchnorm': False, 'reload_dataloaders_every_n_epochs': 0, 'default_root_dir': None, 'model_registry': None, '__class__': <class 'lightning.pytorch.trainer.trainer.Trainer'>}
2025-07-23 14:06:31,081 - lightning.pytorch.utilities.rank_zero - INFO - GPU available: True (cuda), used: True
2025-07-23 14:06:31,082 - lightning.pytorch.utilities.rank_zero - INFO - TPU available: False, using: 0 TPU cores
2025-07-23 14:06:31,082 - lightning.pytorch.utilities.rank_zero - INFO - HPU available: False, using: 0 HPUs
2025-07-23 14:06:31,160 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: trainer fit stage
2025-07-23 14:06:31,163 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_callbacks
2025-07-23 14:06:31,164 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: setting up strategy environment
2025-07-23 14:06:38,577 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: Initializing trainer with parameters: {'self': <lightning.pytorch.trainer.trainer.Trainer object at 0x760db39a8e60>, 'accelerator': 'gpu', 'strategy': <internal.mp_strategy.MPStrategy object at 0x760db4821580>, 'devices': -1, 'num_nodes': 1, 'precision': None, 'logger': <lightning.pytorch.loggers.wandb.WandbLogger object at 0x760db37e4a70>, 'callbacks': [<internal.entrypoints.gspl.LazyInstance_SaveGaussian object at 0x760dc0288140>, <internal.entrypoints.gspl.LazyInstance_ValidateOnTrainEnd object at 0x760db4c8d9d0>, <internal.entrypoints.gspl.LazyInstance_KeepRunningIfWebViewerEnabled object at 0x760db4aff740>, <internal.entrypoints.gspl.LazyInstance_StopImageSavingThreads object at 0x760db4a63ce0>, <internal.entrypoints.gspl.LazyInstance_ProgressBar object at 0x760db4affec0>, <internal.entrypoints.gspl.LazyInstance_StopDataLoaderCacheThread object at 0x760db4a9dac0>, <internal.callbacks.MySaveConfigCallback object at 0x760db46185f0>], 'fast_dev_run': False, 'max_epochs': None, 'min_epochs': None, 'max_steps': 90000, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'overfit_batches': 0.0, 'val_check_interval': None, 'check_val_every_n_epoch': 999999, 'num_sanity_val_steps': 1, 'log_every_n_steps': None, 'enable_checkpointing': False, 'enable_progress_bar': None, 'enable_model_summary': None, 'accumulate_grad_batches': 1, 'gradient_clip_val': None, 'gradient_clip_algorithm': None, 'deterministic': None, 'benchmark': None, 'inference_mode': True, 'use_distributed_sampler': False, 'profiler': None, 'detect_anomaly': False, 'barebones': False, 'plugins': None, 'sync_batchnorm': False, 'reload_dataloaders_every_n_epochs': 0, 'default_root_dir': None, 'model_registry': None, '__class__': <class 'lightning.pytorch.trainer.trainer.Trainer'>}
2025-07-23 14:06:38,650 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: trainer fit stage
2025-07-23 14:06:38,650 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_callbacks
2025-07-23 14:06:38,651 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: setting up strategy environment
2025-07-23 14:06:38,749 - lightning.pytorch.utilities.rank_zero - INFO - ----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 2 processes
----------------------------------------------------------------------------------------------------

2025-07-23 14:06:38,758 - lightning.pytorch.utilities.rank_zero - INFO - You are using a CUDA device ('NVIDIA GeForce RTX 3090 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
2025-07-23 14:06:39,234 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: preparing data
2025-07-23 14:06:39,262 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: preparing data
2025-07-23 14:06:41,977 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: setup
2025-07-23 14:06:41,977 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: setup
2025-07-23 14:06:44,658 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: setup
2025-07-23 14:06:56,699 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: setup
2025-07-23 14:06:57,306 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: setup
2025-07-23 14:06:57,306 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: setup
2025-07-23 14:06:58,863 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: configuring model
2025-07-23 14:06:58,864 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring module and callbacks from checkpoint path: None
2025-07-23 14:06:58,864 - lightning.pytorch.trainer.connectors.checkpoint_connector - DEBUG - `checkpoint_path` not specified. Skipping checkpoint loading.
2025-07-23 14:06:58,986 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: configuring model
2025-07-23 14:06:58,987 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring module and callbacks from checkpoint path: None
2025-07-23 14:06:58,987 - lightning.pytorch.trainer.connectors.checkpoint_connector - DEBUG - `checkpoint_path` not specified. Skipping checkpoint loading.
2025-07-23 14:06:59,222 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [2,7]
2025-07-23 14:06:59,223 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_optimizers
2025-07-23 14:06:59,227 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_fit_start
2025-07-23 14:06:59,228 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_fit_start
2025-07-23 14:06:59,229 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring training state
2025-07-23 14:06:59,331 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2,7]
2025-07-23 14:06:59,332 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_optimizers
2025-07-23 14:06:59,335 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_fit_start
2025-07-23 14:06:59,335 - lightning.pytorch.callbacks.model_summary - INFO - 
  | Name               | Type                                    | Params | Mode 
---------------------------------------------------------------------------------------
0 | gaussian_model     | VanillaGaussianModel                    | 124 M  | train
1 | renderer           | GSplatDistributedRendererImpl           | 0      | train
2 | density_controller | DistributedVanillaDensityControllerImpl | 0      | train
3 | metric             | HasInverseDepthMetricsModule            | 0      | train
---------------------------------------------------------------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
497.487   Total estimated model params size (MB)
6         Modules in train mode
0         Modules in eval mode
2025-07-23 14:06:59,335 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_fit_start
2025-07-23 14:06:59,337 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring training state
2025-07-23 14:06:59,338 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_sanity_check_start
2025-07-23 14:06:59,339 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_sanity_check_start
2025-07-23 14:06:59,340 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: val_dataloader
2025-07-23 14:06:59,342 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: val_dataloader
2025-07-23 14:06:59,390 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_model_eval
2025-07-23 14:06:59,390 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_start
2025-07-23 14:06:59,390 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_start
2025-07-23 14:06:59,390 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: on_validation_start
2025-07-23 14:06:59,391 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_epoch_start
2025-07-23 14:06:59,391 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_epoch_start
2025-07-23 14:06:59,393 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_model_eval
2025-07-23 14:06:59,393 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_start
2025-07-23 14:06:59,393 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_start
2025-07-23 14:06:59,393 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: on_validation_start
2025-07-23 14:06:59,394 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_epoch_start
2025-07-23 14:06:59,394 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_epoch_start
2025-07-23 14:07:00,603 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_before_batch_transfer
2025-07-23 14:07:00,604 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: batch_to_device
2025-07-23 14:07:00,604 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: transfer_batch_to_device
2025-07-23 14:07:00,609 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: on_after_batch_transfer
2025-07-23 14:07:00,610 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_batch_start
2025-07-23 14:07:00,610 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_batch_start
2025-07-23 14:07:00,610 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: validation_step
2025-07-23 14:07:00,734 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_before_batch_transfer
2025-07-23 14:07:00,734 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: batch_to_device
2025-07-23 14:07:00,735 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: transfer_batch_to_device
2025-07-23 14:07:00,739 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: on_after_batch_transfer
2025-07-23 14:07:00,740 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_batch_start
2025-07-23 14:07:00,741 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_batch_start
2025-07-23 14:07:00,741 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: validation_step
2025-07-23 14:10:05,110 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: Initializing trainer with parameters: {'self': <lightning.pytorch.trainer.trainer.Trainer object at 0x78b862ec4920>, 'accelerator': 'gpu', 'strategy': <internal.mp_strategy.MPStrategy object at 0x78b86312af60>, 'devices': -1, 'num_nodes': 1, 'precision': None, 'logger': <lightning.pytorch.loggers.wandb.WandbLogger object at 0x78b862d526c0>, 'callbacks': [<internal.entrypoints.gspl.LazyInstance_SaveGaussian object at 0x78b863495100>, <internal.entrypoints.gspl.LazyInstance_ValidateOnTrainEnd object at 0x78ba42d54aa0>, <internal.entrypoints.gspl.LazyInstance_KeepRunningIfWebViewerEnabled object at 0x78b86eb45be0>, <internal.entrypoints.gspl.LazyInstance_StopImageSavingThreads object at 0x78b863497da0>, <internal.entrypoints.gspl.LazyInstance_ProgressBar object at 0x78b8632c7c50>, <internal.entrypoints.gspl.LazyInstance_StopDataLoaderCacheThread object at 0x78b86ed95940>, <internal.callbacks.MySaveConfigCallback object at 0x78b862ec5be0>], 'fast_dev_run': False, 'max_epochs': None, 'min_epochs': None, 'max_steps': 90000, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'overfit_batches': 0.0, 'val_check_interval': None, 'check_val_every_n_epoch': 999999, 'num_sanity_val_steps': 1, 'log_every_n_steps': None, 'enable_checkpointing': False, 'enable_progress_bar': None, 'enable_model_summary': None, 'accumulate_grad_batches': 1, 'gradient_clip_val': None, 'gradient_clip_algorithm': None, 'deterministic': None, 'benchmark': None, 'inference_mode': True, 'use_distributed_sampler': False, 'profiler': None, 'detect_anomaly': False, 'barebones': False, 'plugins': None, 'sync_batchnorm': False, 'reload_dataloaders_every_n_epochs': 0, 'default_root_dir': None, 'model_registry': None, '__class__': <class 'lightning.pytorch.trainer.trainer.Trainer'>}
2025-07-23 14:10:05,197 - lightning.pytorch.utilities.rank_zero - INFO - GPU available: True (cuda), used: True
2025-07-23 14:10:05,198 - lightning.pytorch.utilities.rank_zero - INFO - TPU available: False, using: 0 TPU cores
2025-07-23 14:10:05,198 - lightning.pytorch.utilities.rank_zero - INFO - HPU available: False, using: 0 HPUs
2025-07-23 14:10:05,359 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: trainer fit stage
2025-07-23 14:10:05,366 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_callbacks
2025-07-23 14:10:05,367 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: setting up strategy environment
2025-07-23 14:10:13,096 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: Initializing trainer with parameters: {'self': <lightning.pytorch.trainer.trainer.Trainer object at 0x70731900d0d0>, 'accelerator': 'gpu', 'strategy': <internal.mp_strategy.MPStrategy object at 0x707318ddabd0>, 'devices': -1, 'num_nodes': 1, 'precision': None, 'logger': <lightning.pytorch.loggers.wandb.WandbLogger object at 0x707318e22060>, 'callbacks': [<internal.entrypoints.gspl.LazyInstance_SaveGaussian object at 0x7074f8c4cc50>, <internal.entrypoints.gspl.LazyInstance_ValidateOnTrainEnd object at 0x7073193d9130>, <internal.entrypoints.gspl.LazyInstance_KeepRunningIfWebViewerEnabled object at 0x70731922e630>, <internal.entrypoints.gspl.LazyInstance_StopImageSavingThreads object at 0x70731928b1a0>, <internal.entrypoints.gspl.LazyInstance_ProgressBar object at 0x707319576210>, <internal.entrypoints.gspl.LazyInstance_StopDataLoaderCacheThread object at 0x7073195a5af0>, <internal.callbacks.MySaveConfigCallback object at 0x707318e04e30>], 'fast_dev_run': False, 'max_epochs': None, 'min_epochs': None, 'max_steps': 90000, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'overfit_batches': 0.0, 'val_check_interval': None, 'check_val_every_n_epoch': 999999, 'num_sanity_val_steps': 1, 'log_every_n_steps': None, 'enable_checkpointing': False, 'enable_progress_bar': None, 'enable_model_summary': None, 'accumulate_grad_batches': 1, 'gradient_clip_val': None, 'gradient_clip_algorithm': None, 'deterministic': None, 'benchmark': None, 'inference_mode': True, 'use_distributed_sampler': False, 'profiler': None, 'detect_anomaly': False, 'barebones': False, 'plugins': None, 'sync_batchnorm': False, 'reload_dataloaders_every_n_epochs': 0, 'default_root_dir': None, 'model_registry': None, '__class__': <class 'lightning.pytorch.trainer.trainer.Trainer'>}
2025-07-23 14:10:13,164 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: trainer fit stage
2025-07-23 14:10:13,164 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_callbacks
2025-07-23 14:10:13,164 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: setting up strategy environment
2025-07-23 14:10:13,281 - lightning.pytorch.utilities.rank_zero - INFO - ----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 2 processes
----------------------------------------------------------------------------------------------------

2025-07-23 14:10:13,287 - lightning.pytorch.utilities.rank_zero - INFO - You are using a CUDA device ('NVIDIA GeForce RTX 3090 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
2025-07-23 14:10:13,734 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: preparing data
2025-07-23 14:10:13,791 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: preparing data
2025-07-23 14:10:16,372 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: setup
2025-07-23 14:10:16,372 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: setup
2025-07-23 14:10:19,549 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: setup
2025-07-23 14:10:35,900 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: setup
2025-07-23 14:10:36,499 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: setup
2025-07-23 14:10:36,575 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: setup
2025-07-23 14:10:38,103 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: configuring model
2025-07-23 14:10:38,103 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring module and callbacks from checkpoint path: None
2025-07-23 14:10:38,104 - lightning.pytorch.trainer.connectors.checkpoint_connector - DEBUG - `checkpoint_path` not specified. Skipping checkpoint loading.
2025-07-23 14:10:38,122 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: configuring model
2025-07-23 14:10:38,123 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring module and callbacks from checkpoint path: None
2025-07-23 14:10:38,123 - lightning.pytorch.trainer.connectors.checkpoint_connector - DEBUG - `checkpoint_path` not specified. Skipping checkpoint loading.
2025-07-23 14:10:38,420 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [2,7]
2025-07-23 14:10:38,421 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_optimizers
2025-07-23 14:10:38,424 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_fit_start
2025-07-23 14:10:38,425 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_fit_start
2025-07-23 14:10:38,425 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring training state
2025-07-23 14:10:38,437 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2,7]
2025-07-23 14:10:38,438 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_optimizers
2025-07-23 14:10:38,443 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_fit_start
2025-07-23 14:10:38,444 - lightning.pytorch.callbacks.model_summary - INFO - 
  | Name               | Type                                    | Params | Mode 
---------------------------------------------------------------------------------------
0 | gaussian_model     | VanillaGaussianModel                    | 124 M  | train
1 | renderer           | GSplatDistributedRendererImpl           | 0      | train
2 | density_controller | DistributedVanillaDensityControllerImpl | 0      | train
3 | metric             | HasInverseDepthMetricsModule            | 0      | train
---------------------------------------------------------------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
497.487   Total estimated model params size (MB)
6         Modules in train mode
0         Modules in eval mode
2025-07-23 14:10:38,444 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_fit_start
2025-07-23 14:10:38,446 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring training state
2025-07-23 14:10:38,448 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_sanity_check_start
2025-07-23 14:10:38,448 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_sanity_check_start
2025-07-23 14:10:38,450 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: val_dataloader
2025-07-23 14:10:38,450 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: val_dataloader
2025-07-23 14:10:38,496 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_model_eval
2025-07-23 14:10:38,496 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_start
2025-07-23 14:10:38,496 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_start
2025-07-23 14:10:38,496 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: on_validation_start
2025-07-23 14:10:38,496 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_epoch_start
2025-07-23 14:10:38,497 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_epoch_start
2025-07-23 14:10:38,499 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_model_eval
2025-07-23 14:10:38,499 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_start
2025-07-23 14:10:38,500 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_start
2025-07-23 14:10:38,500 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: on_validation_start
2025-07-23 14:10:38,500 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_epoch_start
2025-07-23 14:10:38,500 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_epoch_start
2025-07-23 14:10:39,470 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_before_batch_transfer
2025-07-23 14:10:39,472 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: batch_to_device
2025-07-23 14:10:39,473 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: transfer_batch_to_device
2025-07-23 14:10:39,480 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: on_after_batch_transfer
2025-07-23 14:10:39,480 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_batch_start
2025-07-23 14:10:39,483 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_batch_start
2025-07-23 14:10:39,483 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: validation_step
2025-07-23 14:10:39,539 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_before_batch_transfer
2025-07-23 14:10:39,540 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: batch_to_device
2025-07-23 14:10:39,540 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: transfer_batch_to_device
2025-07-23 14:10:39,546 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: on_after_batch_transfer
2025-07-23 14:10:39,546 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_batch_start
2025-07-23 14:10:39,546 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_batch_start
2025-07-23 14:10:39,547 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: validation_step
2025-07-23 14:15:23,272 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: Initializing trainer with parameters: {'self': <lightning.pytorch.trainer.trainer.Trainer object at 0x74182d06f7d0>, 'accelerator': 'gpu', 'strategy': <internal.mp_strategy.MPStrategy object at 0x74182ce0bc50>, 'devices': -1, 'num_nodes': 1, 'precision': None, 'logger': <lightning.pytorch.loggers.wandb.WandbLogger object at 0x74182ce37d40>, 'callbacks': [<internal.entrypoints.gspl.LazyInstance_SaveGaussian object at 0x741a0cc48b30>, <internal.entrypoints.gspl.LazyInstance_ValidateOnTrainEnd object at 0x74182d3d9130>, <internal.entrypoints.gspl.LazyInstance_KeepRunningIfWebViewerEnabled object at 0x7418389c3d70>, <internal.entrypoints.gspl.LazyInstance_StopImageSavingThreads object at 0x741838c231a0>, <internal.entrypoints.gspl.LazyInstance_ProgressBar object at 0x74182d322210>, <internal.entrypoints.gspl.LazyInstance_StopDataLoaderCacheThread object at 0x7418edfb2180>, <internal.callbacks.MySaveConfigCallback object at 0x74182d04a600>], 'fast_dev_run': False, 'max_epochs': None, 'min_epochs': None, 'max_steps': 90000, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'overfit_batches': 0.0, 'val_check_interval': None, 'check_val_every_n_epoch': 999999, 'num_sanity_val_steps': 1, 'log_every_n_steps': None, 'enable_checkpointing': False, 'enable_progress_bar': None, 'enable_model_summary': None, 'accumulate_grad_batches': 1, 'gradient_clip_val': None, 'gradient_clip_algorithm': None, 'deterministic': None, 'benchmark': None, 'inference_mode': True, 'use_distributed_sampler': False, 'profiler': None, 'detect_anomaly': False, 'barebones': False, 'plugins': None, 'sync_batchnorm': False, 'reload_dataloaders_every_n_epochs': 0, 'default_root_dir': None, 'model_registry': None, '__class__': <class 'lightning.pytorch.trainer.trainer.Trainer'>}
2025-07-23 14:15:23,355 - lightning.pytorch.utilities.rank_zero - INFO - GPU available: True (cuda), used: True
2025-07-23 14:15:23,355 - lightning.pytorch.utilities.rank_zero - INFO - TPU available: False, using: 0 TPU cores
2025-07-23 14:15:23,356 - lightning.pytorch.utilities.rank_zero - INFO - HPU available: False, using: 0 HPUs
2025-07-23 14:15:23,465 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: trainer fit stage
2025-07-23 14:15:23,466 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_callbacks
2025-07-23 14:15:23,467 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: setting up strategy environment
2025-07-23 14:15:30,480 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: Initializing trainer with parameters: {'self': <lightning.pytorch.trainer.trainer.Trainer object at 0x776d190dabd0>, 'accelerator': 'gpu', 'strategy': <internal.mp_strategy.MPStrategy object at 0x776d190dad50>, 'devices': -1, 'num_nodes': 1, 'precision': None, 'logger': <lightning.pytorch.loggers.wandb.WandbLogger object at 0x776d18008980>, 'callbacks': [<internal.entrypoints.gspl.LazyInstance_SaveGaussian object at 0x776ef8cfcc50>, <internal.entrypoints.gspl.LazyInstance_ValidateOnTrainEnd object at 0x776d24c07da0>, <internal.entrypoints.gspl.LazyInstance_KeepRunningIfWebViewerEnabled object at 0x776d24c37230>, <internal.entrypoints.gspl.LazyInstance_StopImageSavingThreads object at 0x776d24a4f560>, <internal.entrypoints.gspl.LazyInstance_ProgressBar object at 0x776d24c74710>, <internal.entrypoints.gspl.LazyInstance_StopDataLoaderCacheThread object at 0x776d1960a0c0>, <internal.callbacks.MySaveConfigCallback object at 0x776d185ba0c0>], 'fast_dev_run': False, 'max_epochs': None, 'min_epochs': None, 'max_steps': 90000, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'overfit_batches': 0.0, 'val_check_interval': None, 'check_val_every_n_epoch': 999999, 'num_sanity_val_steps': 1, 'log_every_n_steps': None, 'enable_checkpointing': False, 'enable_progress_bar': None, 'enable_model_summary': None, 'accumulate_grad_batches': 1, 'gradient_clip_val': None, 'gradient_clip_algorithm': None, 'deterministic': None, 'benchmark': None, 'inference_mode': True, 'use_distributed_sampler': False, 'profiler': None, 'detect_anomaly': False, 'barebones': False, 'plugins': None, 'sync_batchnorm': False, 'reload_dataloaders_every_n_epochs': 0, 'default_root_dir': None, 'model_registry': None, '__class__': <class 'lightning.pytorch.trainer.trainer.Trainer'>}
2025-07-23 14:15:30,564 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: trainer fit stage
2025-07-23 14:15:30,565 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_callbacks
2025-07-23 14:15:30,565 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: setting up strategy environment
2025-07-23 14:15:30,663 - lightning.pytorch.utilities.rank_zero - INFO - ----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 2 processes
----------------------------------------------------------------------------------------------------

2025-07-23 14:15:30,672 - lightning.pytorch.utilities.rank_zero - INFO - You are using a CUDA device ('NVIDIA GeForce RTX 3090 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
2025-07-23 14:15:31,367 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: preparing data
2025-07-23 14:15:31,417 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: preparing data
2025-07-23 14:15:34,122 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: setup
2025-07-23 14:15:34,122 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: setup
2025-07-23 14:15:37,550 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: setup
2025-07-23 14:15:50,158 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: setup
2025-07-23 14:15:50,644 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: setup
2025-07-23 14:15:50,644 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: setup
2025-07-23 14:15:52,254 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: configuring model
2025-07-23 14:15:52,254 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: configuring model
2025-07-23 14:15:52,254 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring module and callbacks from checkpoint path: None
2025-07-23 14:15:52,254 - lightning.pytorch.trainer.connectors.checkpoint_connector - DEBUG - `checkpoint_path` not specified. Skipping checkpoint loading.
2025-07-23 14:15:52,254 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring module and callbacks from checkpoint path: None
2025-07-23 14:15:52,254 - lightning.pytorch.trainer.connectors.checkpoint_connector - DEBUG - `checkpoint_path` not specified. Skipping checkpoint loading.
2025-07-23 14:15:52,578 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2,7]
2025-07-23 14:15:52,579 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_optimizers
2025-07-23 14:15:52,582 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_fit_start
2025-07-23 14:15:52,582 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [2,7]
2025-07-23 14:15:52,583 - lightning.pytorch.callbacks.model_summary - INFO - 
  | Name               | Type                                    | Params | Mode 
---------------------------------------------------------------------------------------
0 | gaussian_model     | VanillaGaussianModel                    | 124 M  | train
1 | renderer           | GSplatDistributedRendererImpl           | 0      | train
2 | density_controller | DistributedVanillaDensityControllerImpl | 0      | train
3 | metric             | HasInverseDepthMetricsModule            | 0      | train
---------------------------------------------------------------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
497.487   Total estimated model params size (MB)
6         Modules in train mode
0         Modules in eval mode
2025-07-23 14:15:52,583 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_fit_start
2025-07-23 14:15:52,583 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_optimizers
2025-07-23 14:15:52,584 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring training state
2025-07-23 14:15:52,585 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_fit_start
2025-07-23 14:15:52,586 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_fit_start
2025-07-23 14:15:52,587 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring training state
2025-07-23 14:15:52,588 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_sanity_check_start
2025-07-23 14:15:52,588 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_sanity_check_start
2025-07-23 14:15:52,590 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: val_dataloader
2025-07-23 14:15:52,590 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: val_dataloader
2025-07-23 14:15:52,638 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_model_eval
2025-07-23 14:15:52,639 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_start
2025-07-23 14:15:52,639 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_start
2025-07-23 14:15:52,639 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: on_validation_start
2025-07-23 14:15:52,639 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_epoch_start
2025-07-23 14:15:52,639 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_epoch_start
2025-07-23 14:15:52,641 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_model_eval
2025-07-23 14:15:52,641 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_start
2025-07-23 14:15:52,641 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_start
2025-07-23 14:15:52,641 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: on_validation_start
2025-07-23 14:15:52,641 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_epoch_start
2025-07-23 14:15:52,641 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_epoch_start
2025-07-23 14:15:53,584 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_before_batch_transfer
2025-07-23 14:15:53,585 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: batch_to_device
2025-07-23 14:15:53,585 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: transfer_batch_to_device
2025-07-23 14:15:53,592 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: on_after_batch_transfer
2025-07-23 14:15:53,593 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_batch_start
2025-07-23 14:15:53,593 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_batch_start
2025-07-23 14:15:53,594 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: validation_step
2025-07-23 14:15:53,763 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_before_batch_transfer
2025-07-23 14:15:53,764 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: batch_to_device
2025-07-23 14:15:53,765 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: transfer_batch_to_device
2025-07-23 14:15:53,770 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: on_after_batch_transfer
2025-07-23 14:15:53,771 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_batch_start
2025-07-23 14:15:53,773 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_batch_start
2025-07-23 14:15:53,774 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: validation_step
2025-07-23 14:26:42,056 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: Initializing trainer with parameters: {'self': <lightning.pytorch.trainer.trainer.Trainer object at 0x7f53e125ec90>, 'accelerator': 'gpu', 'strategy': <internal.mp_strategy.MPStrategy object at 0x7f53e125e8d0>, 'devices': '2,4,6,7', 'num_nodes': 1, 'precision': None, 'logger': <lightning.pytorch.loggers.wandb.WandbLogger object at 0x7f53e1005550>, 'callbacks': [<internal.entrypoints.gspl.LazyInstance_SaveGaussian object at 0x7f55c0e38bc0>, <internal.entrypoints.gspl.LazyInstance_ValidateOnTrainEnd object at 0x7f54a21b2300>, <internal.entrypoints.gspl.LazyInstance_KeepRunningIfWebViewerEnabled object at 0x7f53e142d820>, <internal.entrypoints.gspl.LazyInstance_StopImageSavingThreads object at 0x7f53e15525a0>, <internal.entrypoints.gspl.LazyInstance_ProgressBar object at 0x7f53e14efb90>, <internal.entrypoints.gspl.LazyInstance_StopDataLoaderCacheThread object at 0x7f53e148af00>, <internal.callbacks.MySaveConfigCallback object at 0x7f53e1005ee0>], 'fast_dev_run': False, 'max_epochs': None, 'min_epochs': None, 'max_steps': 90000, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'overfit_batches': 0.0, 'val_check_interval': None, 'check_val_every_n_epoch': 999999, 'num_sanity_val_steps': 1, 'log_every_n_steps': None, 'enable_checkpointing': False, 'enable_progress_bar': None, 'enable_model_summary': None, 'accumulate_grad_batches': 1, 'gradient_clip_val': None, 'gradient_clip_algorithm': None, 'deterministic': None, 'benchmark': None, 'inference_mode': True, 'use_distributed_sampler': False, 'profiler': None, 'detect_anomaly': False, 'barebones': False, 'plugins': None, 'sync_batchnorm': False, 'reload_dataloaders_every_n_epochs': 0, 'default_root_dir': None, 'model_registry': None, '__class__': <class 'lightning.pytorch.trainer.trainer.Trainer'>}
2025-07-23 14:26:42,157 - lightning.pytorch.utilities.rank_zero - INFO - GPU available: True (cuda), used: True
2025-07-23 14:26:42,158 - lightning.pytorch.utilities.rank_zero - INFO - TPU available: False, using: 0 TPU cores
2025-07-23 14:26:42,158 - lightning.pytorch.utilities.rank_zero - INFO - HPU available: False, using: 0 HPUs
2025-07-23 14:26:42,281 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: trainer fit stage
2025-07-23 14:26:42,282 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_callbacks
2025-07-23 14:26:42,282 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: setting up strategy environment
2025-07-23 14:26:49,490 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: Initializing trainer with parameters: {'self': <lightning.pytorch.trainer.trainer.Trainer object at 0x75268c0f55b0>, 'accelerator': 'gpu', 'strategy': <internal.mp_strategy.MPStrategy object at 0x7524abff36e0>, 'devices': '2,4,6,7', 'num_nodes': 1, 'precision': None, 'logger': <lightning.pytorch.loggers.wandb.WandbLogger object at 0x7524ac048980>, 'callbacks': [<internal.entrypoints.gspl.LazyInstance_SaveGaussian object at 0x75268be34c20>, <internal.entrypoints.gspl.LazyInstance_ValidateOnTrainEnd object at 0x7524ac616300>, <internal.entrypoints.gspl.LazyInstance_KeepRunningIfWebViewerEnabled object at 0x75268be355e0>, <internal.entrypoints.gspl.LazyInstance_StopImageSavingThreads object at 0x7524ac4acef0>, <internal.entrypoints.gspl.LazyInstance_ProgressBar object at 0x7524ac153e00>, <internal.entrypoints.gspl.LazyInstance_StopDataLoaderCacheThread object at 0x7524ac1b4fb0>, <internal.callbacks.MySaveConfigCallback object at 0x7524ac121b50>], 'fast_dev_run': False, 'max_epochs': None, 'min_epochs': None, 'max_steps': 90000, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'overfit_batches': 0.0, 'val_check_interval': None, 'check_val_every_n_epoch': 999999, 'num_sanity_val_steps': 1, 'log_every_n_steps': None, 'enable_checkpointing': False, 'enable_progress_bar': None, 'enable_model_summary': None, 'accumulate_grad_batches': 1, 'gradient_clip_val': None, 'gradient_clip_algorithm': None, 'deterministic': None, 'benchmark': None, 'inference_mode': True, 'use_distributed_sampler': False, 'profiler': None, 'detect_anomaly': False, 'barebones': False, 'plugins': None, 'sync_batchnorm': False, 'reload_dataloaders_every_n_epochs': 0, 'default_root_dir': None, 'model_registry': None, '__class__': <class 'lightning.pytorch.trainer.trainer.Trainer'>}
2025-07-23 14:26:49,559 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: trainer fit stage
2025-07-23 14:26:49,560 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_callbacks
2025-07-23 14:26:49,560 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: setting up strategy environment
2025-07-23 14:26:49,570 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: Initializing trainer with parameters: {'self': <lightning.pytorch.trainer.trainer.Trainer object at 0x7bb27f1fb740>, 'accelerator': 'gpu', 'strategy': <internal.mp_strategy.MPStrategy object at 0x7bb27f004ad0>, 'devices': '2,4,6,7', 'num_nodes': 1, 'precision': None, 'logger': <lightning.pytorch.loggers.wandb.WandbLogger object at 0x7bb27eff21e0>, 'callbacks': [<internal.entrypoints.gspl.LazyInstance_SaveGaussian object at 0x7bb45ee1cc50>, <internal.entrypoints.gspl.LazyInstance_ValidateOnTrainEnd object at 0x7bb27f291760>, <internal.entrypoints.gspl.LazyInstance_KeepRunningIfWebViewerEnabled object at 0x7bb27f5f6e70>, <internal.entrypoints.gspl.LazyInstance_StopImageSavingThreads object at 0x7bb28ad17fe0>, <internal.entrypoints.gspl.LazyInstance_ProgressBar object at 0x7bb27f50e2d0>, <internal.entrypoints.gspl.LazyInstance_StopDataLoaderCacheThread object at 0x7bb27f75e240>, <internal.callbacks.MySaveConfigCallback object at 0x7bb27f1fb8c0>], 'fast_dev_run': False, 'max_epochs': None, 'min_epochs': None, 'max_steps': 90000, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'overfit_batches': 0.0, 'val_check_interval': None, 'check_val_every_n_epoch': 999999, 'num_sanity_val_steps': 1, 'log_every_n_steps': None, 'enable_checkpointing': False, 'enable_progress_bar': None, 'enable_model_summary': None, 'accumulate_grad_batches': 1, 'gradient_clip_val': None, 'gradient_clip_algorithm': None, 'deterministic': None, 'benchmark': None, 'inference_mode': True, 'use_distributed_sampler': False, 'profiler': None, 'detect_anomaly': False, 'barebones': False, 'plugins': None, 'sync_batchnorm': False, 'reload_dataloaders_every_n_epochs': 0, 'default_root_dir': None, 'model_registry': None, '__class__': <class 'lightning.pytorch.trainer.trainer.Trainer'>}
2025-07-23 14:26:49,674 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: trainer fit stage
2025-07-23 14:26:49,675 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_callbacks
2025-07-23 14:26:49,675 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: setting up strategy environment
2025-07-23 14:26:49,970 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: Initializing trainer with parameters: {'self': <lightning.pytorch.trainer.trainer.Trainer object at 0x7d465689aed0>, 'accelerator': 'gpu', 'strategy': <internal.mp_strategy.MPStrategy object at 0x7d4657a636e0>, 'devices': '2,4,6,7', 'num_nodes': 1, 'precision': None, 'logger': <lightning.pytorch.loggers.wandb.WandbLogger object at 0x7d4657a62990>, 'callbacks': [<internal.entrypoints.gspl.LazyInstance_SaveGaussian object at 0x7d4837644d10>, <internal.entrypoints.gspl.LazyInstance_ValidateOnTrainEnd object at 0x7d4657d24aa0>, <internal.entrypoints.gspl.LazyInstance_KeepRunningIfWebViewerEnabled object at 0x7d4657f7a570>, <internal.entrypoints.gspl.LazyInstance_StopImageSavingThreads object at 0x7d4657cf3ec0>, <internal.entrypoints.gspl.LazyInstance_ProgressBar object at 0x7d4657c0cd10>, <internal.entrypoints.gspl.LazyInstance_StopDataLoaderCacheThread object at 0x7d4657d26360>, <internal.callbacks.MySaveConfigCallback object at 0x7d4656899010>], 'fast_dev_run': False, 'max_epochs': None, 'min_epochs': None, 'max_steps': 90000, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'overfit_batches': 0.0, 'val_check_interval': None, 'check_val_every_n_epoch': 999999, 'num_sanity_val_steps': 1, 'log_every_n_steps': None, 'enable_checkpointing': False, 'enable_progress_bar': None, 'enable_model_summary': None, 'accumulate_grad_batches': 1, 'gradient_clip_val': None, 'gradient_clip_algorithm': None, 'deterministic': None, 'benchmark': None, 'inference_mode': True, 'use_distributed_sampler': False, 'profiler': None, 'detect_anomaly': False, 'barebones': False, 'plugins': None, 'sync_batchnorm': False, 'reload_dataloaders_every_n_epochs': 0, 'default_root_dir': None, 'model_registry': None, '__class__': <class 'lightning.pytorch.trainer.trainer.Trainer'>}
2025-07-23 14:26:50,042 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: trainer fit stage
2025-07-23 14:26:50,043 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_callbacks
2025-07-23 14:26:50,043 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: setting up strategy environment
2025-07-23 14:26:50,154 - lightning.pytorch.utilities.rank_zero - INFO - ----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 4 processes
----------------------------------------------------------------------------------------------------

2025-07-23 14:26:50,165 - lightning.pytorch.utilities.rank_zero - INFO - You are using a CUDA device ('NVIDIA GeForce RTX 3090 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
2025-07-23 14:26:50,680 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: preparing data
2025-07-23 14:26:50,719 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: preparing data
2025-07-23 14:26:50,729 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: preparing data
2025-07-23 14:26:50,730 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: preparing data
2025-07-23 14:26:53,298 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: setup
2025-07-23 14:26:53,298 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: setup
2025-07-23 14:26:53,298 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: setup
2025-07-23 14:26:53,298 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: setup
2025-07-23 14:26:58,569 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: setup
2025-07-23 14:26:58,577 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: setup
2025-07-23 14:26:59,104 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: setup
2025-07-23 14:27:15,095 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: setup
2025-07-23 14:27:15,767 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: setup
2025-07-23 14:27:15,768 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: setup
2025-07-23 14:27:15,768 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: setup
2025-07-23 14:27:15,769 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: setup
2025-07-23 14:27:17,756 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: configuring model
2025-07-23 14:27:17,757 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring module and callbacks from checkpoint path: None
2025-07-23 14:27:17,757 - lightning.pytorch.trainer.connectors.checkpoint_connector - DEBUG - `checkpoint_path` not specified. Skipping checkpoint loading.
2025-07-23 14:27:18,097 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
2025-07-23 14:27:18,098 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_optimizers
2025-07-23 14:27:18,104 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_fit_start
2025-07-23 14:27:18,104 - lightning.pytorch.callbacks.model_summary - INFO - 
  | Name               | Type                                    | Params | Mode 
---------------------------------------------------------------------------------------
0 | gaussian_model     | VanillaGaussianModel                    | 62.2 M | train
1 | renderer           | GSplatDistributedRendererImpl           | 0      | train
2 | density_controller | DistributedVanillaDensityControllerImpl | 0      | train
3 | metric             | HasInverseDepthMetricsModule            | 0      | train
---------------------------------------------------------------------------------------
62.2 M    Trainable params
0         Non-trainable params
62.2 M    Total params
248.743   Total estimated model params size (MB)
6         Modules in train mode
0         Modules in eval mode
2025-07-23 14:27:18,105 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_fit_start
2025-07-23 14:27:18,107 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring training state
2025-07-23 14:29:07,781 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: Initializing trainer with parameters: {'self': <lightning.pytorch.trainer.trainer.Trainer object at 0x74a4ae7b9b50>, 'accelerator': 'gpu', 'strategy': <internal.mp_strategy.MPStrategy object at 0x74a4af6fe990>, 'devices': '2,4', 'num_nodes': 1, 'precision': None, 'logger': <lightning.pytorch.loggers.wandb.WandbLogger object at 0x74a4af728140>, 'callbacks': [<internal.entrypoints.gspl.LazyInstance_SaveGaussian object at 0x74a4afbae660>, <internal.entrypoints.gspl.LazyInstance_ValidateOnTrainEnd object at 0x74a68f51cb00>, <internal.entrypoints.gspl.LazyInstance_KeepRunningIfWebViewerEnabled object at 0x74a4bb1960f0>, <internal.entrypoints.gspl.LazyInstance_StopImageSavingThreads object at 0x74a4bb1961e0>, <internal.entrypoints.gspl.LazyInstance_ProgressBar object at 0x74a4afb2fd10>, <internal.entrypoints.gspl.LazyInstance_StopDataLoaderCacheThread object at 0x74a4afd7ff80>, <internal.callbacks.MySaveConfigCallback object at 0x74a4af95aba0>], 'fast_dev_run': False, 'max_epochs': None, 'min_epochs': None, 'max_steps': 90000, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'overfit_batches': 0.0, 'val_check_interval': None, 'check_val_every_n_epoch': 999999, 'num_sanity_val_steps': 1, 'log_every_n_steps': None, 'enable_checkpointing': False, 'enable_progress_bar': None, 'enable_model_summary': None, 'accumulate_grad_batches': 1, 'gradient_clip_val': None, 'gradient_clip_algorithm': None, 'deterministic': None, 'benchmark': None, 'inference_mode': True, 'use_distributed_sampler': False, 'profiler': None, 'detect_anomaly': False, 'barebones': False, 'plugins': None, 'sync_batchnorm': False, 'reload_dataloaders_every_n_epochs': 0, 'default_root_dir': None, 'model_registry': None, '__class__': <class 'lightning.pytorch.trainer.trainer.Trainer'>}
2025-07-23 14:29:07,847 - lightning.pytorch.utilities.rank_zero - INFO - GPU available: True (cuda), used: True
2025-07-23 14:29:07,848 - lightning.pytorch.utilities.rank_zero - INFO - TPU available: False, using: 0 TPU cores
2025-07-23 14:29:07,848 - lightning.pytorch.utilities.rank_zero - INFO - HPU available: False, using: 0 HPUs
2025-07-23 14:29:07,923 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: trainer fit stage
2025-07-23 14:29:07,923 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_callbacks
2025-07-23 14:29:07,924 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: setting up strategy environment
2025-07-23 14:29:15,126 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: Initializing trainer with parameters: {'self': <lightning.pytorch.trainer.trainer.Trainer object at 0x77ede8b368d0>, 'accelerator': 'gpu', 'strategy': <internal.mp_strategy.MPStrategy object at 0x77ede8a9da00>, 'devices': '2,4', 'num_nodes': 1, 'precision': None, 'logger': <lightning.pytorch.loggers.wandb.WandbLogger object at 0x77ede8507500>, 'callbacks': [<internal.entrypoints.gspl.LazyInstance_SaveGaussian object at 0x77ede909fef0>, <internal.entrypoints.gspl.LazyInstance_ValidateOnTrainEnd object at 0x77edf46ce300>, <internal.entrypoints.gspl.LazyInstance_KeepRunningIfWebViewerEnabled object at 0x77edf499caa0>, <internal.entrypoints.gspl.LazyInstance_StopImageSavingThreads object at 0x77ede8fdcb30>, <internal.entrypoints.gspl.LazyInstance_ProgressBar object at 0x77ede92b3ad0>, <internal.entrypoints.gspl.LazyInstance_StopDataLoaderCacheThread object at 0x77edf46cff80>, <internal.callbacks.MySaveConfigCallback object at 0x77ede8cd1c10>], 'fast_dev_run': False, 'max_epochs': None, 'min_epochs': None, 'max_steps': 90000, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'overfit_batches': 0.0, 'val_check_interval': None, 'check_val_every_n_epoch': 999999, 'num_sanity_val_steps': 1, 'log_every_n_steps': None, 'enable_checkpointing': False, 'enable_progress_bar': None, 'enable_model_summary': None, 'accumulate_grad_batches': 1, 'gradient_clip_val': None, 'gradient_clip_algorithm': None, 'deterministic': None, 'benchmark': None, 'inference_mode': True, 'use_distributed_sampler': False, 'profiler': None, 'detect_anomaly': False, 'barebones': False, 'plugins': None, 'sync_batchnorm': False, 'reload_dataloaders_every_n_epochs': 0, 'default_root_dir': None, 'model_registry': None, '__class__': <class 'lightning.pytorch.trainer.trainer.Trainer'>}
2025-07-23 14:29:15,221 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: trainer fit stage
2025-07-23 14:29:15,222 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_callbacks
2025-07-23 14:29:15,223 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: setting up strategy environment
2025-07-23 14:29:15,278 - lightning.pytorch.utilities.rank_zero - INFO - ----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 2 processes
----------------------------------------------------------------------------------------------------

2025-07-23 14:29:15,323 - lightning.pytorch.utilities.rank_zero - INFO - You are using a CUDA device ('NVIDIA GeForce RTX 3090 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
2025-07-23 14:29:15,919 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: preparing data
2025-07-23 14:29:15,950 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: preparing data
2025-07-23 14:29:18,489 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: setup
2025-07-23 14:29:18,489 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: setup
2025-07-23 14:29:20,976 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: setup
2025-07-23 14:29:32,066 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: setup
2025-07-23 14:29:32,619 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: setup
2025-07-23 14:29:32,619 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: setup
2025-07-23 14:29:34,394 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: configuring model
2025-07-23 14:29:34,394 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: configuring model
2025-07-23 14:29:34,395 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring module and callbacks from checkpoint path: None
2025-07-23 14:29:34,395 - lightning.pytorch.trainer.connectors.checkpoint_connector - DEBUG - `checkpoint_path` not specified. Skipping checkpoint loading.
2025-07-23 14:29:34,395 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring module and callbacks from checkpoint path: None
2025-07-23 14:29:34,395 - lightning.pytorch.trainer.connectors.checkpoint_connector - DEBUG - `checkpoint_path` not specified. Skipping checkpoint loading.
2025-07-23 14:29:34,753 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
2025-07-23 14:29:34,754 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_optimizers
2025-07-23 14:29:34,758 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_fit_start
2025-07-23 14:29:34,759 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_fit_start
2025-07-23 14:29:34,760 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring training state
2025-07-23 14:29:34,821 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
2025-07-23 14:29:34,822 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_optimizers
2025-07-23 14:29:34,825 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_fit_start
2025-07-23 14:29:34,826 - lightning.pytorch.callbacks.model_summary - INFO - 
  | Name               | Type                                    | Params | Mode 
---------------------------------------------------------------------------------------
0 | gaussian_model     | VanillaGaussianModel                    | 124 M  | train
1 | renderer           | GSplatDistributedRendererImpl           | 0      | train
2 | density_controller | DistributedVanillaDensityControllerImpl | 0      | train
3 | metric             | HasInverseDepthMetricsModule            | 0      | train
---------------------------------------------------------------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
497.487   Total estimated model params size (MB)
6         Modules in train mode
0         Modules in eval mode
2025-07-23 14:29:34,826 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_fit_start
2025-07-23 14:29:34,828 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring training state
2025-07-23 14:29:34,829 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_sanity_check_start
2025-07-23 14:29:34,829 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_sanity_check_start
2025-07-23 14:29:34,831 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: val_dataloader
2025-07-23 14:29:34,832 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: val_dataloader
2025-07-23 14:29:34,883 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_model_eval
2025-07-23 14:29:34,884 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_start
2025-07-23 14:29:34,884 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_start
2025-07-23 14:29:34,884 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: on_validation_start
2025-07-23 14:29:34,884 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_epoch_start
2025-07-23 14:29:34,884 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_epoch_start
2025-07-23 14:29:34,886 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_model_eval
2025-07-23 14:29:34,887 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_start
2025-07-23 14:29:34,887 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_start
2025-07-23 14:29:34,887 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: on_validation_start
2025-07-23 14:29:34,887 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_epoch_start
2025-07-23 14:29:34,887 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_epoch_start
2025-07-23 14:29:35,806 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_before_batch_transfer
2025-07-23 14:29:35,808 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: batch_to_device
2025-07-23 14:29:35,808 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: transfer_batch_to_device
2025-07-23 14:29:35,813 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: on_after_batch_transfer
2025-07-23 14:29:35,814 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_batch_start
2025-07-23 14:29:35,814 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_batch_start
2025-07-23 14:29:35,814 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: validation_step
2025-07-23 14:29:35,885 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_before_batch_transfer
2025-07-23 14:29:35,886 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: batch_to_device
2025-07-23 14:29:35,887 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: transfer_batch_to_device
2025-07-23 14:29:35,891 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: on_after_batch_transfer
2025-07-23 14:29:35,892 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_batch_start
2025-07-23 14:29:35,893 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_batch_start
2025-07-23 14:29:35,893 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: validation_step
2025-07-23 14:41:35,405 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: Initializing trainer with parameters: {'self': <lightning.pytorch.trainer.trainer.Trainer object at 0x71b479c13500>, 'accelerator': 'gpu', 'strategy': <internal.mp_strategy.MPStrategy object at 0x71b479cbb6e0>, 'devices': '2,4', 'num_nodes': 1, 'precision': None, 'logger': <lightning.pytorch.loggers.wandb.WandbLogger object at 0x71b478d5d280>, 'callbacks': [<internal.entrypoints.gspl.LazyInstance_SaveGaussian object at 0x71b479e973e0>, <internal.entrypoints.gspl.LazyInstance_ValidateOnTrainEnd object at 0x71b659a19490>, <internal.entrypoints.gspl.LazyInstance_KeepRunningIfWebViewerEnabled object at 0x71b47a197b30>, <internal.entrypoints.gspl.LazyInstance_StopImageSavingThreads object at 0x71b47a1ccef0>, <internal.entrypoints.gspl.LazyInstance_ProgressBar object at 0x71b47a1cfe90>, <internal.entrypoints.gspl.LazyInstance_StopDataLoaderCacheThread object at 0x71b47a36a600>, <internal.callbacks.MySaveConfigCallback object at 0x71b479c13530>], 'fast_dev_run': False, 'max_epochs': None, 'min_epochs': None, 'max_steps': 90000, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'overfit_batches': 0.0, 'val_check_interval': None, 'check_val_every_n_epoch': 999999, 'num_sanity_val_steps': 1, 'log_every_n_steps': None, 'enable_checkpointing': False, 'enable_progress_bar': None, 'enable_model_summary': None, 'accumulate_grad_batches': 1, 'gradient_clip_val': None, 'gradient_clip_algorithm': None, 'deterministic': None, 'benchmark': None, 'inference_mode': True, 'use_distributed_sampler': False, 'profiler': None, 'detect_anomaly': False, 'barebones': False, 'plugins': None, 'sync_batchnorm': False, 'reload_dataloaders_every_n_epochs': 0, 'default_root_dir': None, 'model_registry': None, '__class__': <class 'lightning.pytorch.trainer.trainer.Trainer'>}
2025-07-23 14:41:35,546 - lightning.pytorch.utilities.rank_zero - INFO - GPU available: True (cuda), used: True
2025-07-23 14:41:35,548 - lightning.pytorch.utilities.rank_zero - INFO - TPU available: False, using: 0 TPU cores
2025-07-23 14:41:35,548 - lightning.pytorch.utilities.rank_zero - INFO - HPU available: False, using: 0 HPUs
2025-07-23 14:41:35,864 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: trainer fit stage
2025-07-23 14:41:35,865 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_callbacks
2025-07-23 14:41:35,865 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: setting up strategy environment
2025-07-23 14:42:05,483 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: Initializing trainer with parameters: {'self': <lightning.pytorch.trainer.trainer.Trainer object at 0x76c0ba779b80>, 'accelerator': 'gpu', 'strategy': <internal.mp_strategy.MPStrategy object at 0x76c0ba9799a0>, 'devices': '2,4', 'num_nodes': 1, 'precision': None, 'logger': <lightning.pytorch.loggers.wandb.WandbLogger object at 0x76c0ba8bb2c0>, 'callbacks': [<internal.entrypoints.gspl.LazyInstance_SaveGaussian object at 0x76c0bacbfef0>, <internal.entrypoints.gspl.LazyInstance_ValidateOnTrainEnd object at 0x76c0c6bcff20>, <internal.entrypoints.gspl.LazyInstance_KeepRunningIfWebViewerEnabled object at 0x76c0c6e7fb30>, <internal.entrypoints.gspl.LazyInstance_StopImageSavingThreads object at 0x76c0bad9f950>, <internal.entrypoints.gspl.LazyInstance_ProgressBar object at 0x76c0bb0a39b0>, <internal.entrypoints.gspl.LazyInstance_StopDataLoaderCacheThread object at 0x76c0c6cc6ff0>, <internal.callbacks.MySaveConfigCallback object at 0x76c0ba8b8c80>], 'fast_dev_run': False, 'max_epochs': None, 'min_epochs': None, 'max_steps': 90000, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'overfit_batches': 0.0, 'val_check_interval': None, 'check_val_every_n_epoch': 999999, 'num_sanity_val_steps': 1, 'log_every_n_steps': None, 'enable_checkpointing': False, 'enable_progress_bar': None, 'enable_model_summary': None, 'accumulate_grad_batches': 1, 'gradient_clip_val': None, 'gradient_clip_algorithm': None, 'deterministic': None, 'benchmark': None, 'inference_mode': True, 'use_distributed_sampler': False, 'profiler': None, 'detect_anomaly': False, 'barebones': False, 'plugins': None, 'sync_batchnorm': False, 'reload_dataloaders_every_n_epochs': 0, 'default_root_dir': None, 'model_registry': None, '__class__': <class 'lightning.pytorch.trainer.trainer.Trainer'>}
2025-07-23 14:42:05,676 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: trainer fit stage
2025-07-23 14:42:05,678 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_callbacks
2025-07-23 14:42:05,679 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: setting up strategy environment
2025-07-23 14:42:05,825 - lightning.pytorch.utilities.rank_zero - INFO - ----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 2 processes
----------------------------------------------------------------------------------------------------

2025-07-23 14:42:05,982 - lightning.pytorch.utilities.rank_zero - INFO - You are using a CUDA device ('NVIDIA GeForce RTX 3090 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
2025-07-23 14:42:07,894 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: preparing data
2025-07-23 14:42:07,990 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: preparing data
2025-07-23 14:42:11,323 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: setup
2025-07-23 14:42:11,323 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: setup
2025-07-23 14:42:21,334 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: setup
2025-07-23 14:43:01,549 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: setup
2025-07-23 14:43:02,744 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: setup
2025-07-23 14:43:02,749 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: setup
2025-07-23 14:43:06,807 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: configuring model
2025-07-23 14:43:06,807 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring module and callbacks from checkpoint path: None
2025-07-23 14:43:06,808 - lightning.pytorch.trainer.connectors.checkpoint_connector - DEBUG - `checkpoint_path` not specified. Skipping checkpoint loading.
2025-07-23 14:43:06,976 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: configuring model
2025-07-23 14:43:06,979 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring module and callbacks from checkpoint path: None
2025-07-23 14:43:06,980 - lightning.pytorch.trainer.connectors.checkpoint_connector - DEBUG - `checkpoint_path` not specified. Skipping checkpoint loading.
2025-07-23 14:43:08,174 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
2025-07-23 14:43:08,178 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_optimizers
2025-07-23 14:43:08,189 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_fit_start
2025-07-23 14:43:08,191 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_fit_start
2025-07-23 14:43:08,193 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring training state
2025-07-23 14:43:08,248 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
2025-07-23 14:43:08,254 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_optimizers
2025-07-23 14:43:08,272 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_fit_start
2025-07-23 14:43:08,276 - lightning.pytorch.callbacks.model_summary - INFO - 
  | Name               | Type                                    | Params | Mode 
---------------------------------------------------------------------------------------
0 | gaussian_model     | VanillaGaussianModel                    | 124 M  | train
1 | renderer           | GSplatDistributedRendererImpl           | 0      | train
2 | density_controller | DistributedVanillaDensityControllerImpl | 0      | train
3 | metric             | HasInverseDepthMetricsModule            | 0      | train
---------------------------------------------------------------------------------------
124 M     Trainable params
0         Non-trainable params
124 M     Total params
497.487   Total estimated model params size (MB)
6         Modules in train mode
0         Modules in eval mode
2025-07-23 14:43:08,279 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_fit_start
2025-07-23 14:43:08,289 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring training state
2025-07-23 14:43:08,296 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_sanity_check_start
2025-07-23 14:43:08,297 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_sanity_check_start
2025-07-23 14:43:08,303 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: val_dataloader
2025-07-23 14:43:08,310 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: val_dataloader
2025-07-23 14:43:08,448 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_model_eval
2025-07-23 14:43:08,449 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_start
2025-07-23 14:43:08,450 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_start
2025-07-23 14:43:08,450 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: on_validation_start
2025-07-23 14:43:08,451 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_epoch_start
2025-07-23 14:43:08,451 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_epoch_start
2025-07-23 14:43:08,451 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_model_eval
2025-07-23 14:43:08,452 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_start
2025-07-23 14:43:08,453 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_start
2025-07-23 14:43:08,455 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: on_validation_start
2025-07-23 14:43:08,456 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_epoch_start
2025-07-23 14:43:08,457 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_epoch_start
2025-07-23 14:43:12,141 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_before_batch_transfer
2025-07-23 14:43:12,147 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: batch_to_device
2025-07-23 14:43:12,149 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: transfer_batch_to_device
2025-07-23 14:43:12,162 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: on_after_batch_transfer
2025-07-23 14:43:12,164 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_batch_start
2025-07-23 14:43:12,165 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_batch_start
2025-07-23 14:43:12,167 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: validation_step
2025-07-23 14:43:12,247 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_before_batch_transfer
2025-07-23 14:43:12,249 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: batch_to_device
2025-07-23 14:43:12,250 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: transfer_batch_to_device
2025-07-23 14:43:12,264 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: on_after_batch_transfer
2025-07-23 14:43:12,267 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_batch_start
2025-07-23 14:43:12,278 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_batch_start
2025-07-23 14:43:12,280 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: validation_step
2025-07-23 14:57:56,940 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: Initializing trainer with parameters: {'self': <lightning.pytorch.trainer.trainer.Trainer object at 0x725b629bdfa0>, 'accelerator': 'gpu', 'strategy': <internal.mp_strategy.MPStrategy object at 0x725b62aec650>, 'devices': -1, 'num_nodes': 1, 'precision': None, 'logger': <lightning.pytorch.loggers.tensorboard.TensorBoardLogger object at 0x725b62a76c00>, 'callbacks': [<internal.entrypoints.gspl.LazyInstance_SaveGaussian object at 0x725b6e900140>, <internal.entrypoints.gspl.LazyInstance_ValidateOnTrainEnd object at 0x725b63011130>, <internal.entrypoints.gspl.LazyInstance_KeepRunningIfWebViewerEnabled object at 0x725b632366f0>, <internal.entrypoints.gspl.LazyInstance_StopImageSavingThreads object at 0x725b63267230>, <internal.entrypoints.gspl.LazyInstance_ProgressBar object at 0x725b62eef410>, <internal.entrypoints.gspl.LazyInstance_StopDataLoaderCacheThread object at 0x725b630edb80>, <internal.callbacks.MySaveConfigCallback object at 0x725b62ac8d40>], 'fast_dev_run': False, 'max_epochs': None, 'min_epochs': None, 'max_steps': 30000, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'overfit_batches': 0.0, 'val_check_interval': None, 'check_val_every_n_epoch': 1, 'num_sanity_val_steps': 1, 'log_every_n_steps': None, 'enable_checkpointing': False, 'enable_progress_bar': None, 'enable_model_summary': None, 'accumulate_grad_batches': 1, 'gradient_clip_val': None, 'gradient_clip_algorithm': None, 'deterministic': None, 'benchmark': None, 'inference_mode': True, 'use_distributed_sampler': False, 'profiler': None, 'detect_anomaly': False, 'barebones': False, 'plugins': None, 'sync_batchnorm': False, 'reload_dataloaders_every_n_epochs': 0, 'default_root_dir': None, 'model_registry': None, '__class__': <class 'lightning.pytorch.trainer.trainer.Trainer'>}
2025-07-23 14:57:57,022 - lightning.pytorch.utilities.rank_zero - INFO - GPU available: True (cuda), used: True
2025-07-23 14:57:57,023 - lightning.pytorch.utilities.rank_zero - INFO - TPU available: False, using: 0 TPU cores
2025-07-23 14:57:57,023 - lightning.pytorch.utilities.rank_zero - INFO - HPU available: False, using: 0 HPUs
2025-07-23 14:57:57,158 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: trainer fit stage
2025-07-23 14:57:57,159 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_callbacks
2025-07-23 14:57:57,160 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: setting up strategy environment
2025-07-23 14:58:06,498 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: Initializing trainer with parameters: {'self': <lightning.pytorch.trainer.trainer.Trainer object at 0x7931b76cd550>, 'accelerator': 'gpu', 'strategy': <internal.mp_strategy.MPStrategy object at 0x7931b74e5280>, 'devices': -1, 'num_nodes': 1, 'precision': None, 'logger': <lightning.pytorch.loggers.tensorboard.TensorBoardLogger object at 0x7931b74c0950>, 'callbacks': [<internal.entrypoints.gspl.LazyInstance_SaveGaussian object at 0x7931b7a06a50>, <internal.entrypoints.gspl.LazyInstance_ValidateOnTrainEnd object at 0x7933973a8e00>, <internal.entrypoints.gspl.LazyInstance_KeepRunningIfWebViewerEnabled object at 0x7931b7945130>, <internal.entrypoints.gspl.LazyInstance_StopImageSavingThreads object at 0x7931b79ab9e0>, <internal.entrypoints.gspl.LazyInstance_ProgressBar object at 0x7931b7a96000>, <internal.entrypoints.gspl.LazyInstance_StopDataLoaderCacheThread object at 0x7931b7c323c0>, <internal.callbacks.MySaveConfigCallback object at 0x7931b76cd4f0>], 'fast_dev_run': False, 'max_epochs': None, 'min_epochs': None, 'max_steps': 30000, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'overfit_batches': 0.0, 'val_check_interval': None, 'check_val_every_n_epoch': 1, 'num_sanity_val_steps': 1, 'log_every_n_steps': None, 'enable_checkpointing': False, 'enable_progress_bar': None, 'enable_model_summary': None, 'accumulate_grad_batches': 1, 'gradient_clip_val': None, 'gradient_clip_algorithm': None, 'deterministic': None, 'benchmark': None, 'inference_mode': True, 'use_distributed_sampler': False, 'profiler': None, 'detect_anomaly': False, 'barebones': False, 'plugins': None, 'sync_batchnorm': False, 'reload_dataloaders_every_n_epochs': 0, 'default_root_dir': None, 'model_registry': None, '__class__': <class 'lightning.pytorch.trainer.trainer.Trainer'>}
2025-07-23 14:58:06,580 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: trainer fit stage
2025-07-23 14:58:06,580 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_callbacks
2025-07-23 14:58:06,581 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: setting up strategy environment
2025-07-23 14:58:06,710 - lightning.pytorch.utilities.rank_zero - INFO - ----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 2 processes
----------------------------------------------------------------------------------------------------

2025-07-23 14:58:06,715 - lightning.pytorch.utilities.rank_zero - INFO - You are using a CUDA device ('NVIDIA GeForce RTX 3090 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
2025-07-23 14:58:07,400 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: preparing data
2025-07-23 14:58:07,448 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: preparing data
2025-07-23 14:58:07,459 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: setup
2025-07-23 14:58:07,459 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: setup
2025-07-23 14:58:10,925 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: setup
2025-07-23 14:58:11,541 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: setup
2025-07-23 14:58:11,704 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: setup
2025-07-23 14:58:11,706 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: setup
2025-07-23 14:58:13,550 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: configuring model
2025-07-23 14:58:13,550 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: configuring model
2025-07-23 14:58:13,550 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring module and callbacks from checkpoint path: None
2025-07-23 14:58:13,550 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring module and callbacks from checkpoint path: None
2025-07-23 14:58:13,550 - lightning.pytorch.trainer.connectors.checkpoint_connector - DEBUG - `checkpoint_path` not specified. Skipping checkpoint loading.
2025-07-23 14:58:13,550 - lightning.pytorch.trainer.connectors.checkpoint_connector - DEBUG - `checkpoint_path` not specified. Skipping checkpoint loading.
2025-07-23 14:58:13,567 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [6,7]
2025-07-23 14:58:13,568 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_optimizers
2025-07-23 14:58:13,570 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [6,7]
2025-07-23 14:58:13,571 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_fit_start
2025-07-23 14:58:13,571 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_optimizers
2025-07-23 14:58:13,572 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_fit_start
2025-07-23 14:58:13,572 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring training state
2025-07-23 14:58:13,573 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_fit_start
2025-07-23 14:58:13,574 - lightning.pytorch.callbacks.model_summary - INFO - 
  | Name               | Type                                    | Params | Mode 
---------------------------------------------------------------------------------------
0 | gaussian_model     | VanillaGaussianModel                    | 4.0 M  | train
1 | renderer           | GSplatDistributedRendererImpl           | 0      | train
2 | density_controller | DistributedVanillaDensityControllerImpl | 0      | train
3 | metric             | VanillaMetricsImpl                      | 0      | train
---------------------------------------------------------------------------------------
4.0 M     Trainable params
0         Non-trainable params
4.0 M     Total params
16.051    Total estimated model params size (MB)
6         Modules in train mode
0         Modules in eval mode
2025-07-23 14:58:13,574 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_fit_start
2025-07-23 14:58:13,917 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring training state
2025-07-23 14:58:13,919 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_sanity_check_start
2025-07-23 14:58:13,919 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_sanity_check_start
2025-07-23 14:58:13,920 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: val_dataloader
2025-07-23 14:58:13,924 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: val_dataloader
2025-07-23 14:58:14,420 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_model_eval
2025-07-23 14:58:14,421 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_start
2025-07-23 14:58:14,421 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_start
2025-07-23 14:58:14,421 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: on_validation_start
2025-07-23 14:58:14,421 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_epoch_start
2025-07-23 14:58:14,421 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_model_eval
2025-07-23 14:58:14,421 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_epoch_start
2025-07-23 14:58:14,422 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_before_batch_transfer
2025-07-23 14:58:14,422 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_start
2025-07-23 14:58:14,422 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: batch_to_device
2025-07-23 14:58:14,422 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: transfer_batch_to_device
2025-07-23 14:58:14,422 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_start
2025-07-23 14:58:14,422 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: on_validation_start
2025-07-23 14:58:14,422 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_epoch_start
2025-07-23 14:58:14,422 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_epoch_start
2025-07-23 14:58:14,423 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_before_batch_transfer
2025-07-23 14:58:14,423 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: batch_to_device
2025-07-23 14:58:14,423 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: transfer_batch_to_device
2025-07-23 14:58:14,424 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: on_after_batch_transfer
2025-07-23 14:58:14,424 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_batch_start
2025-07-23 14:58:14,424 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_batch_start
2025-07-23 14:58:14,425 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: validation_step
2025-07-23 14:58:14,425 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: on_after_batch_transfer
2025-07-23 14:58:14,426 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_batch_start
2025-07-23 14:58:14,426 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_batch_start
2025-07-23 14:58:14,426 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: validation_step
2025-07-23 15:03:25,327 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: Initializing trainer with parameters: {'self': <lightning.pytorch.trainer.trainer.Trainer object at 0x74ef321116d0>, 'accelerator': 'gpu', 'strategy': <internal.mp_strategy.MPStrategy object at 0x74ef3216ded0>, 'devices': -1, 'num_nodes': 1, 'precision': None, 'logger': <lightning.pytorch.loggers.tensorboard.TensorBoardLogger object at 0x74ef32223610>, 'callbacks': [<internal.entrypoints.gspl.LazyInstance_SaveGaussian object at 0x74f2dfbc6b10>, <internal.entrypoints.gspl.LazyInstance_ValidateOnTrainEnd object at 0x74ef323dd950>, <internal.entrypoints.gspl.LazyInstance_KeepRunningIfWebViewerEnabled object at 0x74ef32235350>, <internal.entrypoints.gspl.LazyInstance_StopImageSavingThreads object at 0x74ef322372d0>, <internal.entrypoints.gspl.LazyInstance_ProgressBar object at 0x74ef323a9210>, <internal.entrypoints.gspl.LazyInstance_StopDataLoaderCacheThread object at 0x74ef323abb50>, <internal.callbacks.MySaveConfigCallback object at 0x74ef3cde3090>], 'fast_dev_run': False, 'max_epochs': None, 'min_epochs': None, 'max_steps': 30000, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'overfit_batches': 0.0, 'val_check_interval': None, 'check_val_every_n_epoch': 1, 'num_sanity_val_steps': 1, 'log_every_n_steps': None, 'enable_checkpointing': False, 'enable_progress_bar': None, 'enable_model_summary': None, 'accumulate_grad_batches': 1, 'gradient_clip_val': None, 'gradient_clip_algorithm': None, 'deterministic': None, 'benchmark': None, 'inference_mode': True, 'use_distributed_sampler': False, 'profiler': None, 'detect_anomaly': False, 'barebones': False, 'plugins': None, 'sync_batchnorm': False, 'reload_dataloaders_every_n_epochs': 0, 'default_root_dir': None, 'model_registry': None, '__class__': <class 'lightning.pytorch.trainer.trainer.Trainer'>}
2025-07-23 15:03:25,412 - lightning.pytorch.utilities.rank_zero - INFO - GPU available: True (cuda), used: True
2025-07-23 15:03:25,413 - lightning.pytorch.utilities.rank_zero - INFO - TPU available: False, using: 0 TPU cores
2025-07-23 15:03:25,413 - lightning.pytorch.utilities.rank_zero - INFO - HPU available: False, using: 0 HPUs
2025-07-23 15:03:25,992 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: trainer fit stage
2025-07-23 15:03:25,993 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_callbacks
2025-07-23 15:03:25,993 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: setting up strategy environment
2025-07-23 15:03:36,778 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: Initializing trainer with parameters: {'self': <lightning.pytorch.trainer.trainer.Trainer object at 0x7c6470acbb10>, 'accelerator': 'gpu', 'strategy': <internal.mp_strategy.MPStrategy object at 0x7c64706fbc90>, 'devices': -1, 'num_nodes': 1, 'precision': None, 'logger': <lightning.pytorch.loggers.tensorboard.TensorBoardLogger object at 0x7c6470882950>, 'callbacks': [<internal.entrypoints.gspl.LazyInstance_SaveGaussian object at 0x7c6470f43250>, <internal.entrypoints.gspl.LazyInstance_ValidateOnTrainEnd object at 0x7c6470a06d90>, <internal.entrypoints.gspl.LazyInstance_KeepRunningIfWebViewerEnabled object at 0x7c6470a1cc50>, <internal.entrypoints.gspl.LazyInstance_StopImageSavingThreads object at 0x7c6470a1ea50>, <internal.entrypoints.gspl.LazyInstance_ProgressBar object at 0x7c6470a24950>, <internal.entrypoints.gspl.LazyInstance_StopDataLoaderCacheThread object at 0x7c6470a27390>, <internal.callbacks.MySaveConfigCallback object at 0x7c6470a69250>], 'fast_dev_run': False, 'max_epochs': None, 'min_epochs': None, 'max_steps': 30000, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'overfit_batches': 0.0, 'val_check_interval': None, 'check_val_every_n_epoch': 1, 'num_sanity_val_steps': 1, 'log_every_n_steps': None, 'enable_checkpointing': False, 'enable_progress_bar': None, 'enable_model_summary': None, 'accumulate_grad_batches': 1, 'gradient_clip_val': None, 'gradient_clip_algorithm': None, 'deterministic': None, 'benchmark': None, 'inference_mode': True, 'use_distributed_sampler': False, 'profiler': None, 'detect_anomaly': False, 'barebones': False, 'plugins': None, 'sync_batchnorm': False, 'reload_dataloaders_every_n_epochs': 0, 'default_root_dir': None, 'model_registry': None, '__class__': <class 'lightning.pytorch.trainer.trainer.Trainer'>}
2025-07-23 15:03:36,870 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: trainer fit stage
2025-07-23 15:03:36,870 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_callbacks
2025-07-23 15:03:36,871 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: setting up strategy environment
2025-07-23 15:03:37,049 - lightning.pytorch.utilities.rank_zero - INFO - ----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 2 processes
----------------------------------------------------------------------------------------------------

2025-07-23 15:03:37,055 - lightning.pytorch.utilities.rank_zero - INFO - You are using a CUDA device ('NVIDIA GeForce RTX 3090 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
2025-07-23 15:03:37,751 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: preparing data
2025-07-23 15:03:37,811 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: preparing data
2025-07-23 15:03:37,817 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: setup
2025-07-23 15:03:37,817 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: setup
2025-07-23 15:03:41,356 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: setup
2025-07-23 15:03:42,191 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: setup
2025-07-23 15:03:42,354 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: setup
2025-07-23 15:03:42,355 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: setup
2025-07-23 15:03:44,608 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: configuring model
2025-07-23 15:03:44,608 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring module and callbacks from checkpoint path: None
2025-07-23 15:03:44,608 - lightning.pytorch.trainer.connectors.checkpoint_connector - DEBUG - `checkpoint_path` not specified. Skipping checkpoint loading.
2025-07-23 15:03:44,609 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: configuring model
2025-07-23 15:03:44,609 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring module and callbacks from checkpoint path: None
2025-07-23 15:03:44,609 - lightning.pytorch.trainer.connectors.checkpoint_connector - DEBUG - `checkpoint_path` not specified. Skipping checkpoint loading.
2025-07-23 15:03:44,633 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [6,7]
2025-07-23 15:03:44,637 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [6,7]
2025-07-23 15:03:44,639 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_optimizers
2025-07-23 15:03:44,639 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_optimizers
2025-07-23 15:03:44,695 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_fit_start
2025-07-23 15:03:44,696 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_fit_start
2025-07-23 15:03:44,697 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_fit_start
2025-07-23 15:03:44,697 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring training state
2025-07-23 15:03:44,697 - lightning.pytorch.callbacks.model_summary - INFO - 
  | Name               | Type                                    | Params | Mode 
---------------------------------------------------------------------------------------
0 | gaussian_model     | VanillaGaussianModel                    | 4.0 M  | train
1 | renderer           | GSplatDistributedRendererImpl           | 0      | train
2 | density_controller | DistributedVanillaDensityControllerImpl | 0      | train
3 | metric             | VanillaMetricsImpl                      | 0      | train
---------------------------------------------------------------------------------------
4.0 M     Trainable params
0         Non-trainable params
4.0 M     Total params
16.051    Total estimated model params size (MB)
6         Modules in train mode
0         Modules in eval mode
2025-07-23 15:03:44,697 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_fit_start
2025-07-23 15:03:44,772 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring training state
2025-07-23 15:03:44,774 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_sanity_check_start
2025-07-23 15:03:44,775 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_sanity_check_start
2025-07-23 15:03:44,775 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: val_dataloader
2025-07-23 15:03:44,776 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: val_dataloader
2025-07-23 15:03:45,581 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_model_eval
2025-07-23 15:03:45,582 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_start
2025-07-23 15:03:45,582 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_start
2025-07-23 15:03:45,582 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: on_validation_start
2025-07-23 15:03:45,582 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_epoch_start
2025-07-23 15:03:45,582 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_epoch_start
2025-07-23 15:03:45,583 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_before_batch_transfer
2025-07-23 15:03:45,583 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: batch_to_device
2025-07-23 15:03:45,583 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: transfer_batch_to_device
2025-07-23 15:03:45,585 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_model_eval
2025-07-23 15:03:45,586 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: on_after_batch_transfer
2025-07-23 15:03:45,586 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_batch_start
2025-07-23 15:03:45,586 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_start
2025-07-23 15:03:45,586 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_batch_start
2025-07-23 15:03:45,586 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_start
2025-07-23 15:03:45,586 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: validation_step
2025-07-23 15:03:45,586 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: on_validation_start
2025-07-23 15:03:45,586 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_epoch_start
2025-07-23 15:03:45,587 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_epoch_start
2025-07-23 15:03:45,587 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_before_batch_transfer
2025-07-23 15:03:45,587 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: batch_to_device
2025-07-23 15:03:45,587 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: transfer_batch_to_device
2025-07-23 15:03:45,591 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: on_after_batch_transfer
2025-07-23 15:03:45,591 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_batch_start
2025-07-23 15:03:45,592 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_batch_start
2025-07-23 15:03:45,592 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: validation_step
2025-07-23 15:07:41,315 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: Initializing trainer with parameters: {'self': <lightning.pytorch.trainer.trainer.Trainer object at 0x7fd8c8eeda90>, 'accelerator': 'gpu', 'strategy': <internal.mp_strategy.MPStrategy object at 0x7fd8c8e38d70>, 'devices': -1, 'num_nodes': 1, 'precision': None, 'logger': <lightning.pytorch.loggers.tensorboard.TensorBoardLogger object at 0x7fd8c8cbc1d0>, 'callbacks': [<internal.entrypoints.gspl.LazyInstance_SaveGaussian object at 0x7fdaa8c54b00>, <internal.entrypoints.gspl.LazyInstance_ValidateOnTrainEnd object at 0x7fd8c94fd160>, <internal.entrypoints.gspl.LazyInstance_KeepRunningIfWebViewerEnabled object at 0x7fd8c921cec0>, <internal.entrypoints.gspl.LazyInstance_StopImageSavingThreads object at 0x7fd8c9267c80>, <internal.entrypoints.gspl.LazyInstance_ProgressBar object at 0x7fd8c958a330>, <internal.entrypoints.gspl.LazyInstance_StopDataLoaderCacheThread object at 0x7fd8c92fe660>, <internal.callbacks.MySaveConfigCallback object at 0x7fd8c8eed3d0>], 'fast_dev_run': False, 'max_epochs': None, 'min_epochs': None, 'max_steps': 30000, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'overfit_batches': 0.0, 'val_check_interval': None, 'check_val_every_n_epoch': 1, 'num_sanity_val_steps': 1, 'log_every_n_steps': None, 'enable_checkpointing': False, 'enable_progress_bar': None, 'enable_model_summary': None, 'accumulate_grad_batches': 1, 'gradient_clip_val': None, 'gradient_clip_algorithm': None, 'deterministic': None, 'benchmark': None, 'inference_mode': True, 'use_distributed_sampler': False, 'profiler': None, 'detect_anomaly': False, 'barebones': False, 'plugins': None, 'sync_batchnorm': False, 'reload_dataloaders_every_n_epochs': 0, 'default_root_dir': None, 'model_registry': None, '__class__': <class 'lightning.pytorch.trainer.trainer.Trainer'>}
2025-07-23 15:07:41,405 - lightning.pytorch.utilities.rank_zero - INFO - GPU available: True (cuda), used: True
2025-07-23 15:07:41,406 - lightning.pytorch.utilities.rank_zero - INFO - TPU available: False, using: 0 TPU cores
2025-07-23 15:07:41,406 - lightning.pytorch.utilities.rank_zero - INFO - HPU available: False, using: 0 HPUs
2025-07-23 15:07:41,561 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: trainer fit stage
2025-07-23 15:07:41,562 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_callbacks
2025-07-23 15:07:41,562 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: setting up strategy environment
2025-07-23 15:07:50,735 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: Initializing trainer with parameters: {'self': <lightning.pytorch.trainer.trainer.Trainer object at 0x7e564176dd60>, 'accelerator': 'gpu', 'strategy': <internal.mp_strategy.MPStrategy object at 0x7e56416b8950>, 'devices': -1, 'num_nodes': 1, 'precision': None, 'logger': <lightning.pytorch.loggers.tensorboard.TensorBoardLogger object at 0x7e564169ce90>, 'callbacks': [<internal.entrypoints.gspl.LazyInstance_SaveGaussian object at 0x7e564d4d7bc0>, <internal.entrypoints.gspl.LazyInstance_ValidateOnTrainEnd object at 0x7e564d4a3620>, <internal.entrypoints.gspl.LazyInstance_KeepRunningIfWebViewerEnabled object at 0x7e5641e067b0>, <internal.entrypoints.gspl.LazyInstance_StopImageSavingThreads object at 0x7e564d5dff80>, <internal.entrypoints.gspl.LazyInstance_ProgressBar object at 0x7e56419f7fb0>, <internal.entrypoints.gspl.LazyInstance_StopDataLoaderCacheThread object at 0x7e564d3feae0>, <internal.callbacks.MySaveConfigCallback object at 0x7e5641759df0>], 'fast_dev_run': False, 'max_epochs': None, 'min_epochs': None, 'max_steps': 30000, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'overfit_batches': 0.0, 'val_check_interval': None, 'check_val_every_n_epoch': 1, 'num_sanity_val_steps': 1, 'log_every_n_steps': None, 'enable_checkpointing': False, 'enable_progress_bar': None, 'enable_model_summary': None, 'accumulate_grad_batches': 1, 'gradient_clip_val': None, 'gradient_clip_algorithm': None, 'deterministic': None, 'benchmark': None, 'inference_mode': True, 'use_distributed_sampler': False, 'profiler': None, 'detect_anomaly': False, 'barebones': False, 'plugins': None, 'sync_batchnorm': False, 'reload_dataloaders_every_n_epochs': 0, 'default_root_dir': None, 'model_registry': None, '__class__': <class 'lightning.pytorch.trainer.trainer.Trainer'>}
2025-07-23 15:07:50,819 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: trainer fit stage
2025-07-23 15:07:50,820 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_callbacks
2025-07-23 15:07:50,820 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: setting up strategy environment
2025-07-23 15:07:50,867 - lightning.pytorch.utilities.rank_zero - INFO - ----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 2 processes
----------------------------------------------------------------------------------------------------

2025-07-23 15:07:50,910 - lightning.pytorch.utilities.rank_zero - INFO - You are using a CUDA device ('NVIDIA GeForce RTX 3090 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
2025-07-23 15:07:51,685 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: preparing data
2025-07-23 15:07:51,728 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: preparing data
2025-07-23 15:07:51,739 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: setup
2025-07-23 15:07:51,739 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: setup
2025-07-23 15:07:55,220 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: setup
2025-07-23 15:07:56,076 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: setup
2025-07-23 15:07:56,235 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: setup
2025-07-23 15:07:56,237 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: setup
2025-07-23 15:07:58,070 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: configuring model
2025-07-23 15:07:58,070 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: configuring model
2025-07-23 15:07:58,070 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring module and callbacks from checkpoint path: None
2025-07-23 15:07:58,070 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring module and callbacks from checkpoint path: None
2025-07-23 15:07:58,070 - lightning.pytorch.trainer.connectors.checkpoint_connector - DEBUG - `checkpoint_path` not specified. Skipping checkpoint loading.
2025-07-23 15:07:58,070 - lightning.pytorch.trainer.connectors.checkpoint_connector - DEBUG - `checkpoint_path` not specified. Skipping checkpoint loading.
2025-07-23 15:07:58,091 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [6,7]
2025-07-23 15:07:58,092 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_optimizers
2025-07-23 15:07:58,095 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_fit_start
2025-07-23 15:07:58,095 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [6,7]
2025-07-23 15:07:58,096 - lightning.pytorch.callbacks.model_summary - INFO - 
  | Name               | Type                                    | Params | Mode 
---------------------------------------------------------------------------------------
0 | gaussian_model     | VanillaGaussianModel                    | 4.0 M  | train
1 | renderer           | GSplatDistributedRendererImpl           | 0      | train
2 | density_controller | DistributedVanillaDensityControllerImpl | 0      | train
3 | metric             | VanillaMetricsImpl                      | 0      | train
---------------------------------------------------------------------------------------
4.0 M     Trainable params
0         Non-trainable params
4.0 M     Total params
16.051    Total estimated model params size (MB)
6         Modules in train mode
0         Modules in eval mode
2025-07-23 15:07:58,096 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_fit_start
2025-07-23 15:07:58,097 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_optimizers
2025-07-23 15:07:58,100 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_fit_start
2025-07-23 15:07:58,101 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_fit_start
2025-07-23 15:07:58,101 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring training state
2025-07-23 15:07:58,459 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring training state
2025-07-23 15:07:58,460 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_sanity_check_start
2025-07-23 15:07:58,461 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_sanity_check_start
2025-07-23 15:07:58,462 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: val_dataloader
2025-07-23 15:07:58,462 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: val_dataloader
2025-07-23 15:07:59,002 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_model_eval
2025-07-23 15:07:59,003 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_start
2025-07-23 15:07:59,003 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_start
2025-07-23 15:07:59,003 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: on_validation_start
2025-07-23 15:07:59,003 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_epoch_start
2025-07-23 15:07:59,003 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_epoch_start
2025-07-23 15:07:59,004 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_before_batch_transfer
2025-07-23 15:07:59,004 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: batch_to_device
2025-07-23 15:07:59,004 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: transfer_batch_to_device
2025-07-23 15:07:59,004 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_model_eval
2025-07-23 15:07:59,004 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_start
2025-07-23 15:07:59,005 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_start
2025-07-23 15:07:59,005 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: on_validation_start
2025-07-23 15:07:59,005 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_epoch_start
2025-07-23 15:07:59,005 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_epoch_start
2025-07-23 15:07:59,005 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_before_batch_transfer
2025-07-23 15:07:59,005 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: batch_to_device
2025-07-23 15:07:59,006 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: transfer_batch_to_device
2025-07-23 15:07:59,007 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: on_after_batch_transfer
2025-07-23 15:07:59,007 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_batch_start
2025-07-23 15:07:59,008 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_batch_start
2025-07-23 15:07:59,008 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: validation_step
2025-07-23 15:07:59,009 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: on_after_batch_transfer
2025-07-23 15:07:59,009 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_batch_start
2025-07-23 15:07:59,010 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_batch_start
2025-07-23 15:07:59,010 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: validation_step
2025-07-23 15:29:55,868 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: Initializing trainer with parameters: {'self': <lightning.pytorch.trainer.trainer.Trainer object at 0x7f3f63401f10>, 'accelerator': 'gpu', 'strategy': <internal.mp_strategy.MPStrategy object at 0x7f3ea50e4f50>, 'devices': -1, 'num_nodes': 1, 'precision': None, 'logger': <lightning.pytorch.loggers.tensorboard.TensorBoardLogger object at 0x7f3ea52ec230>, 'callbacks': [<internal.entrypoints.gspl.LazyInstance_SaveGaussian object at 0x7f4084f71670>, <internal.entrypoints.gspl.LazyInstance_ValidateOnTrainEnd object at 0x7f3ea55a3290>, <internal.entrypoints.gspl.LazyInstance_KeepRunningIfWebViewerEnabled object at 0x7f3ea582a330>, <internal.entrypoints.gspl.LazyInstance_StopImageSavingThreads object at 0x7f3eb104cb30>, <internal.entrypoints.gspl.LazyInstance_ProgressBar object at 0x7f3ea527c8f0>, <internal.entrypoints.gspl.LazyInstance_StopDataLoaderCacheThread object at 0x7f3ea553e960>, <internal.callbacks.MySaveConfigCallback object at 0x7f3ea52c7a40>], 'fast_dev_run': False, 'max_epochs': None, 'min_epochs': None, 'max_steps': 30000, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'overfit_batches': 0.0, 'val_check_interval': None, 'check_val_every_n_epoch': 1, 'num_sanity_val_steps': 1, 'log_every_n_steps': None, 'enable_checkpointing': False, 'enable_progress_bar': None, 'enable_model_summary': None, 'accumulate_grad_batches': 1, 'gradient_clip_val': None, 'gradient_clip_algorithm': None, 'deterministic': None, 'benchmark': None, 'inference_mode': True, 'use_distributed_sampler': False, 'profiler': None, 'detect_anomaly': False, 'barebones': False, 'plugins': None, 'sync_batchnorm': False, 'reload_dataloaders_every_n_epochs': 0, 'default_root_dir': None, 'model_registry': None, '__class__': <class 'lightning.pytorch.trainer.trainer.Trainer'>}
2025-07-23 15:29:55,936 - lightning.pytorch.utilities.rank_zero - INFO - GPU available: True (cuda), used: True
2025-07-23 15:29:55,937 - lightning.pytorch.utilities.rank_zero - INFO - TPU available: False, using: 0 TPU cores
2025-07-23 15:29:55,937 - lightning.pytorch.utilities.rank_zero - INFO - HPU available: False, using: 0 HPUs
2025-07-23 15:29:56,031 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: trainer fit stage
2025-07-23 15:29:56,031 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_callbacks
2025-07-23 15:29:56,032 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: setting up strategy environment
2025-07-23 15:30:02,081 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: Initializing trainer with parameters: {'self': <lightning.pytorch.trainer.trainer.Trainer object at 0x7284d1f74cb0>, 'accelerator': 'gpu', 'strategy': <internal.mp_strategy.MPStrategy object at 0x7284d1a01f10>, 'devices': -1, 'num_nodes': 1, 'precision': None, 'logger': <lightning.pytorch.loggers.tensorboard.TensorBoardLogger object at 0x7284d19e2b10>, 'callbacks': [<internal.entrypoints.gspl.LazyInstance_SaveGaussian object at 0x7286b1818e00>, <internal.entrypoints.gspl.LazyInstance_ValidateOnTrainEnd object at 0x7284d20549e0>, <internal.entrypoints.gspl.LazyInstance_KeepRunningIfWebViewerEnabled object at 0x7284d1f167b0>, <internal.entrypoints.gspl.LazyInstance_StopImageSavingThreads object at 0x7284dd757b30>, <internal.entrypoints.gspl.LazyInstance_ProgressBar object at 0x7284d1bc0bc0>, <internal.entrypoints.gspl.LazyInstance_StopDataLoaderCacheThread object at 0x7284d1e25f40>, <internal.callbacks.MySaveConfigCallback object at 0x7284d17d8440>], 'fast_dev_run': False, 'max_epochs': None, 'min_epochs': None, 'max_steps': 30000, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'overfit_batches': 0.0, 'val_check_interval': None, 'check_val_every_n_epoch': 1, 'num_sanity_val_steps': 1, 'log_every_n_steps': None, 'enable_checkpointing': False, 'enable_progress_bar': None, 'enable_model_summary': None, 'accumulate_grad_batches': 1, 'gradient_clip_val': None, 'gradient_clip_algorithm': None, 'deterministic': None, 'benchmark': None, 'inference_mode': True, 'use_distributed_sampler': False, 'profiler': None, 'detect_anomaly': False, 'barebones': False, 'plugins': None, 'sync_batchnorm': False, 'reload_dataloaders_every_n_epochs': 0, 'default_root_dir': None, 'model_registry': None, '__class__': <class 'lightning.pytorch.trainer.trainer.Trainer'>}
2025-07-23 15:30:02,148 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: trainer fit stage
2025-07-23 15:30:02,148 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_callbacks
2025-07-23 15:30:02,149 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: setting up strategy environment
2025-07-23 15:30:02,269 - lightning.pytorch.utilities.rank_zero - INFO - ----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 2 processes
----------------------------------------------------------------------------------------------------

2025-07-23 15:30:02,273 - lightning.pytorch.utilities.rank_zero - INFO - You are using a CUDA device ('NVIDIA GeForce RTX 3090 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
2025-07-23 15:30:02,781 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: preparing data
2025-07-23 15:30:02,837 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: preparing data
2025-07-23 15:30:02,846 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: setup
2025-07-23 15:30:02,846 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: setup
2025-07-23 15:30:04,766 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: setup
2025-07-23 15:30:05,221 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: setup
2025-07-23 15:30:05,319 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: setup
2025-07-23 15:30:05,319 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: setup
2025-07-23 15:30:12,015 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: configuring model
2025-07-23 15:30:12,016 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring module and callbacks from checkpoint path: None
2025-07-23 15:30:12,016 - lightning.pytorch.trainer.connectors.checkpoint_connector - DEBUG - `checkpoint_path` not specified. Skipping checkpoint loading.
2025-07-23 15:30:12,016 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: configuring model
2025-07-23 15:30:12,016 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring module and callbacks from checkpoint path: None
2025-07-23 15:30:12,016 - lightning.pytorch.trainer.connectors.checkpoint_connector - DEBUG - `checkpoint_path` not specified. Skipping checkpoint loading.
2025-07-23 15:30:12,038 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [6,7]
2025-07-23 15:30:12,038 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [6,7]
2025-07-23 15:30:12,039 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_optimizers
2025-07-23 15:30:12,039 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_optimizers
2025-07-23 15:30:12,042 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_fit_start
2025-07-23 15:30:12,042 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_fit_start
2025-07-23 15:30:12,043 - lightning.pytorch.callbacks.model_summary - INFO - 
  | Name               | Type                                    | Params | Mode 
---------------------------------------------------------------------------------------
0 | gaussian_model     | VanillaGaussianModel                    | 4.0 M  | train
1 | renderer           | GSplatDistributedRendererImpl           | 0      | train
2 | density_controller | DistributedVanillaDensityControllerImpl | 0      | train
3 | metric             | VanillaMetricsImpl                      | 0      | train
---------------------------------------------------------------------------------------
4.0 M     Trainable params
0         Non-trainable params
4.0 M     Total params
16.051    Total estimated model params size (MB)
6         Modules in train mode
0         Modules in eval mode
2025-07-23 15:30:12,043 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_fit_start
2025-07-23 15:30:12,043 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_fit_start
2025-07-23 15:30:12,043 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring training state
2025-07-23 15:30:12,507 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring training state
2025-07-23 15:30:12,509 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_sanity_check_start
2025-07-23 15:30:12,509 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_sanity_check_start
2025-07-23 15:30:12,510 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: val_dataloader
2025-07-23 15:30:12,510 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: val_dataloader
2025-07-23 15:30:13,132 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_model_eval
2025-07-23 15:30:13,133 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_start
2025-07-23 15:30:13,133 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_start
2025-07-23 15:30:13,133 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: on_validation_start
2025-07-23 15:30:13,133 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_epoch_start
2025-07-23 15:30:13,133 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_epoch_start
2025-07-23 15:30:13,133 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_before_batch_transfer
2025-07-23 15:30:13,134 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: batch_to_device
2025-07-23 15:30:13,134 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: transfer_batch_to_device
2025-07-23 15:30:13,143 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_model_eval
2025-07-23 15:30:13,143 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_start
2025-07-23 15:30:13,143 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_start
2025-07-23 15:30:13,144 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: on_validation_start
2025-07-23 15:30:13,144 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_epoch_start
2025-07-23 15:30:13,144 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_epoch_start
2025-07-23 15:30:13,144 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_before_batch_transfer
2025-07-23 15:30:13,144 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: batch_to_device
2025-07-23 15:30:13,144 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: transfer_batch_to_device
2025-07-23 15:30:13,164 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: on_after_batch_transfer
2025-07-23 15:30:13,164 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_batch_start
2025-07-23 15:30:13,164 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: on_after_batch_transfer
2025-07-23 15:30:13,165 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_batch_start
2025-07-23 15:30:13,165 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_batch_start
2025-07-23 15:30:13,165 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_batch_start
2025-07-23 15:30:13,165 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: validation_step
2025-07-23 15:30:13,165 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: validation_step
2025-07-23 15:34:35,689 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: Initializing trainer with parameters: {'self': <lightning.pytorch.trainer.trainer.Trainer object at 0x78086d8cf8c0>, 'accelerator': 'gpu', 'strategy': <internal.mp_strategy.MPStrategy object at 0x78086d6f5e20>, 'devices': -1, 'num_nodes': 1, 'precision': None, 'logger': <lightning.pytorch.loggers.tensorboard.TensorBoardLogger object at 0x78086d6f4ad0>, 'callbacks': [<internal.entrypoints.gspl.LazyInstance_SaveGaussian object at 0x780a4d598c80>, <internal.entrypoints.gspl.LazyInstance_ValidateOnTrainEnd object at 0x7808795989b0>, <internal.entrypoints.gspl.LazyInstance_KeepRunningIfWebViewerEnabled object at 0x78086dd3ba70>, <internal.entrypoints.gspl.LazyInstance_StopImageSavingThreads object at 0x78086db10920>, <internal.entrypoints.gspl.LazyInstance_ProgressBar object at 0x78086dac8d70>, <internal.entrypoints.gspl.LazyInstance_StopDataLoaderCacheThread object at 0x78086dbabfe0>, <internal.callbacks.MySaveConfigCallback object at 0x78086d6f55b0>], 'fast_dev_run': False, 'max_epochs': None, 'min_epochs': None, 'max_steps': 30000, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'overfit_batches': 0.0, 'val_check_interval': None, 'check_val_every_n_epoch': 1, 'num_sanity_val_steps': 1, 'log_every_n_steps': None, 'enable_checkpointing': False, 'enable_progress_bar': None, 'enable_model_summary': None, 'accumulate_grad_batches': 1, 'gradient_clip_val': None, 'gradient_clip_algorithm': None, 'deterministic': None, 'benchmark': None, 'inference_mode': True, 'use_distributed_sampler': False, 'profiler': None, 'detect_anomaly': False, 'barebones': False, 'plugins': None, 'sync_batchnorm': False, 'reload_dataloaders_every_n_epochs': 0, 'default_root_dir': None, 'model_registry': None, '__class__': <class 'lightning.pytorch.trainer.trainer.Trainer'>}
2025-07-23 15:34:35,756 - lightning.pytorch.utilities.rank_zero - INFO - GPU available: True (cuda), used: True
2025-07-23 15:34:35,756 - lightning.pytorch.utilities.rank_zero - INFO - TPU available: False, using: 0 TPU cores
2025-07-23 15:34:35,757 - lightning.pytorch.utilities.rank_zero - INFO - HPU available: False, using: 0 HPUs
2025-07-23 15:34:35,840 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: trainer fit stage
2025-07-23 15:34:35,841 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_callbacks
2025-07-23 15:34:35,841 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: setting up strategy environment
2025-07-23 15:34:41,615 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: Initializing trainer with parameters: {'self': <lightning.pytorch.trainer.trainer.Trainer object at 0x7c05e08c0500>, 'accelerator': 'gpu', 'strategy': <internal.mp_strategy.MPStrategy object at 0x7c05e06946b0>, 'devices': -1, 'num_nodes': 1, 'precision': None, 'logger': <lightning.pytorch.loggers.tensorboard.TensorBoardLogger object at 0x7c05e044c8c0>, 'callbacks': [<internal.entrypoints.gspl.LazyInstance_SaveGaussian object at 0x7c07c04b0f20>, <internal.entrypoints.gspl.LazyInstance_ValidateOnTrainEnd object at 0x7c05e09ef230>, <internal.entrypoints.gspl.LazyInstance_KeepRunningIfWebViewerEnabled object at 0x7c05e0cb67b0>, <internal.entrypoints.gspl.LazyInstance_StopImageSavingThreads object at 0x7c05ec5ff8f0>, <internal.entrypoints.gspl.LazyInstance_ProgressBar object at 0x7c05e09effb0>, <internal.entrypoints.gspl.LazyInstance_StopDataLoaderCacheThread object at 0x7c05ec281ac0>, <internal.callbacks.MySaveConfigCallback object at 0x7c05e0751850>], 'fast_dev_run': False, 'max_epochs': None, 'min_epochs': None, 'max_steps': 30000, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'overfit_batches': 0.0, 'val_check_interval': None, 'check_val_every_n_epoch': 1, 'num_sanity_val_steps': 1, 'log_every_n_steps': None, 'enable_checkpointing': False, 'enable_progress_bar': None, 'enable_model_summary': None, 'accumulate_grad_batches': 1, 'gradient_clip_val': None, 'gradient_clip_algorithm': None, 'deterministic': None, 'benchmark': None, 'inference_mode': True, 'use_distributed_sampler': False, 'profiler': None, 'detect_anomaly': False, 'barebones': False, 'plugins': None, 'sync_batchnorm': False, 'reload_dataloaders_every_n_epochs': 0, 'default_root_dir': None, 'model_registry': None, '__class__': <class 'lightning.pytorch.trainer.trainer.Trainer'>}
2025-07-23 15:34:41,685 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: Initializing trainer with parameters: {'self': <lightning.pytorch.trainer.trainer.Trainer object at 0x7656b03bf0e0>, 'accelerator': 'gpu', 'strategy': <internal.mp_strategy.MPStrategy object at 0x7656b05846b0>, 'devices': -1, 'num_nodes': 1, 'precision': None, 'logger': <lightning.pytorch.loggers.tensorboard.TensorBoardLogger object at 0x7656b0586540>, 'callbacks': [<internal.entrypoints.gspl.LazyInstance_SaveGaussian object at 0x765890314e00>, <internal.entrypoints.gspl.LazyInstance_ValidateOnTrainEnd object at 0x7658903157c0>, <internal.entrypoints.gspl.LazyInstance_KeepRunningIfWebViewerEnabled object at 0x7656b09d8e30>, <internal.entrypoints.gspl.LazyInstance_StopImageSavingThreads object at 0x7656bc497fe0>, <internal.entrypoints.gspl.LazyInstance_ProgressBar object at 0x7656bc497c50>, <internal.entrypoints.gspl.LazyInstance_StopDataLoaderCacheThread object at 0x7656bc12d2e0>, <internal.callbacks.MySaveConfigCallback object at 0x7656b06cd9d0>], 'fast_dev_run': False, 'max_epochs': None, 'min_epochs': None, 'max_steps': 30000, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'overfit_batches': 0.0, 'val_check_interval': None, 'check_val_every_n_epoch': 1, 'num_sanity_val_steps': 1, 'log_every_n_steps': None, 'enable_checkpointing': False, 'enable_progress_bar': None, 'enable_model_summary': None, 'accumulate_grad_batches': 1, 'gradient_clip_val': None, 'gradient_clip_algorithm': None, 'deterministic': None, 'benchmark': None, 'inference_mode': True, 'use_distributed_sampler': False, 'profiler': None, 'detect_anomaly': False, 'barebones': False, 'plugins': None, 'sync_batchnorm': False, 'reload_dataloaders_every_n_epochs': 0, 'default_root_dir': None, 'model_registry': None, '__class__': <class 'lightning.pytorch.trainer.trainer.Trainer'>}
2025-07-23 15:34:41,685 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: trainer fit stage
2025-07-23 15:34:41,686 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_callbacks
2025-07-23 15:34:41,686 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: setting up strategy environment
2025-07-23 15:34:41,771 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: Initializing trainer with parameters: {'self': <lightning.pytorch.trainer.trainer.Trainer object at 0x7247810a85c0>, 'accelerator': 'gpu', 'strategy': <internal.mp_strategy.MPStrategy object at 0x7247812e4710>, 'devices': -1, 'num_nodes': 1, 'precision': None, 'logger': <lightning.pytorch.loggers.tensorboard.TensorBoardLogger object at 0x724781154e30>, 'callbacks': [<internal.entrypoints.gspl.LazyInstance_SaveGaussian object at 0x72496108cef0>, <internal.entrypoints.gspl.LazyInstance_ValidateOnTrainEnd object at 0x72478ce49820>, <internal.entrypoints.gspl.LazyInstance_KeepRunningIfWebViewerEnabled object at 0x7247818e6870>, <internal.entrypoints.gspl.LazyInstance_StopImageSavingThreads object at 0x7247818e6120>, <internal.entrypoints.gspl.LazyInstance_ProgressBar object at 0x72478147cb30>, <internal.entrypoints.gspl.LazyInstance_StopDataLoaderCacheThread object at 0x72478190dfd0>, <internal.callbacks.MySaveConfigCallback object at 0x72478137ddf0>], 'fast_dev_run': False, 'max_epochs': None, 'min_epochs': None, 'max_steps': 30000, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'overfit_batches': 0.0, 'val_check_interval': None, 'check_val_every_n_epoch': 1, 'num_sanity_val_steps': 1, 'log_every_n_steps': None, 'enable_checkpointing': False, 'enable_progress_bar': None, 'enable_model_summary': None, 'accumulate_grad_batches': 1, 'gradient_clip_val': None, 'gradient_clip_algorithm': None, 'deterministic': None, 'benchmark': None, 'inference_mode': True, 'use_distributed_sampler': False, 'profiler': None, 'detect_anomaly': False, 'barebones': False, 'plugins': None, 'sync_batchnorm': False, 'reload_dataloaders_every_n_epochs': 0, 'default_root_dir': None, 'model_registry': None, '__class__': <class 'lightning.pytorch.trainer.trainer.Trainer'>}
2025-07-23 15:34:41,799 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: trainer fit stage
2025-07-23 15:34:41,799 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_callbacks
2025-07-23 15:34:41,800 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: setting up strategy environment
2025-07-23 15:34:41,886 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: trainer fit stage
2025-07-23 15:34:41,886 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_callbacks
2025-07-23 15:34:41,887 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: setting up strategy environment
2025-07-23 15:34:42,004 - lightning.pytorch.utilities.rank_zero - INFO - ----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 4 processes
----------------------------------------------------------------------------------------------------

2025-07-23 15:34:42,014 - lightning.pytorch.utilities.rank_zero - INFO - You are using a CUDA device ('NVIDIA GeForce RTX 3090 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
2025-07-23 15:34:42,613 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: preparing data
2025-07-23 15:34:42,646 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: preparing data
2025-07-23 15:34:42,666 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: preparing data
2025-07-23 15:34:42,669 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: preparing data
2025-07-23 15:34:42,680 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: setup
2025-07-23 15:34:42,680 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: setup
2025-07-23 15:34:42,680 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: setup
2025-07-23 15:34:42,680 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: setup
2025-07-23 15:34:44,512 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: setup
2025-07-23 15:34:44,617 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: setup
2025-07-23 15:34:44,667 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: setup
2025-07-23 15:34:44,772 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: setup
2025-07-23 15:34:44,858 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: setup
2025-07-23 15:34:44,858 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: setup
2025-07-23 15:34:44,858 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: setup
2025-07-23 15:34:44,858 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: setup
2025-07-23 15:34:45,865 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: configuring model
2025-07-23 15:34:45,866 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring module and callbacks from checkpoint path: None
2025-07-23 15:34:45,866 - lightning.pytorch.trainer.connectors.checkpoint_connector - DEBUG - `checkpoint_path` not specified. Skipping checkpoint loading.
2025-07-23 15:34:45,881 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [4,5,6,7]
2025-07-23 15:34:45,882 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_optimizers
2025-07-23 15:34:45,884 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_fit_start
2025-07-23 15:34:45,885 - lightning.pytorch.callbacks.model_summary - INFO - 
  | Name               | Type                                    | Params | Mode 
---------------------------------------------------------------------------------------
0 | gaussian_model     | VanillaGaussianModel                    | 2.0 M  | train
1 | renderer           | GSplatDistributedRendererImpl           | 0      | train
2 | density_controller | DistributedVanillaDensityControllerImpl | 0      | train
3 | metric             | VanillaMetricsImpl                      | 0      | train
---------------------------------------------------------------------------------------
2.0 M     Trainable params
0         Non-trainable params
2.0 M     Total params
8.026     Total estimated model params size (MB)
6         Modules in train mode
0         Modules in eval mode
2025-07-23 15:34:45,885 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_fit_start
2025-07-23 15:34:46,176 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring training state
2025-07-23 15:39:00,557 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: Initializing trainer with parameters: {'self': <lightning.pytorch.trainer.trainer.Trainer object at 0x772486226450>, 'accelerator': 'gpu', 'strategy': <internal.mp_strategy.MPStrategy object at 0x77248651f2f0>, 'devices': -1, 'num_nodes': 1, 'precision': None, 'logger': <lightning.pytorch.loggers.tensorboard.TensorBoardLogger object at 0x77248629b020>, 'callbacks': [<internal.entrypoints.gspl.LazyInstance_SaveGaussian object at 0x77266607cce0>, <internal.entrypoints.gspl.LazyInstance_ValidateOnTrainEnd object at 0x772492061130>, <internal.entrypoints.gspl.LazyInstance_KeepRunningIfWebViewerEnabled object at 0x77248688b800>, <internal.entrypoints.gspl.LazyInstance_StopImageSavingThreads object at 0x77248682d010>, <internal.entrypoints.gspl.LazyInstance_ProgressBar object at 0x7724868e6510>, <internal.entrypoints.gspl.LazyInstance_StopDataLoaderCacheThread object at 0x772486775520>, <internal.callbacks.MySaveConfigCallback object at 0x7724860c5c40>], 'fast_dev_run': False, 'max_epochs': None, 'min_epochs': None, 'max_steps': 30000, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'overfit_batches': 0.0, 'val_check_interval': None, 'check_val_every_n_epoch': 1, 'num_sanity_val_steps': 1, 'log_every_n_steps': None, 'enable_checkpointing': False, 'enable_progress_bar': None, 'enable_model_summary': None, 'accumulate_grad_batches': 1, 'gradient_clip_val': None, 'gradient_clip_algorithm': None, 'deterministic': None, 'benchmark': None, 'inference_mode': True, 'use_distributed_sampler': False, 'profiler': None, 'detect_anomaly': False, 'barebones': False, 'plugins': None, 'sync_batchnorm': False, 'reload_dataloaders_every_n_epochs': 0, 'default_root_dir': None, 'model_registry': None, '__class__': <class 'lightning.pytorch.trainer.trainer.Trainer'>}
2025-07-23 15:39:00,621 - lightning.pytorch.utilities.rank_zero - INFO - GPU available: True (cuda), used: True
2025-07-23 15:39:00,622 - lightning.pytorch.utilities.rank_zero - INFO - TPU available: False, using: 0 TPU cores
2025-07-23 15:39:00,622 - lightning.pytorch.utilities.rank_zero - INFO - HPU available: False, using: 0 HPUs
2025-07-23 15:39:00,700 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: trainer fit stage
2025-07-23 15:39:00,701 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_callbacks
2025-07-23 15:39:00,701 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: setting up strategy environment
2025-07-23 15:39:06,409 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: Initializing trainer with parameters: {'self': <lightning.pytorch.trainer.trainer.Trainer object at 0x781551919ac0>, 'accelerator': 'gpu', 'strategy': <internal.mp_strategy.MPStrategy object at 0x7815516c46b0>, 'devices': -1, 'num_nodes': 1, 'precision': None, 'logger': <lightning.pytorch.loggers.tensorboard.TensorBoardLogger object at 0x7815516c4350>, 'callbacks': [<internal.entrypoints.gspl.LazyInstance_SaveGaussian object at 0x781551ac6e10>, <internal.entrypoints.gspl.LazyInstance_ValidateOnTrainEnd object at 0x78173156ce00>, <internal.entrypoints.gspl.LazyInstance_KeepRunningIfWebViewerEnabled object at 0x781551e63fb0>, <internal.entrypoints.gspl.LazyInstance_StopImageSavingThreads object at 0x781551d0cb30>, <internal.entrypoints.gspl.LazyInstance_ProgressBar object at 0x781551ba7f50>, <internal.entrypoints.gspl.LazyInstance_StopDataLoaderCacheThread object at 0x781551ac4ec0>, <internal.callbacks.MySaveConfigCallback object at 0x7815517814f0>], 'fast_dev_run': False, 'max_epochs': None, 'min_epochs': None, 'max_steps': 30000, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'overfit_batches': 0.0, 'val_check_interval': None, 'check_val_every_n_epoch': 1, 'num_sanity_val_steps': 1, 'log_every_n_steps': None, 'enable_checkpointing': False, 'enable_progress_bar': None, 'enable_model_summary': None, 'accumulate_grad_batches': 1, 'gradient_clip_val': None, 'gradient_clip_algorithm': None, 'deterministic': None, 'benchmark': None, 'inference_mode': True, 'use_distributed_sampler': False, 'profiler': None, 'detect_anomaly': False, 'barebones': False, 'plugins': None, 'sync_batchnorm': False, 'reload_dataloaders_every_n_epochs': 0, 'default_root_dir': None, 'model_registry': None, '__class__': <class 'lightning.pytorch.trainer.trainer.Trainer'>}
2025-07-23 15:39:06,478 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: trainer fit stage
2025-07-23 15:39:06,478 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_callbacks
2025-07-23 15:39:06,478 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: setting up strategy environment
2025-07-23 15:39:06,480 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: Initializing trainer with parameters: {'self': <lightning.pytorch.trainer.trainer.Trainer object at 0x742d4d0fca70>, 'accelerator': 'gpu', 'strategy': <internal.mp_strategy.MPStrategy object at 0x742d589177a0>, 'devices': -1, 'num_nodes': 1, 'precision': None, 'logger': <lightning.pytorch.loggers.tensorboard.TensorBoardLogger object at 0x742d5a1a0500>, 'callbacks': [<internal.entrypoints.gspl.LazyInstance_SaveGaussian object at 0x742f2c968f20>, <internal.entrypoints.gspl.LazyInstance_ValidateOnTrainEnd object at 0x742d4d1949e0>, <internal.entrypoints.gspl.LazyInstance_KeepRunningIfWebViewerEnabled object at 0x742d4cfc67b0>, <internal.entrypoints.gspl.LazyInstance_StopImageSavingThreads object at 0x742d4d29bfb0>, <internal.entrypoints.gspl.LazyInstance_ProgressBar object at 0x742d4cc70bf0>, <internal.entrypoints.gspl.LazyInstance_StopDataLoaderCacheThread object at 0x742d4cff2c00>, <internal.callbacks.MySaveConfigCallback object at 0x742d4ca93740>], 'fast_dev_run': False, 'max_epochs': None, 'min_epochs': None, 'max_steps': 30000, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'overfit_batches': 0.0, 'val_check_interval': None, 'check_val_every_n_epoch': 1, 'num_sanity_val_steps': 1, 'log_every_n_steps': None, 'enable_checkpointing': False, 'enable_progress_bar': None, 'enable_model_summary': None, 'accumulate_grad_batches': 1, 'gradient_clip_val': None, 'gradient_clip_algorithm': None, 'deterministic': None, 'benchmark': None, 'inference_mode': True, 'use_distributed_sampler': False, 'profiler': None, 'detect_anomaly': False, 'barebones': False, 'plugins': None, 'sync_batchnorm': False, 'reload_dataloaders_every_n_epochs': 0, 'default_root_dir': None, 'model_registry': None, '__class__': <class 'lightning.pytorch.trainer.trainer.Trainer'>}
2025-07-23 15:39:06,491 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: Initializing trainer with parameters: {'self': <lightning.pytorch.trainer.trainer.Trainer object at 0x7535f36f72f0>, 'accelerator': 'gpu', 'strategy': <internal.mp_strategy.MPStrategy object at 0x7535f35846b0>, 'devices': -1, 'num_nodes': 1, 'precision': None, 'logger': <lightning.pytorch.loggers.tensorboard.TensorBoardLogger object at 0x7535f34a7260>, 'callbacks': [<internal.entrypoints.gspl.LazyInstance_SaveGaussian object at 0x7535f38c8140>, <internal.entrypoints.gspl.LazyInstance_ValidateOnTrainEnd object at 0x7535ff0b7bf0>, <internal.entrypoints.gspl.LazyInstance_KeepRunningIfWebViewerEnabled object at 0x7536b45be570>, <internal.entrypoints.gspl.LazyInstance_StopImageSavingThreads object at 0x7535f39abfb0>, <internal.entrypoints.gspl.LazyInstance_ProgressBar object at 0x7535f39abfe0>, <internal.entrypoints.gspl.LazyInstance_StopDataLoaderCacheThread object at 0x7535f390f140>, <internal.callbacks.MySaveConfigCallback object at 0x7535f36f5ee0>], 'fast_dev_run': False, 'max_epochs': None, 'min_epochs': None, 'max_steps': 30000, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'overfit_batches': 0.0, 'val_check_interval': None, 'check_val_every_n_epoch': 1, 'num_sanity_val_steps': 1, 'log_every_n_steps': None, 'enable_checkpointing': False, 'enable_progress_bar': None, 'enable_model_summary': None, 'accumulate_grad_batches': 1, 'gradient_clip_val': None, 'gradient_clip_algorithm': None, 'deterministic': None, 'benchmark': None, 'inference_mode': True, 'use_distributed_sampler': False, 'profiler': None, 'detect_anomaly': False, 'barebones': False, 'plugins': None, 'sync_batchnorm': False, 'reload_dataloaders_every_n_epochs': 0, 'default_root_dir': None, 'model_registry': None, '__class__': <class 'lightning.pytorch.trainer.trainer.Trainer'>}
2025-07-23 15:39:06,583 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: trainer fit stage
2025-07-23 15:39:06,584 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_callbacks
2025-07-23 15:39:06,584 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: setting up strategy environment
2025-07-23 15:39:06,598 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: trainer fit stage
2025-07-23 15:39:06,599 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_callbacks
2025-07-23 15:39:06,599 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: setting up strategy environment
2025-07-23 15:39:06,779 - lightning.pytorch.utilities.rank_zero - INFO - ----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 4 processes
----------------------------------------------------------------------------------------------------

2025-07-23 15:39:06,801 - lightning.pytorch.utilities.rank_zero - INFO - You are using a CUDA device ('NVIDIA GeForce RTX 3090 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
2025-07-23 15:39:07,295 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: preparing data
2025-07-23 15:39:07,319 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: preparing data
2025-07-23 15:39:07,325 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: preparing data
2025-07-23 15:39:07,355 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: preparing data
2025-07-23 15:39:07,364 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: setup
2025-07-23 15:39:07,364 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: setup
2025-07-23 15:39:07,364 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: setup
2025-07-23 15:39:07,364 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: setup
2025-07-23 15:39:09,093 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: setup
2025-07-23 15:39:09,103 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: setup
2025-07-23 15:39:09,110 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: setup
2025-07-23 15:39:09,600 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: setup
2025-07-23 15:39:09,681 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: setup
2025-07-23 15:39:09,681 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: setup
2025-07-23 15:39:09,681 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: setup
2025-07-23 15:39:09,681 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: setup
2025-07-23 15:39:10,676 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: configuring model
2025-07-23 15:39:10,676 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring module and callbacks from checkpoint path: None
2025-07-23 15:39:10,676 - lightning.pytorch.trainer.connectors.checkpoint_connector - DEBUG - `checkpoint_path` not specified. Skipping checkpoint loading.
2025-07-23 15:39:10,691 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [4,5,6,7]
2025-07-23 15:39:10,692 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_optimizers
2025-07-23 15:39:10,694 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_fit_start
2025-07-23 15:39:10,694 - lightning.pytorch.callbacks.model_summary - INFO - 
  | Name               | Type                                    | Params | Mode 
---------------------------------------------------------------------------------------
0 | gaussian_model     | VanillaGaussianModel                    | 2.0 M  | train
1 | renderer           | GSplatDistributedRendererImpl           | 0      | train
2 | density_controller | DistributedVanillaDensityControllerImpl | 0      | train
3 | metric             | VanillaMetricsImpl                      | 0      | train
---------------------------------------------------------------------------------------
2.0 M     Trainable params
0         Non-trainable params
2.0 M     Total params
8.026     Total estimated model params size (MB)
6         Modules in train mode
0         Modules in eval mode
2025-07-23 15:39:10,694 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_fit_start
2025-07-23 15:39:10,938 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring training state
2025-07-23 15:40:39,166 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: Initializing trainer with parameters: {'self': <lightning.pytorch.trainer.trainer.Trainer object at 0x71d4e7022150>, 'accelerator': 'gpu', 'strategy': <internal.mp_strategy.MPStrategy object at 0x71d4e6e1c6b0>, 'devices': -1, 'num_nodes': 1, 'precision': None, 'logger': <lightning.pytorch.loggers.tensorboard.TensorBoardLogger object at 0x71d4e6bde090>, 'callbacks': [<internal.entrypoints.gspl.LazyInstance_SaveGaussian object at 0x71d4f2ee0140>, <internal.entrypoints.gspl.LazyInstance_ValidateOnTrainEnd object at 0x71d4e72d5850>, <internal.entrypoints.gspl.LazyInstance_KeepRunningIfWebViewerEnabled object at 0x71d4e73eb800>, <internal.entrypoints.gspl.LazyInstance_StopImageSavingThreads object at 0x71d4e73e9160>, <internal.entrypoints.gspl.LazyInstance_ProgressBar object at 0x71d4e72fffb0>, <internal.entrypoints.gspl.LazyInstance_StopDataLoaderCacheThread object at 0x71d4e72d5820>, <internal.callbacks.MySaveConfigCallback object at 0x71d4e7021700>], 'fast_dev_run': False, 'max_epochs': None, 'min_epochs': None, 'max_steps': 30000, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'overfit_batches': 0.0, 'val_check_interval': None, 'check_val_every_n_epoch': 1, 'num_sanity_val_steps': 1, 'log_every_n_steps': None, 'enable_checkpointing': False, 'enable_progress_bar': None, 'enable_model_summary': None, 'accumulate_grad_batches': 1, 'gradient_clip_val': None, 'gradient_clip_algorithm': None, 'deterministic': None, 'benchmark': None, 'inference_mode': True, 'use_distributed_sampler': False, 'profiler': None, 'detect_anomaly': False, 'barebones': False, 'plugins': None, 'sync_batchnorm': False, 'reload_dataloaders_every_n_epochs': 0, 'default_root_dir': None, 'model_registry': None, '__class__': <class 'lightning.pytorch.trainer.trainer.Trainer'>}
2025-07-23 15:40:39,231 - lightning.pytorch.utilities.rank_zero - INFO - GPU available: True (cuda), used: True
2025-07-23 15:40:39,231 - lightning.pytorch.utilities.rank_zero - INFO - TPU available: False, using: 0 TPU cores
2025-07-23 15:40:39,231 - lightning.pytorch.utilities.rank_zero - INFO - HPU available: False, using: 0 HPUs
2025-07-23 15:40:39,306 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: trainer fit stage
2025-07-23 15:40:39,306 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_callbacks
2025-07-23 15:40:39,307 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: setting up strategy environment
2025-07-23 15:40:44,860 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: Initializing trainer with parameters: {'self': <lightning.pytorch.trainer.trainer.Trainer object at 0x7b4144889e50>, 'accelerator': 'gpu', 'strategy': <internal.mp_strategy.MPStrategy object at 0x7b41446ea750>, 'devices': -1, 'num_nodes': 1, 'precision': None, 'logger': <lightning.pytorch.loggers.tensorboard.TensorBoardLogger object at 0x7b41446a5f70>, 'callbacks': [<internal.entrypoints.gspl.LazyInstance_SaveGaussian object at 0x7b4324540e00>, <internal.entrypoints.gspl.LazyInstance_ValidateOnTrainEnd object at 0x7b4144b13470>, <internal.entrypoints.gspl.LazyInstance_KeepRunningIfWebViewerEnabled object at 0x7b4144d15e20>, <internal.entrypoints.gspl.LazyInstance_StopImageSavingThreads object at 0x7b4144e67da0>, <internal.entrypoints.gspl.LazyInstance_ProgressBar object at 0x7b4144babf20>, <internal.entrypoints.gspl.LazyInstance_StopDataLoaderCacheThread object at 0x7b4144e363c0>, <internal.callbacks.MySaveConfigCallback object at 0x7b41446e9d60>], 'fast_dev_run': False, 'max_epochs': None, 'min_epochs': None, 'max_steps': 30000, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'overfit_batches': 0.0, 'val_check_interval': None, 'check_val_every_n_epoch': 1, 'num_sanity_val_steps': 1, 'log_every_n_steps': None, 'enable_checkpointing': False, 'enable_progress_bar': None, 'enable_model_summary': None, 'accumulate_grad_batches': 1, 'gradient_clip_val': None, 'gradient_clip_algorithm': None, 'deterministic': None, 'benchmark': None, 'inference_mode': True, 'use_distributed_sampler': False, 'profiler': None, 'detect_anomaly': False, 'barebones': False, 'plugins': None, 'sync_batchnorm': False, 'reload_dataloaders_every_n_epochs': 0, 'default_root_dir': None, 'model_registry': None, '__class__': <class 'lightning.pytorch.trainer.trainer.Trainer'>}
2025-07-23 15:40:44,925 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: trainer fit stage
2025-07-23 15:40:44,925 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_callbacks
2025-07-23 15:40:44,926 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: setting up strategy environment
2025-07-23 15:40:44,941 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: Initializing trainer with parameters: {'self': <lightning.pytorch.trainer.trainer.Trainer object at 0x72ac2b4c5910>, 'accelerator': 'gpu', 'strategy': <internal.mp_strategy.MPStrategy object at 0x72ac2b2bc6b0>, 'devices': -1, 'num_nodes': 1, 'precision': None, 'logger': <lightning.pytorch.loggers.tensorboard.TensorBoardLogger object at 0x72ac2b522ba0>, 'callbacks': [<internal.entrypoints.gspl.LazyInstance_SaveGaussian object at 0x72ac37387ef0>, <internal.entrypoints.gspl.LazyInstance_ValidateOnTrainEnd object at 0x72ac2b779130>, <internal.entrypoints.gspl.LazyInstance_KeepRunningIfWebViewerEnabled object at 0x72ac2b6c3e30>, <internal.entrypoints.gspl.LazyInstance_StopImageSavingThreads object at 0x72ac2ba2a1e0>, <internal.entrypoints.gspl.LazyInstance_ProgressBar object at 0x72ac2b9a0fe0>, <internal.entrypoints.gspl.LazyInstance_StopDataLoaderCacheThread object at 0x72ac2b8e5fa0>, <internal.callbacks.MySaveConfigCallback object at 0x72ac371b35c0>], 'fast_dev_run': False, 'max_epochs': None, 'min_epochs': None, 'max_steps': 30000, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'overfit_batches': 0.0, 'val_check_interval': None, 'check_val_every_n_epoch': 1, 'num_sanity_val_steps': 1, 'log_every_n_steps': None, 'enable_checkpointing': False, 'enable_progress_bar': None, 'enable_model_summary': None, 'accumulate_grad_batches': 1, 'gradient_clip_val': None, 'gradient_clip_algorithm': None, 'deterministic': None, 'benchmark': None, 'inference_mode': True, 'use_distributed_sampler': False, 'profiler': None, 'detect_anomaly': False, 'barebones': False, 'plugins': None, 'sync_batchnorm': False, 'reload_dataloaders_every_n_epochs': 0, 'default_root_dir': None, 'model_registry': None, '__class__': <class 'lightning.pytorch.trainer.trainer.Trainer'>}
2025-07-23 15:40:44,958 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: Initializing trainer with parameters: {'self': <lightning.pytorch.trainer.trainer.Trainer object at 0x709bcbdb3da0>, 'accelerator': 'gpu', 'strategy': <internal.mp_strategy.MPStrategy object at 0x709bcbde3e00>, 'devices': -1, 'num_nodes': 1, 'precision': None, 'logger': <lightning.pytorch.loggers.tensorboard.TensorBoardLogger object at 0x709bcbb9be00>, 'callbacks': [<internal.entrypoints.gspl.LazyInstance_SaveGaussian object at 0x709bcc286a50>, <internal.entrypoints.gspl.LazyInstance_ValidateOnTrainEnd object at 0x709bd78b8140>, <internal.entrypoints.gspl.LazyInstance_KeepRunningIfWebViewerEnabled object at 0x709bcc2e4980>, <internal.entrypoints.gspl.LazyInstance_StopImageSavingThreads object at 0x709bcc206ae0>, <internal.entrypoints.gspl.LazyInstance_ProgressBar object at 0x709bcbf36000>, <internal.entrypoints.gspl.LazyInstance_StopDataLoaderCacheThread object at 0x709bcc285430>, <internal.callbacks.MySaveConfigCallback object at 0x709bcbdb3d40>], 'fast_dev_run': False, 'max_epochs': None, 'min_epochs': None, 'max_steps': 30000, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'overfit_batches': 0.0, 'val_check_interval': None, 'check_val_every_n_epoch': 1, 'num_sanity_val_steps': 1, 'log_every_n_steps': None, 'enable_checkpointing': False, 'enable_progress_bar': None, 'enable_model_summary': None, 'accumulate_grad_batches': 1, 'gradient_clip_val': None, 'gradient_clip_algorithm': None, 'deterministic': None, 'benchmark': None, 'inference_mode': True, 'use_distributed_sampler': False, 'profiler': None, 'detect_anomaly': False, 'barebones': False, 'plugins': None, 'sync_batchnorm': False, 'reload_dataloaders_every_n_epochs': 0, 'default_root_dir': None, 'model_registry': None, '__class__': <class 'lightning.pytorch.trainer.trainer.Trainer'>}
2025-07-23 15:40:45,041 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: trainer fit stage
2025-07-23 15:40:45,041 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_callbacks
2025-07-23 15:40:45,041 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: setting up strategy environment
2025-07-23 15:40:45,067 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: trainer fit stage
2025-07-23 15:40:45,067 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_callbacks
2025-07-23 15:40:45,067 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: setting up strategy environment
2025-07-23 15:40:45,238 - lightning.pytorch.utilities.rank_zero - INFO - ----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 4 processes
----------------------------------------------------------------------------------------------------

2025-07-23 15:40:45,248 - lightning.pytorch.utilities.rank_zero - INFO - You are using a CUDA device ('NVIDIA GeForce RTX 3090 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
2025-07-23 15:40:45,740 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: preparing data
2025-07-23 15:40:45,767 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: preparing data
2025-07-23 15:40:45,793 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: preparing data
2025-07-23 15:40:45,797 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: preparing data
2025-07-23 15:40:45,806 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: setup
2025-07-23 15:40:45,806 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: setup
2025-07-23 15:40:45,806 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: setup
2025-07-23 15:40:45,806 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: setup
2025-07-23 15:40:47,535 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: setup
2025-07-23 15:40:47,538 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: setup
2025-07-23 15:40:47,585 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: setup
2025-07-23 15:40:48,056 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: setup
2025-07-23 15:40:48,140 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: setup
2025-07-23 15:40:48,140 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: setup
2025-07-23 15:40:48,140 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: setup
2025-07-23 15:40:48,141 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: setup
2025-07-23 15:40:49,116 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: configuring model
2025-07-23 15:40:49,116 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring module and callbacks from checkpoint path: None
2025-07-23 15:40:49,116 - lightning.pytorch.trainer.connectors.checkpoint_connector - DEBUG - `checkpoint_path` not specified. Skipping checkpoint loading.
2025-07-23 15:40:49,132 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [4,5,6,7]
2025-07-23 15:40:49,133 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_optimizers
2025-07-23 15:40:49,135 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_fit_start
2025-07-23 15:40:49,135 - lightning.pytorch.callbacks.model_summary - INFO - 
  | Name               | Type                                    | Params | Mode 
---------------------------------------------------------------------------------------
0 | gaussian_model     | VanillaGaussianModel                    | 2.0 M  | train
1 | renderer           | GSplatDistributedRendererImpl           | 0      | train
2 | density_controller | DistributedVanillaDensityControllerImpl | 0      | train
3 | metric             | VanillaMetricsImpl                      | 0      | train
---------------------------------------------------------------------------------------
2.0 M     Trainable params
0         Non-trainable params
2.0 M     Total params
8.026     Total estimated model params size (MB)
6         Modules in train mode
0         Modules in eval mode
2025-07-23 15:40:49,135 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_fit_start
2025-07-23 15:40:49,369 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring training state
2025-07-23 15:41:36,034 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: Initializing trainer with parameters: {'self': <lightning.pytorch.trainer.trainer.Trainer object at 0x7cfc920cbec0>, 'accelerator': 'gpu', 'strategy': <internal.mp_strategy.MPStrategy object at 0x7cfc9211b1a0>, 'devices': -1, 'num_nodes': 1, 'precision': None, 'logger': <lightning.pytorch.loggers.tensorboard.TensorBoardLogger object at 0x7cfc92550bf0>, 'callbacks': [<internal.entrypoints.gspl.LazyInstance_SaveGaussian object at 0x7cfe71cf4ec0>, <internal.entrypoints.gspl.LazyInstance_ValidateOnTrainEnd object at 0x7cfc9df038f0>, <internal.entrypoints.gspl.LazyInstance_KeepRunningIfWebViewerEnabled object at 0x7cfc92372690>, <internal.entrypoints.gspl.LazyInstance_StopImageSavingThreads object at 0x7cfc923de6f0>, <internal.entrypoints.gspl.LazyInstance_ProgressBar object at 0x7cfc9daafc50>, <internal.entrypoints.gspl.LazyInstance_StopDataLoaderCacheThread object at 0x7cfc9265e030>, <internal.callbacks.MySaveConfigCallback object at 0x7cfc9262eb40>], 'fast_dev_run': False, 'max_epochs': None, 'min_epochs': None, 'max_steps': 30000, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'overfit_batches': 0.0, 'val_check_interval': None, 'check_val_every_n_epoch': 1, 'num_sanity_val_steps': 1, 'log_every_n_steps': None, 'enable_checkpointing': False, 'enable_progress_bar': None, 'enable_model_summary': None, 'accumulate_grad_batches': 1, 'gradient_clip_val': None, 'gradient_clip_algorithm': None, 'deterministic': None, 'benchmark': None, 'inference_mode': True, 'use_distributed_sampler': False, 'profiler': None, 'detect_anomaly': False, 'barebones': False, 'plugins': None, 'sync_batchnorm': False, 'reload_dataloaders_every_n_epochs': 0, 'default_root_dir': None, 'model_registry': None, '__class__': <class 'lightning.pytorch.trainer.trainer.Trainer'>}
2025-07-23 15:41:36,099 - lightning.pytorch.utilities.rank_zero - INFO - GPU available: True (cuda), used: True
2025-07-23 15:41:36,099 - lightning.pytorch.utilities.rank_zero - INFO - TPU available: False, using: 0 TPU cores
2025-07-23 15:41:36,099 - lightning.pytorch.utilities.rank_zero - INFO - HPU available: False, using: 0 HPUs
2025-07-23 15:41:36,179 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: trainer fit stage
2025-07-23 15:41:36,179 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_callbacks
2025-07-23 15:41:36,180 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: setting up strategy environment
2025-07-23 15:41:41,590 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: Initializing trainer with parameters: {'self': <lightning.pytorch.trainer.trainer.Trainer object at 0x7985f9806510>, 'accelerator': 'gpu', 'strategy': <internal.mp_strategy.MPStrategy object at 0x79853bad8b90>, 'devices': -1, 'num_nodes': 1, 'precision': None, 'logger': <lightning.pytorch.loggers.tensorboard.TensorBoardLogger object at 0x79853b3acfb0>, 'callbacks': [<internal.entrypoints.gspl.LazyInstance_SaveGaussian object at 0x79871b448e00>, <internal.entrypoints.gspl.LazyInstance_ValidateOnTrainEnd object at 0x79853ba40b60>, <internal.entrypoints.gspl.LazyInstance_KeepRunningIfWebViewerEnabled object at 0x7985471467b0>, <internal.entrypoints.gspl.LazyInstance_StopImageSavingThreads object at 0x79853b9c4b30>, <internal.entrypoints.gspl.LazyInstance_ProgressBar object at 0x798547761e80>, <internal.entrypoints.gspl.LazyInstance_StopDataLoaderCacheThread object at 0x79853ba77740>, <internal.callbacks.MySaveConfigCallback object at 0x79853b7b6db0>], 'fast_dev_run': False, 'max_epochs': None, 'min_epochs': None, 'max_steps': 30000, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'overfit_batches': 0.0, 'val_check_interval': None, 'check_val_every_n_epoch': 1, 'num_sanity_val_steps': 1, 'log_every_n_steps': None, 'enable_checkpointing': False, 'enable_progress_bar': None, 'enable_model_summary': None, 'accumulate_grad_batches': 1, 'gradient_clip_val': None, 'gradient_clip_algorithm': None, 'deterministic': None, 'benchmark': None, 'inference_mode': True, 'use_distributed_sampler': False, 'profiler': None, 'detect_anomaly': False, 'barebones': False, 'plugins': None, 'sync_batchnorm': False, 'reload_dataloaders_every_n_epochs': 0, 'default_root_dir': None, 'model_registry': None, '__class__': <class 'lightning.pytorch.trainer.trainer.Trainer'>}
2025-07-23 15:41:41,657 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: trainer fit stage
2025-07-23 15:41:41,658 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_callbacks
2025-07-23 15:41:41,658 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: setting up strategy environment
2025-07-23 15:41:41,769 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: Initializing trainer with parameters: {'self': <lightning.pytorch.trainer.trainer.Trainer object at 0x7277adac1550>, 'accelerator': 'gpu', 'strategy': <internal.mp_strategy.MPStrategy object at 0x7277ad8d8260>, 'devices': -1, 'num_nodes': 1, 'precision': None, 'logger': <lightning.pytorch.loggers.tensorboard.TensorBoardLogger object at 0x7277adb11d60>, 'callbacks': [<internal.entrypoints.gspl.LazyInstance_SaveGaussian object at 0x72798d774e00>, <internal.entrypoints.gspl.LazyInstance_ValidateOnTrainEnd object at 0x7277ade89580>, <internal.entrypoints.gspl.LazyInstance_KeepRunningIfWebViewerEnabled object at 0x72786eab23f0>, <internal.entrypoints.gspl.LazyInstance_StopImageSavingThreads object at 0x7277b97eec00>, <internal.entrypoints.gspl.LazyInstance_ProgressBar object at 0x7277ada78a10>, <internal.entrypoints.gspl.LazyInstance_StopDataLoaderCacheThread object at 0x7277b99b3980>, <internal.callbacks.MySaveConfigCallback object at 0x7277ad8007a0>], 'fast_dev_run': False, 'max_epochs': None, 'min_epochs': None, 'max_steps': 30000, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'overfit_batches': 0.0, 'val_check_interval': None, 'check_val_every_n_epoch': 1, 'num_sanity_val_steps': 1, 'log_every_n_steps': None, 'enable_checkpointing': False, 'enable_progress_bar': None, 'enable_model_summary': None, 'accumulate_grad_batches': 1, 'gradient_clip_val': None, 'gradient_clip_algorithm': None, 'deterministic': None, 'benchmark': None, 'inference_mode': True, 'use_distributed_sampler': False, 'profiler': None, 'detect_anomaly': False, 'barebones': False, 'plugins': None, 'sync_batchnorm': False, 'reload_dataloaders_every_n_epochs': 0, 'default_root_dir': None, 'model_registry': None, '__class__': <class 'lightning.pytorch.trainer.trainer.Trainer'>}
2025-07-23 15:41:41,781 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: Initializing trainer with parameters: {'self': <lightning.pytorch.trainer.trainer.Trainer object at 0x78d5072ff860>, 'accelerator': 'gpu', 'strategy': <internal.mp_strategy.MPStrategy object at 0x78d5075e50d0>, 'devices': -1, 'num_nodes': 1, 'precision': None, 'logger': <lightning.pytorch.loggers.tensorboard.TensorBoardLogger object at 0x78d5070acc80>, 'callbacks': [<internal.entrypoints.gspl.LazyInstance_SaveGaussian object at 0x78d6e6f08e00>, <internal.entrypoints.gspl.LazyInstance_ValidateOnTrainEnd object at 0x78d5076ab500>, <internal.entrypoints.gspl.LazyInstance_KeepRunningIfWebViewerEnabled object at 0x78d5078127b0>, <internal.entrypoints.gspl.LazyInstance_StopImageSavingThreads object at 0x78d512eae270>, <internal.entrypoints.gspl.LazyInstance_ProgressBar object at 0x78d507396b10>, <internal.entrypoints.gspl.LazyInstance_StopDataLoaderCacheThread object at 0x78d512e43e00>, <internal.callbacks.MySaveConfigCallback object at 0x78d5072fdfa0>], 'fast_dev_run': False, 'max_epochs': None, 'min_epochs': None, 'max_steps': 30000, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'overfit_batches': 0.0, 'val_check_interval': None, 'check_val_every_n_epoch': 1, 'num_sanity_val_steps': 1, 'log_every_n_steps': None, 'enable_checkpointing': False, 'enable_progress_bar': None, 'enable_model_summary': None, 'accumulate_grad_batches': 1, 'gradient_clip_val': None, 'gradient_clip_algorithm': None, 'deterministic': None, 'benchmark': None, 'inference_mode': True, 'use_distributed_sampler': False, 'profiler': None, 'detect_anomaly': False, 'barebones': False, 'plugins': None, 'sync_batchnorm': False, 'reload_dataloaders_every_n_epochs': 0, 'default_root_dir': None, 'model_registry': None, '__class__': <class 'lightning.pytorch.trainer.trainer.Trainer'>}
2025-07-23 15:41:41,847 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: trainer fit stage
2025-07-23 15:41:41,848 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_callbacks
2025-07-23 15:41:41,848 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: setting up strategy environment
2025-07-23 15:41:41,873 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: trainer fit stage
2025-07-23 15:41:41,873 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_callbacks
2025-07-23 15:41:41,874 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: setting up strategy environment
2025-07-23 15:41:41,987 - lightning.pytorch.utilities.rank_zero - INFO - ----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 4 processes
----------------------------------------------------------------------------------------------------

2025-07-23 15:41:41,992 - lightning.pytorch.utilities.rank_zero - INFO - You are using a CUDA device ('NVIDIA GeForce RTX 3090 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
2025-07-23 15:41:42,517 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: preparing data
2025-07-23 15:41:42,558 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: preparing data
2025-07-23 15:41:42,572 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: preparing data
2025-07-23 15:41:42,574 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: preparing data
2025-07-23 15:41:42,584 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: setup
2025-07-23 15:41:42,584 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: setup
2025-07-23 15:41:42,584 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: setup
2025-07-23 15:41:42,584 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: setup
2025-07-23 15:41:44,320 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: setup
2025-07-23 15:41:44,501 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: setup
2025-07-23 15:41:44,511 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: setup
2025-07-23 15:41:44,673 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: setup
2025-07-23 15:41:44,758 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: setup
2025-07-23 15:41:44,758 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: setup
2025-07-23 15:41:44,758 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: setup
2025-07-23 15:41:44,759 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: setup
2025-07-23 15:41:45,702 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: configuring model
2025-07-23 15:41:45,703 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring module and callbacks from checkpoint path: None
2025-07-23 15:41:45,703 - lightning.pytorch.trainer.connectors.checkpoint_connector - DEBUG - `checkpoint_path` not specified. Skipping checkpoint loading.
2025-07-23 15:41:45,718 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [4,5,6,7]
2025-07-23 15:41:45,719 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_optimizers
2025-07-23 15:41:45,721 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_fit_start
2025-07-23 15:41:45,721 - lightning.pytorch.callbacks.model_summary - INFO - 
  | Name               | Type                                    | Params | Mode 
---------------------------------------------------------------------------------------
0 | gaussian_model     | VanillaGaussianModel                    | 2.0 M  | train
1 | renderer           | GSplatDistributedRendererImpl           | 0      | train
2 | density_controller | DistributedVanillaDensityControllerImpl | 0      | train
3 | metric             | VanillaMetricsImpl                      | 0      | train
---------------------------------------------------------------------------------------
2.0 M     Trainable params
0         Non-trainable params
2.0 M     Total params
8.026     Total estimated model params size (MB)
6         Modules in train mode
0         Modules in eval mode
2025-07-23 15:41:45,721 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_fit_start
2025-07-23 15:41:45,957 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring training state
2025-07-23 15:44:38,994 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: Initializing trainer with parameters: {'self': <lightning.pytorch.trainer.trainer.Trainer object at 0x70d4589cce30>, 'accelerator': 'gpu', 'strategy': <internal.mp_strategy.MPStrategy object at 0x70d45870c6b0>, 'devices': -1, 'num_nodes': 1, 'precision': None, 'logger': <lightning.pytorch.loggers.tensorboard.TensorBoardLogger object at 0x70d458589a90>, 'callbacks': [<internal.entrypoints.gspl.LazyInstance_SaveGaussian object at 0x70d638358e00>, <internal.entrypoints.gspl.LazyInstance_ValidateOnTrainEnd object at 0x70d458a292e0>, <internal.entrypoints.gspl.LazyInstance_KeepRunningIfWebViewerEnabled object at 0x70d4589ce6f0>, <internal.entrypoints.gspl.LazyInstance_StopImageSavingThreads object at 0x70d46413e030>, <internal.entrypoints.gspl.LazyInstance_ProgressBar object at 0x70d4587ebad0>, <internal.entrypoints.gspl.LazyInstance_StopDataLoaderCacheThread object at 0x70d4589ce540>, <internal.callbacks.MySaveConfigCallback object at 0x70d4643ab470>], 'fast_dev_run': False, 'max_epochs': None, 'min_epochs': None, 'max_steps': 30000, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'overfit_batches': 0.0, 'val_check_interval': None, 'check_val_every_n_epoch': 1, 'num_sanity_val_steps': 1, 'log_every_n_steps': None, 'enable_checkpointing': False, 'enable_progress_bar': None, 'enable_model_summary': None, 'accumulate_grad_batches': 1, 'gradient_clip_val': None, 'gradient_clip_algorithm': None, 'deterministic': None, 'benchmark': None, 'inference_mode': True, 'use_distributed_sampler': False, 'profiler': None, 'detect_anomaly': False, 'barebones': False, 'plugins': None, 'sync_batchnorm': False, 'reload_dataloaders_every_n_epochs': 0, 'default_root_dir': None, 'model_registry': None, '__class__': <class 'lightning.pytorch.trainer.trainer.Trainer'>}
2025-07-23 15:44:39,061 - lightning.pytorch.utilities.rank_zero - INFO - GPU available: True (cuda), used: True
2025-07-23 15:44:39,061 - lightning.pytorch.utilities.rank_zero - INFO - TPU available: False, using: 0 TPU cores
2025-07-23 15:44:39,061 - lightning.pytorch.utilities.rank_zero - INFO - HPU available: False, using: 0 HPUs
2025-07-23 15:44:39,138 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: trainer fit stage
2025-07-23 15:44:39,138 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_callbacks
2025-07-23 15:44:39,139 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: setting up strategy environment
2025-07-23 15:44:44,666 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: Initializing trainer with parameters: {'self': <lightning.pytorch.trainer.trainer.Trainer object at 0x747ec169ec00>, 'accelerator': 'gpu', 'strategy': <internal.mp_strategy.MPStrategy object at 0x747ec19546b0>, 'devices': -1, 'num_nodes': 1, 'precision': None, 'logger': <lightning.pytorch.loggers.tensorboard.TensorBoardLogger object at 0x747ec1b38500>, 'callbacks': [<internal.entrypoints.gspl.LazyInstance_SaveGaussian object at 0x747ec1dee2d0>, <internal.entrypoints.gspl.LazyInstance_ValidateOnTrainEnd object at 0x747ec1d01fd0>, <internal.entrypoints.gspl.LazyInstance_KeepRunningIfWebViewerEnabled object at 0x747ec1a8faa0>, <internal.entrypoints.gspl.LazyInstance_StopImageSavingThreads object at 0x747ec1a8fad0>, <internal.entrypoints.gspl.LazyInstance_ProgressBar object at 0x747ec1af0a40>, <internal.entrypoints.gspl.LazyInstance_StopDataLoaderCacheThread object at 0x747ec1db1190>, <internal.callbacks.MySaveConfigCallback object at 0x747ec19efe30>], 'fast_dev_run': False, 'max_epochs': None, 'min_epochs': None, 'max_steps': 30000, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'overfit_batches': 0.0, 'val_check_interval': None, 'check_val_every_n_epoch': 1, 'num_sanity_val_steps': 1, 'log_every_n_steps': None, 'enable_checkpointing': False, 'enable_progress_bar': None, 'enable_model_summary': None, 'accumulate_grad_batches': 1, 'gradient_clip_val': None, 'gradient_clip_algorithm': None, 'deterministic': None, 'benchmark': None, 'inference_mode': True, 'use_distributed_sampler': False, 'profiler': None, 'detect_anomaly': False, 'barebones': False, 'plugins': None, 'sync_batchnorm': False, 'reload_dataloaders_every_n_epochs': 0, 'default_root_dir': None, 'model_registry': None, '__class__': <class 'lightning.pytorch.trainer.trainer.Trainer'>}
2025-07-23 15:44:44,734 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: trainer fit stage
2025-07-23 15:44:44,735 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_callbacks
2025-07-23 15:44:44,735 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: setting up strategy environment
2025-07-23 15:44:44,857 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: Initializing trainer with parameters: {'self': <lightning.pytorch.trainer.trainer.Trainer object at 0x75bca807cb30>, 'accelerator': 'gpu', 'strategy': <internal.mp_strategy.MPStrategy object at 0x75bca82e1f40>, 'devices': -1, 'num_nodes': 1, 'precision': None, 'logger': <lightning.pytorch.loggers.tensorboard.TensorBoardLogger object at 0x75bca813e0c0>, 'callbacks': [<internal.entrypoints.gspl.LazyInstance_SaveGaussian object at 0x75be880d0e00>, <internal.entrypoints.gspl.LazyInstance_ValidateOnTrainEnd object at 0x75bca88892e0>, <internal.entrypoints.gspl.LazyInstance_KeepRunningIfWebViewerEnabled object at 0x75bca8a267b0>, <internal.entrypoints.gspl.LazyInstance_StopImageSavingThreads object at 0x75bcb40b7770>, <internal.entrypoints.gspl.LazyInstance_ProgressBar object at 0x75bca8856150>, <internal.entrypoints.gspl.LazyInstance_StopDataLoaderCacheThread object at 0x75bca8739190>, <internal.callbacks.MySaveConfigCallback object at 0x75bca8053ef0>], 'fast_dev_run': False, 'max_epochs': None, 'min_epochs': None, 'max_steps': 30000, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'overfit_batches': 0.0, 'val_check_interval': None, 'check_val_every_n_epoch': 1, 'num_sanity_val_steps': 1, 'log_every_n_steps': None, 'enable_checkpointing': False, 'enable_progress_bar': None, 'enable_model_summary': None, 'accumulate_grad_batches': 1, 'gradient_clip_val': None, 'gradient_clip_algorithm': None, 'deterministic': None, 'benchmark': None, 'inference_mode': True, 'use_distributed_sampler': False, 'profiler': None, 'detect_anomaly': False, 'barebones': False, 'plugins': None, 'sync_batchnorm': False, 'reload_dataloaders_every_n_epochs': 0, 'default_root_dir': None, 'model_registry': None, '__class__': <class 'lightning.pytorch.trainer.trainer.Trainer'>}
2025-07-23 15:44:44,922 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: Initializing trainer with parameters: {'self': <lightning.pytorch.trainer.trainer.Trainer object at 0x75342caf0350>, 'accelerator': 'gpu', 'strategy': <internal.mp_strategy.MPStrategy object at 0x75342c814920>, 'devices': -1, 'num_nodes': 1, 'precision': None, 'logger': <lightning.pytorch.loggers.tensorboard.TensorBoardLogger object at 0x75342c6ecfb0>, 'callbacks': [<internal.entrypoints.gspl.LazyInstance_SaveGaussian object at 0x75342cdc5460>, <internal.entrypoints.gspl.LazyInstance_ValidateOnTrainEnd object at 0x75342ca934a0>, <internal.entrypoints.gspl.LazyInstance_KeepRunningIfWebViewerEnabled object at 0x7534387af8f0>, <internal.entrypoints.gspl.LazyInstance_StopImageSavingThreads object at 0x75342cb53920>, <internal.entrypoints.gspl.LazyInstance_ProgressBar object at 0x75343839fc80>, <internal.entrypoints.gspl.LazyInstance_StopDataLoaderCacheThread object at 0x75342cd690a0>, <internal.callbacks.MySaveConfigCallback object at 0x75342c8caf00>], 'fast_dev_run': False, 'max_epochs': None, 'min_epochs': None, 'max_steps': 30000, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'overfit_batches': 0.0, 'val_check_interval': None, 'check_val_every_n_epoch': 1, 'num_sanity_val_steps': 1, 'log_every_n_steps': None, 'enable_checkpointing': False, 'enable_progress_bar': None, 'enable_model_summary': None, 'accumulate_grad_batches': 1, 'gradient_clip_val': None, 'gradient_clip_algorithm': None, 'deterministic': None, 'benchmark': None, 'inference_mode': True, 'use_distributed_sampler': False, 'profiler': None, 'detect_anomaly': False, 'barebones': False, 'plugins': None, 'sync_batchnorm': False, 'reload_dataloaders_every_n_epochs': 0, 'default_root_dir': None, 'model_registry': None, '__class__': <class 'lightning.pytorch.trainer.trainer.Trainer'>}
2025-07-23 15:44:44,933 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: trainer fit stage
2025-07-23 15:44:44,934 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_callbacks
2025-07-23 15:44:44,934 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: setting up strategy environment
2025-07-23 15:44:44,991 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: trainer fit stage
2025-07-23 15:44:44,992 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_callbacks
2025-07-23 15:44:44,992 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: setting up strategy environment
2025-07-23 15:44:45,155 - lightning.pytorch.utilities.rank_zero - INFO - ----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 4 processes
----------------------------------------------------------------------------------------------------

2025-07-23 15:44:45,168 - lightning.pytorch.utilities.rank_zero - INFO - You are using a CUDA device ('NVIDIA GeForce RTX 3090 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
2025-07-23 15:44:45,618 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: preparing data
2025-07-23 15:44:45,651 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: preparing data
2025-07-23 15:44:45,659 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: preparing data
2025-07-23 15:44:45,668 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: preparing data
2025-07-23 15:44:45,677 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: setup
2025-07-23 15:44:45,677 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: setup
2025-07-23 15:44:45,677 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: setup
2025-07-23 15:44:45,677 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: setup
2025-07-23 15:44:47,391 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: setup
2025-07-23 15:44:47,447 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: setup
2025-07-23 15:44:47,555 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: setup
2025-07-23 15:44:47,795 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: setup
2025-07-23 15:44:47,892 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: setup
2025-07-23 15:44:47,892 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: setup
2025-07-23 15:44:47,892 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: setup
2025-07-23 15:44:47,893 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: setup
2025-07-23 15:44:49,029 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: configuring model
2025-07-23 15:44:49,030 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring module and callbacks from checkpoint path: None
2025-07-23 15:44:49,030 - lightning.pytorch.trainer.connectors.checkpoint_connector - DEBUG - `checkpoint_path` not specified. Skipping checkpoint loading.
2025-07-23 15:44:49,045 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [4,5,6,7]
2025-07-23 15:44:49,046 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_optimizers
2025-07-23 15:44:49,049 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_fit_start
2025-07-23 15:44:49,050 - lightning.pytorch.callbacks.model_summary - INFO - 
  | Name               | Type                                    | Params | Mode 
---------------------------------------------------------------------------------------
0 | gaussian_model     | VanillaGaussianModel                    | 2.0 M  | train
1 | renderer           | GSplatDistributedRendererImpl           | 0      | train
2 | density_controller | DistributedVanillaDensityControllerImpl | 0      | train
3 | metric             | VanillaMetricsImpl                      | 0      | train
---------------------------------------------------------------------------------------
2.0 M     Trainable params
0         Non-trainable params
2.0 M     Total params
8.026     Total estimated model params size (MB)
6         Modules in train mode
0         Modules in eval mode
2025-07-23 15:44:49,050 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_fit_start
2025-07-23 15:44:49,409 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring training state
2025-07-23 15:51:37,744 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: Initializing trainer with parameters: {'self': <lightning.pytorch.trainer.trainer.Trainer object at 0x74ab9f789970>, 'accelerator': 'gpu', 'strategy': <internal.mp_strategy.MPStrategy object at 0x74ab9f6da4b0>, 'devices': -1, 'num_nodes': 1, 'precision': None, 'logger': <lightning.pytorch.loggers.tensorboard.TensorBoardLogger object at 0x74ab9f6b9a60>, 'callbacks': [<internal.entrypoints.gspl.LazyInstance_SaveGaussian object at 0x74abacd87ef0>, <internal.entrypoints.gspl.LazyInstance_ValidateOnTrainEnd object at 0x74ab9f931130>, <internal.entrypoints.gspl.LazyInstance_KeepRunningIfWebViewerEnabled object at 0x74ab9fa139e0>, <internal.entrypoints.gspl.LazyInstance_StopImageSavingThreads object at 0x74abab58da00>, <internal.entrypoints.gspl.LazyInstance_ProgressBar object at 0x74ab9f9eb9b0>, <internal.entrypoints.gspl.LazyInstance_StopDataLoaderCacheThread object at 0x74ab9f9e9ac0>, <internal.callbacks.MySaveConfigCallback object at 0x74ab9f542540>], 'fast_dev_run': False, 'max_epochs': None, 'min_epochs': None, 'max_steps': 30000, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'overfit_batches': 0.0, 'val_check_interval': None, 'check_val_every_n_epoch': 1, 'num_sanity_val_steps': 1, 'log_every_n_steps': None, 'enable_checkpointing': False, 'enable_progress_bar': None, 'enable_model_summary': None, 'accumulate_grad_batches': 1, 'gradient_clip_val': None, 'gradient_clip_algorithm': None, 'deterministic': None, 'benchmark': None, 'inference_mode': True, 'use_distributed_sampler': False, 'profiler': None, 'detect_anomaly': False, 'barebones': False, 'plugins': None, 'sync_batchnorm': False, 'reload_dataloaders_every_n_epochs': 0, 'default_root_dir': None, 'model_registry': None, '__class__': <class 'lightning.pytorch.trainer.trainer.Trainer'>}
2025-07-23 15:51:37,809 - lightning.pytorch.utilities.rank_zero - INFO - GPU available: True (cuda), used: True
2025-07-23 15:51:37,810 - lightning.pytorch.utilities.rank_zero - INFO - TPU available: False, using: 0 TPU cores
2025-07-23 15:51:37,810 - lightning.pytorch.utilities.rank_zero - INFO - HPU available: False, using: 0 HPUs
2025-07-23 15:51:37,885 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: trainer fit stage
2025-07-23 15:51:37,886 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_callbacks
2025-07-23 15:51:37,886 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: setting up strategy environment
2025-07-23 15:51:43,152 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: Initializing trainer with parameters: {'self': <lightning.pytorch.trainer.trainer.Trainer object at 0x7f80ae051fa0>, 'accelerator': 'gpu', 'strategy': <internal.mp_strategy.MPStrategy object at 0x7f80adeb8f80>, 'devices': -1, 'num_nodes': 1, 'precision': None, 'logger': <lightning.pytorch.loggers.tensorboard.TensorBoardLogger object at 0x7f80adf14320>, 'callbacks': [<internal.entrypoints.gspl.LazyInstance_SaveGaussian object at 0x7f80b9d68140>, <internal.entrypoints.gspl.LazyInstance_ValidateOnTrainEnd object at 0x7f80ae4615e0>, <internal.entrypoints.gspl.LazyInstance_KeepRunningIfWebViewerEnabled object at 0x7f80ae5fe3f0>, <internal.entrypoints.gspl.LazyInstance_StopImageSavingThreads object at 0x7f80b9a7fce0>, <internal.entrypoints.gspl.LazyInstance_ProgressBar object at 0x7f80ae463bc0>, <internal.entrypoints.gspl.LazyInstance_StopDataLoaderCacheThread object at 0x7f80ae4b6a80>, <internal.callbacks.MySaveConfigCallback object at 0x7f80adf53ef0>], 'fast_dev_run': False, 'max_epochs': None, 'min_epochs': None, 'max_steps': 30000, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'overfit_batches': 0.0, 'val_check_interval': None, 'check_val_every_n_epoch': 1, 'num_sanity_val_steps': 1, 'log_every_n_steps': None, 'enable_checkpointing': False, 'enable_progress_bar': None, 'enable_model_summary': None, 'accumulate_grad_batches': 1, 'gradient_clip_val': None, 'gradient_clip_algorithm': None, 'deterministic': None, 'benchmark': None, 'inference_mode': True, 'use_distributed_sampler': False, 'profiler': None, 'detect_anomaly': False, 'barebones': False, 'plugins': None, 'sync_batchnorm': False, 'reload_dataloaders_every_n_epochs': 0, 'default_root_dir': None, 'model_registry': None, '__class__': <class 'lightning.pytorch.trainer.trainer.Trainer'>}
2025-07-23 15:51:43,208 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: Initializing trainer with parameters: {'self': <lightning.pytorch.trainer.trainer.Trainer object at 0x7be647545580>, 'accelerator': 'gpu', 'strategy': <internal.mp_strategy.MPStrategy object at 0x7be6476a0950>, 'devices': -1, 'num_nodes': 1, 'precision': None, 'logger': <lightning.pytorch.loggers.tensorboard.TensorBoardLogger object at 0x7be6476e18e0>, 'callbacks': [<internal.entrypoints.gspl.LazyInstance_SaveGaussian object at 0x7be827514e00>, <internal.entrypoints.gspl.LazyInstance_ValidateOnTrainEnd object at 0x7be647d10860>, <internal.entrypoints.gspl.LazyInstance_KeepRunningIfWebViewerEnabled object at 0x7be6537c7170>, <internal.entrypoints.gspl.LazyInstance_StopImageSavingThreads object at 0x7be647b47560>, <internal.entrypoints.gspl.LazyInstance_ProgressBar object at 0x7be647ae7350>, <internal.entrypoints.gspl.LazyInstance_StopDataLoaderCacheThread object at 0x7be647b44f20>, <internal.callbacks.MySaveConfigCallback object at 0x7be647478a70>], 'fast_dev_run': False, 'max_epochs': None, 'min_epochs': None, 'max_steps': 30000, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'overfit_batches': 0.0, 'val_check_interval': None, 'check_val_every_n_epoch': 1, 'num_sanity_val_steps': 1, 'log_every_n_steps': None, 'enable_checkpointing': False, 'enable_progress_bar': None, 'enable_model_summary': None, 'accumulate_grad_batches': 1, 'gradient_clip_val': None, 'gradient_clip_algorithm': None, 'deterministic': None, 'benchmark': None, 'inference_mode': True, 'use_distributed_sampler': False, 'profiler': None, 'detect_anomaly': False, 'barebones': False, 'plugins': None, 'sync_batchnorm': False, 'reload_dataloaders_every_n_epochs': 0, 'default_root_dir': None, 'model_registry': None, '__class__': <class 'lightning.pytorch.trainer.trainer.Trainer'>}
2025-07-23 15:51:43,218 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: trainer fit stage
2025-07-23 15:51:43,219 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_callbacks
2025-07-23 15:51:43,219 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: setting up strategy environment
2025-07-23 15:51:43,315 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: trainer fit stage
2025-07-23 15:51:43,315 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_callbacks
2025-07-23 15:51:43,316 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: setting up strategy environment
2025-07-23 15:51:43,655 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: Initializing trainer with parameters: {'self': <lightning.pytorch.trainer.trainer.Trainer object at 0x79c3a7dd2180>, 'accelerator': 'gpu', 'strategy': <internal.mp_strategy.MPStrategy object at 0x79c3a7c14290>, 'devices': -1, 'num_nodes': 1, 'precision': None, 'logger': <lightning.pytorch.loggers.tensorboard.TensorBoardLogger object at 0x79c3a7c16a80>, 'callbacks': [<internal.entrypoints.gspl.LazyInstance_SaveGaussian object at 0x79c587a78e00>, <internal.entrypoints.gspl.LazyInstance_ValidateOnTrainEnd object at 0x79c3a80919a0>, <internal.entrypoints.gspl.LazyInstance_KeepRunningIfWebViewerEnabled object at 0x79c3a80cfbf0>, <internal.entrypoints.gspl.LazyInstance_StopImageSavingThreads object at 0x79c3a837e2a0>, <internal.entrypoints.gspl.LazyInstance_ProgressBar object at 0x79c3a81e3bc0>, <internal.entrypoints.gspl.LazyInstance_StopDataLoaderCacheThread object at 0x79c3a82f63c0>, <internal.callbacks.MySaveConfigCallback object at 0x79c3a7a29d60>], 'fast_dev_run': False, 'max_epochs': None, 'min_epochs': None, 'max_steps': 30000, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'overfit_batches': 0.0, 'val_check_interval': None, 'check_val_every_n_epoch': 1, 'num_sanity_val_steps': 1, 'log_every_n_steps': None, 'enable_checkpointing': False, 'enable_progress_bar': None, 'enable_model_summary': None, 'accumulate_grad_batches': 1, 'gradient_clip_val': None, 'gradient_clip_algorithm': None, 'deterministic': None, 'benchmark': None, 'inference_mode': True, 'use_distributed_sampler': False, 'profiler': None, 'detect_anomaly': False, 'barebones': False, 'plugins': None, 'sync_batchnorm': False, 'reload_dataloaders_every_n_epochs': 0, 'default_root_dir': None, 'model_registry': None, '__class__': <class 'lightning.pytorch.trainer.trainer.Trainer'>}
2025-07-23 15:51:43,724 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: trainer fit stage
2025-07-23 15:51:43,725 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_callbacks
2025-07-23 15:51:43,725 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: setting up strategy environment
2025-07-23 15:51:43,830 - lightning.pytorch.utilities.rank_zero - INFO - ----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 4 processes
----------------------------------------------------------------------------------------------------

2025-07-23 15:51:43,838 - lightning.pytorch.utilities.rank_zero - INFO - You are using a CUDA device ('NVIDIA GeForce RTX 3090 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
2025-07-23 15:51:44,373 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: preparing data
2025-07-23 15:51:44,405 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: preparing data
2025-07-23 15:51:44,429 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: preparing data
2025-07-23 15:51:44,433 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: preparing data
2025-07-23 15:51:44,444 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: setup
2025-07-23 15:51:44,444 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: setup
2025-07-23 15:51:44,445 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: setup
2025-07-23 15:51:44,444 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: setup
2025-07-23 15:51:46,369 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: setup
2025-07-23 15:51:46,382 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: setup
2025-07-23 15:51:46,419 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: setup
2025-07-23 15:51:47,158 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: setup
2025-07-23 15:51:47,242 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: setup
2025-07-23 15:51:47,242 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: setup
2025-07-23 15:51:47,242 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: setup
2025-07-23 15:51:47,242 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: setup
2025-07-23 15:51:48,378 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: configuring model
2025-07-23 15:51:48,378 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring module and callbacks from checkpoint path: None
2025-07-23 15:51:48,378 - lightning.pytorch.trainer.connectors.checkpoint_connector - DEBUG - `checkpoint_path` not specified. Skipping checkpoint loading.
2025-07-23 15:51:48,394 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [4,5,6,7]
2025-07-23 15:51:48,395 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_optimizers
2025-07-23 15:51:48,397 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_fit_start
2025-07-23 15:51:48,397 - lightning.pytorch.callbacks.model_summary - INFO - 
  | Name               | Type                                    | Params | Mode 
---------------------------------------------------------------------------------------
0 | gaussian_model     | VanillaGaussianModel                    | 2.0 M  | train
1 | renderer           | GSplatDistributedRendererImpl           | 0      | train
2 | density_controller | DistributedVanillaDensityControllerImpl | 0      | train
3 | metric             | VanillaMetricsImpl                      | 0      | train
---------------------------------------------------------------------------------------
2.0 M     Trainable params
0         Non-trainable params
2.0 M     Total params
8.026     Total estimated model params size (MB)
6         Modules in train mode
0         Modules in eval mode
2025-07-23 15:51:48,398 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_fit_start
2025-07-23 15:51:48,734 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring training state
2025-07-23 15:55:12,303 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: Initializing trainer with parameters: {'self': <lightning.pytorch.trainer.trainer.Trainer object at 0x7aeda1769790>, 'accelerator': 'gpu', 'strategy': <internal.mp_strategy.MPStrategy object at 0x7aeda10d3710>, 'devices': -1, 'num_nodes': 1, 'precision': None, 'logger': <lightning.pytorch.loggers.tensorboard.TensorBoardLogger object at 0x7aeda10d2fc0>, 'callbacks': [<internal.entrypoints.gspl.LazyInstance_SaveGaussian object at 0x7aef80f6cd70>, <internal.entrypoints.gspl.LazyInstance_ValidateOnTrainEnd object at 0x7aeda1587ce0>, <internal.entrypoints.gspl.LazyInstance_KeepRunningIfWebViewerEnabled object at 0x7aeda1718e30>, <internal.entrypoints.gspl.LazyInstance_StopImageSavingThreads object at 0x7aeda14edca0>, <internal.entrypoints.gspl.LazyInstance_ProgressBar object at 0x7aeda128c890>, <internal.entrypoints.gspl.LazyInstance_StopDataLoaderCacheThread object at 0x7aedacf2fa40>, <internal.callbacks.MySaveConfigCallback object at 0x7aeda11892e0>], 'fast_dev_run': False, 'max_epochs': None, 'min_epochs': None, 'max_steps': 30000, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'overfit_batches': 0.0, 'val_check_interval': None, 'check_val_every_n_epoch': 1, 'num_sanity_val_steps': 1, 'log_every_n_steps': None, 'enable_checkpointing': False, 'enable_progress_bar': None, 'enable_model_summary': None, 'accumulate_grad_batches': 1, 'gradient_clip_val': None, 'gradient_clip_algorithm': None, 'deterministic': None, 'benchmark': None, 'inference_mode': True, 'use_distributed_sampler': False, 'profiler': None, 'detect_anomaly': False, 'barebones': False, 'plugins': None, 'sync_batchnorm': False, 'reload_dataloaders_every_n_epochs': 0, 'default_root_dir': None, 'model_registry': None, '__class__': <class 'lightning.pytorch.trainer.trainer.Trainer'>}
2025-07-23 15:55:12,367 - lightning.pytorch.utilities.rank_zero - INFO - GPU available: True (cuda), used: True
2025-07-23 15:55:12,368 - lightning.pytorch.utilities.rank_zero - INFO - TPU available: False, using: 0 TPU cores
2025-07-23 15:55:12,368 - lightning.pytorch.utilities.rank_zero - INFO - HPU available: False, using: 0 HPUs
2025-07-23 15:55:12,445 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: trainer fit stage
2025-07-23 15:55:12,446 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_callbacks
2025-07-23 15:55:12,446 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: setting up strategy environment
2025-07-23 15:55:17,889 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: Initializing trainer with parameters: {'self': <lightning.pytorch.trainer.trainer.Trainer object at 0x7cbd55dae210>, 'accelerator': 'gpu', 'strategy': <internal.mp_strategy.MPStrategy object at 0x7cbd55bec6b0>, 'devices': -1, 'num_nodes': 1, 'precision': None, 'logger': <lightning.pytorch.loggers.tensorboard.TensorBoardLogger object at 0x7cbd55dadd30>, 'callbacks': [<internal.entrypoints.gspl.LazyInstance_SaveGaussian object at 0x7cbf359f0e00>, <internal.entrypoints.gspl.LazyInstance_ValidateOnTrainEnd object at 0x7cbd5618bf50>, <internal.entrypoints.gspl.LazyInstance_KeepRunningIfWebViewerEnabled object at 0x7cbd6170bfb0>, <internal.entrypoints.gspl.LazyInstance_StopImageSavingThreads object at 0x7cbd61d0bf20>, <internal.entrypoints.gspl.LazyInstance_ProgressBar object at 0x7cbd55edd910>, <internal.entrypoints.gspl.LazyInstance_StopDataLoaderCacheThread object at 0x7cbd61ae8380>, <internal.callbacks.MySaveConfigCallback object at 0x7cbd55daef60>], 'fast_dev_run': False, 'max_epochs': None, 'min_epochs': None, 'max_steps': 30000, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'overfit_batches': 0.0, 'val_check_interval': None, 'check_val_every_n_epoch': 1, 'num_sanity_val_steps': 1, 'log_every_n_steps': None, 'enable_checkpointing': False, 'enable_progress_bar': None, 'enable_model_summary': None, 'accumulate_grad_batches': 1, 'gradient_clip_val': None, 'gradient_clip_algorithm': None, 'deterministic': None, 'benchmark': None, 'inference_mode': True, 'use_distributed_sampler': False, 'profiler': None, 'detect_anomaly': False, 'barebones': False, 'plugins': None, 'sync_batchnorm': False, 'reload_dataloaders_every_n_epochs': 0, 'default_root_dir': None, 'model_registry': None, '__class__': <class 'lightning.pytorch.trainer.trainer.Trainer'>}
2025-07-23 15:55:17,958 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: trainer fit stage
2025-07-23 15:55:17,958 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_callbacks
2025-07-23 15:55:17,959 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: setting up strategy environment
2025-07-23 15:55:18,018 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: Initializing trainer with parameters: {'self': <lightning.pytorch.trainer.trainer.Trainer object at 0x79ede0fcecf0>, 'accelerator': 'gpu', 'strategy': <internal.mp_strategy.MPStrategy object at 0x79ede0e28ec0>, 'devices': -1, 'num_nodes': 1, 'precision': None, 'logger': <lightning.pytorch.loggers.tensorboard.TensorBoardLogger object at 0x79edecc98b60>, 'callbacks': [<internal.entrypoints.gspl.LazyInstance_SaveGaussian object at 0x79efc0c5cdd0>, <internal.entrypoints.gspl.LazyInstance_ValidateOnTrainEnd object at 0x79ede1211130>, <internal.entrypoints.gspl.LazyInstance_KeepRunningIfWebViewerEnabled object at 0x79ede1352750>, <internal.entrypoints.gspl.LazyInstance_StopImageSavingThreads object at 0x79eded546570>, <internal.entrypoints.gspl.LazyInstance_ProgressBar object at 0x79ede15a91f0>, <internal.entrypoints.gspl.LazyInstance_StopDataLoaderCacheThread object at 0x79ede13df200>, <internal.callbacks.MySaveConfigCallback object at 0x79ede12c5bb0>], 'fast_dev_run': False, 'max_epochs': None, 'min_epochs': None, 'max_steps': 30000, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'overfit_batches': 0.0, 'val_check_interval': None, 'check_val_every_n_epoch': 1, 'num_sanity_val_steps': 1, 'log_every_n_steps': None, 'enable_checkpointing': False, 'enable_progress_bar': None, 'enable_model_summary': None, 'accumulate_grad_batches': 1, 'gradient_clip_val': None, 'gradient_clip_algorithm': None, 'deterministic': None, 'benchmark': None, 'inference_mode': True, 'use_distributed_sampler': False, 'profiler': None, 'detect_anomaly': False, 'barebones': False, 'plugins': None, 'sync_batchnorm': False, 'reload_dataloaders_every_n_epochs': 0, 'default_root_dir': None, 'model_registry': None, '__class__': <class 'lightning.pytorch.trainer.trainer.Trainer'>}
2025-07-23 15:55:18,103 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: trainer fit stage
2025-07-23 15:55:18,104 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_callbacks
2025-07-23 15:55:18,104 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: setting up strategy environment
2025-07-23 15:55:18,367 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: Initializing trainer with parameters: {'self': <lightning.pytorch.trainer.trainer.Trainer object at 0x7c9ec1619790>, 'accelerator': 'gpu', 'strategy': <internal.mp_strategy.MPStrategy object at 0x7c9ce157c6b0>, 'devices': -1, 'num_nodes': 1, 'precision': None, 'logger': <lightning.pytorch.loggers.tensorboard.TensorBoardLogger object at 0x7c9ce13ac320>, 'callbacks': [<internal.entrypoints.gspl.LazyInstance_SaveGaussian object at 0x7c9ec1364ef0>, <internal.entrypoints.gspl.LazyInstance_ValidateOnTrainEnd object at 0x7c9ce1a8e810>, <internal.entrypoints.gspl.LazyInstance_KeepRunningIfWebViewerEnabled object at 0x7c9ce19a3b00>, <internal.entrypoints.gspl.LazyInstance_StopImageSavingThreads object at 0x7c9ce1975910>, <internal.entrypoints.gspl.LazyInstance_ProgressBar object at 0x7c9ce167c980>, <internal.entrypoints.gspl.LazyInstance_StopDataLoaderCacheThread object at 0x7c9ce18c23c0>, <internal.callbacks.MySaveConfigCallback object at 0x7c9ce16fed80>], 'fast_dev_run': False, 'max_epochs': None, 'min_epochs': None, 'max_steps': 30000, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'overfit_batches': 0.0, 'val_check_interval': None, 'check_val_every_n_epoch': 1, 'num_sanity_val_steps': 1, 'log_every_n_steps': None, 'enable_checkpointing': False, 'enable_progress_bar': None, 'enable_model_summary': None, 'accumulate_grad_batches': 1, 'gradient_clip_val': None, 'gradient_clip_algorithm': None, 'deterministic': None, 'benchmark': None, 'inference_mode': True, 'use_distributed_sampler': False, 'profiler': None, 'detect_anomaly': False, 'barebones': False, 'plugins': None, 'sync_batchnorm': False, 'reload_dataloaders_every_n_epochs': 0, 'default_root_dir': None, 'model_registry': None, '__class__': <class 'lightning.pytorch.trainer.trainer.Trainer'>}
2025-07-23 15:55:18,435 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: trainer fit stage
2025-07-23 15:55:18,435 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_callbacks
2025-07-23 15:55:18,436 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: setting up strategy environment
2025-07-23 15:55:18,527 - lightning.pytorch.utilities.rank_zero - INFO - ----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 4 processes
----------------------------------------------------------------------------------------------------

2025-07-23 15:55:18,533 - lightning.pytorch.utilities.rank_zero - INFO - You are using a CUDA device ('NVIDIA GeForce RTX 3090 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
2025-07-23 15:55:19,023 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: preparing data
2025-07-23 15:55:19,060 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: preparing data
2025-07-23 15:55:19,063 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: preparing data
2025-07-23 15:55:19,082 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: preparing data
2025-07-23 15:55:19,092 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: setup
2025-07-23 15:55:19,092 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: setup
2025-07-23 15:55:19,092 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: setup
2025-07-23 15:55:19,092 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: setup
2025-07-23 15:55:20,771 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: setup
2025-07-23 15:55:20,874 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: setup
2025-07-23 15:55:20,888 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: setup
2025-07-23 15:55:21,118 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: setup
2025-07-23 15:55:21,199 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: setup
2025-07-23 15:55:21,199 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: setup
2025-07-23 15:55:21,199 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: setup
2025-07-23 15:55:21,199 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: setup
2025-07-23 15:55:22,176 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: configuring model
2025-07-23 15:55:22,176 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring module and callbacks from checkpoint path: None
2025-07-23 15:55:22,176 - lightning.pytorch.trainer.connectors.checkpoint_connector - DEBUG - `checkpoint_path` not specified. Skipping checkpoint loading.
2025-07-23 15:55:22,192 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [4,5,6,7]
2025-07-23 15:55:22,192 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_optimizers
2025-07-23 15:55:22,194 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_fit_start
2025-07-23 15:55:22,195 - lightning.pytorch.callbacks.model_summary - INFO - 
  | Name               | Type                                    | Params | Mode 
---------------------------------------------------------------------------------------
0 | gaussian_model     | VanillaGaussianModel                    | 2.0 M  | train
1 | renderer           | GSplatDistributedRendererImpl           | 0      | train
2 | density_controller | DistributedVanillaDensityControllerImpl | 0      | train
3 | metric             | VanillaMetricsImpl                      | 0      | train
---------------------------------------------------------------------------------------
2.0 M     Trainable params
0         Non-trainable params
2.0 M     Total params
8.026     Total estimated model params size (MB)
6         Modules in train mode
0         Modules in eval mode
2025-07-23 15:55:22,195 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_fit_start
2025-07-23 15:55:22,438 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring training state
2025-07-23 15:58:57,764 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: Initializing trainer with parameters: {'self': <lightning.pytorch.trainer.trainer.Trainer object at 0x72d7f4027860>, 'accelerator': 'gpu', 'strategy': <internal.mp_strategy.MPStrategy object at 0x72d7f3e91a90>, 'devices': -1, 'num_nodes': 1, 'precision': None, 'logger': <lightning.pytorch.loggers.tensorboard.TensorBoardLogger object at 0x72d7f405df70>, 'callbacks': [<internal.entrypoints.gspl.LazyInstance_SaveGaussian object at 0x72d9d3c58c80>, <internal.entrypoints.gspl.LazyInstance_ValidateOnTrainEnd object at 0x72d7f44fc9e0>, <internal.entrypoints.gspl.LazyInstance_KeepRunningIfWebViewerEnabled object at 0x72d7ffc67470>, <internal.entrypoints.gspl.LazyInstance_StopImageSavingThreads object at 0x72d7f448faa0>, <internal.entrypoints.gspl.LazyInstance_ProgressBar object at 0x72d7f42cf950>, <internal.entrypoints.gspl.LazyInstance_StopDataLoaderCacheThread object at 0x72d7f43eb290>, <internal.callbacks.MySaveConfigCallback object at 0x72d7f4586570>], 'fast_dev_run': False, 'max_epochs': None, 'min_epochs': None, 'max_steps': 30000, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'overfit_batches': 0.0, 'val_check_interval': None, 'check_val_every_n_epoch': 1, 'num_sanity_val_steps': 1, 'log_every_n_steps': None, 'enable_checkpointing': False, 'enable_progress_bar': None, 'enable_model_summary': None, 'accumulate_grad_batches': 1, 'gradient_clip_val': None, 'gradient_clip_algorithm': None, 'deterministic': None, 'benchmark': None, 'inference_mode': True, 'use_distributed_sampler': False, 'profiler': None, 'detect_anomaly': False, 'barebones': False, 'plugins': None, 'sync_batchnorm': False, 'reload_dataloaders_every_n_epochs': 0, 'default_root_dir': None, 'model_registry': None, '__class__': <class 'lightning.pytorch.trainer.trainer.Trainer'>}
2025-07-23 15:58:57,831 - lightning.pytorch.utilities.rank_zero - INFO - GPU available: True (cuda), used: True
2025-07-23 15:58:57,832 - lightning.pytorch.utilities.rank_zero - INFO - TPU available: False, using: 0 TPU cores
2025-07-23 15:58:57,832 - lightning.pytorch.utilities.rank_zero - INFO - HPU available: False, using: 0 HPUs
2025-07-23 15:58:57,918 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: trainer fit stage
2025-07-23 15:58:57,919 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_callbacks
2025-07-23 15:58:57,919 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: setting up strategy environment
2025-07-23 15:59:03,364 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: Initializing trainer with parameters: {'self': <lightning.pytorch.trainer.trainer.Trainer object at 0x76fa2a370f20>, 'accelerator': 'gpu', 'strategy': <internal.mp_strategy.MPStrategy object at 0x76fa2a2b8230>, 'devices': -1, 'num_nodes': 1, 'precision': None, 'logger': <lightning.pytorch.loggers.tensorboard.TensorBoardLogger object at 0x76fa2a2a1f70>, 'callbacks': [<internal.entrypoints.gspl.LazyInstance_SaveGaussian object at 0x76fc0a0acef0>, <internal.entrypoints.gspl.LazyInstance_ValidateOnTrainEnd object at 0x76fa36078920>, <internal.entrypoints.gspl.LazyInstance_KeepRunningIfWebViewerEnabled object at 0x76fa2a58e0f0>, <internal.entrypoints.gspl.LazyInstance_StopImageSavingThreads object at 0x76fa2a538230>, <internal.entrypoints.gspl.LazyInstance_ProgressBar object at 0x76fa35e079e0>, <internal.entrypoints.gspl.LazyInstance_StopDataLoaderCacheThread object at 0x76fa2a980980>, <internal.callbacks.MySaveConfigCallback object at 0x76fa36039940>], 'fast_dev_run': False, 'max_epochs': None, 'min_epochs': None, 'max_steps': 30000, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'overfit_batches': 0.0, 'val_check_interval': None, 'check_val_every_n_epoch': 1, 'num_sanity_val_steps': 1, 'log_every_n_steps': None, 'enable_checkpointing': False, 'enable_progress_bar': None, 'enable_model_summary': None, 'accumulate_grad_batches': 1, 'gradient_clip_val': None, 'gradient_clip_algorithm': None, 'deterministic': None, 'benchmark': None, 'inference_mode': True, 'use_distributed_sampler': False, 'profiler': None, 'detect_anomaly': False, 'barebones': False, 'plugins': None, 'sync_batchnorm': False, 'reload_dataloaders_every_n_epochs': 0, 'default_root_dir': None, 'model_registry': None, '__class__': <class 'lightning.pytorch.trainer.trainer.Trainer'>}
2025-07-23 15:59:03,431 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: trainer fit stage
2025-07-23 15:59:03,432 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_callbacks
2025-07-23 15:59:03,432 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: setting up strategy environment
2025-07-23 15:59:03,483 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: Initializing trainer with parameters: {'self': <lightning.pytorch.trainer.trainer.Trainer object at 0x77d501d398b0>, 'accelerator': 'gpu', 'strategy': <internal.mp_strategy.MPStrategy object at 0x77d4f5b1c6b0>, 'devices': -1, 'num_nodes': 1, 'precision': None, 'logger': <lightning.pytorch.loggers.tensorboard.TensorBoardLogger object at 0x77d4f58ab740>, 'callbacks': [<internal.entrypoints.gspl.LazyInstance_SaveGaussian object at 0x77d4f5ee8140>, <internal.entrypoints.gspl.LazyInstance_ValidateOnTrainEnd object at 0x77d4f5e0a7e0>, <internal.entrypoints.gspl.LazyInstance_KeepRunningIfWebViewerEnabled object at 0x77d4f605ffb0>, <internal.entrypoints.gspl.LazyInstance_StopImageSavingThreads object at 0x77d4f5dabb00>, <internal.entrypoints.gspl.LazyInstance_ProgressBar object at 0x77d4f5d7f890>, <internal.entrypoints.gspl.LazyInstance_StopDataLoaderCacheThread object at 0x77d501728ec0>, <internal.callbacks.MySaveConfigCallback object at 0x77d4f58f14f0>], 'fast_dev_run': False, 'max_epochs': None, 'min_epochs': None, 'max_steps': 30000, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'overfit_batches': 0.0, 'val_check_interval': None, 'check_val_every_n_epoch': 1, 'num_sanity_val_steps': 1, 'log_every_n_steps': None, 'enable_checkpointing': False, 'enable_progress_bar': None, 'enable_model_summary': None, 'accumulate_grad_batches': 1, 'gradient_clip_val': None, 'gradient_clip_algorithm': None, 'deterministic': None, 'benchmark': None, 'inference_mode': True, 'use_distributed_sampler': False, 'profiler': None, 'detect_anomaly': False, 'barebones': False, 'plugins': None, 'sync_batchnorm': False, 'reload_dataloaders_every_n_epochs': 0, 'default_root_dir': None, 'model_registry': None, '__class__': <class 'lightning.pytorch.trainer.trainer.Trainer'>}
2025-07-23 15:59:03,587 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: trainer fit stage
2025-07-23 15:59:03,587 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_callbacks
2025-07-23 15:59:03,587 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: setting up strategy environment
2025-07-23 15:59:04,111 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: Initializing trainer with parameters: {'self': <lightning.pytorch.trainer.trainer.Trainer object at 0x7f5d17059c40>, 'accelerator': 'gpu', 'strategy': <internal.mp_strategy.MPStrategy object at 0x7f5d16ccc6b0>, 'devices': -1, 'num_nodes': 1, 'precision': None, 'logger': <lightning.pytorch.loggers.tensorboard.TensorBoardLogger object at 0x7f5d16dcda30>, 'callbacks': [<internal.entrypoints.gspl.LazyInstance_SaveGaussian object at 0x7f5d1705b5c0>, <internal.entrypoints.gspl.LazyInstance_ValidateOnTrainEnd object at 0x7f5d170c5910>, <internal.entrypoints.gspl.LazyInstance_KeepRunningIfWebViewerEnabled object at 0x7f5d1714eb70>, <internal.entrypoints.gspl.LazyInstance_StopImageSavingThreads object at 0x7f5d170c7560>, <internal.entrypoints.gspl.LazyInstance_ProgressBar object at 0x7f5d16dcca10>, <internal.entrypoints.gspl.LazyInstance_StopDataLoaderCacheThread object at 0x7f5d17232240>, <internal.callbacks.MySaveConfigCallback object at 0x7f5d16bbf980>], 'fast_dev_run': False, 'max_epochs': None, 'min_epochs': None, 'max_steps': 30000, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'overfit_batches': 0.0, 'val_check_interval': None, 'check_val_every_n_epoch': 1, 'num_sanity_val_steps': 1, 'log_every_n_steps': None, 'enable_checkpointing': False, 'enable_progress_bar': None, 'enable_model_summary': None, 'accumulate_grad_batches': 1, 'gradient_clip_val': None, 'gradient_clip_algorithm': None, 'deterministic': None, 'benchmark': None, 'inference_mode': True, 'use_distributed_sampler': False, 'profiler': None, 'detect_anomaly': False, 'barebones': False, 'plugins': None, 'sync_batchnorm': False, 'reload_dataloaders_every_n_epochs': 0, 'default_root_dir': None, 'model_registry': None, '__class__': <class 'lightning.pytorch.trainer.trainer.Trainer'>}
2025-07-23 15:59:04,179 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: trainer fit stage
2025-07-23 15:59:04,180 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_callbacks
2025-07-23 15:59:04,180 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: setting up strategy environment
2025-07-23 15:59:04,302 - lightning.pytorch.utilities.rank_zero - INFO - ----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 4 processes
----------------------------------------------------------------------------------------------------

2025-07-23 15:59:04,310 - lightning.pytorch.utilities.rank_zero - INFO - You are using a CUDA device ('NVIDIA GeForce RTX 3090 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
2025-07-23 15:59:04,887 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: preparing data
2025-07-23 15:59:04,931 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: preparing data
2025-07-23 15:59:04,936 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: preparing data
2025-07-23 15:59:04,947 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: preparing data
2025-07-23 15:59:04,957 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: setup
2025-07-23 15:59:04,957 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: setup
2025-07-23 15:59:04,957 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: setup
2025-07-23 15:59:04,957 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: setup
2025-07-23 15:59:07,390 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: setup
2025-07-23 15:59:07,390 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: setup
2025-07-23 15:59:07,390 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: setup
2025-07-23 15:59:07,390 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: setup
2025-07-23 15:59:07,470 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: setup
2025-07-23 16:06:12,089 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: Initializing trainer with parameters: {'self': <lightning.pytorch.trainer.trainer.Trainer object at 0x75e11896c7d0>, 'accelerator': 'gpu', 'strategy': <internal.mp_strategy.MPStrategy object at 0x75e118bf3aa0>, 'devices': -1, 'num_nodes': 1, 'precision': None, 'logger': <lightning.pytorch.loggers.tensorboard.TensorBoardLogger object at 0x75e118ad5af0>, 'callbacks': [<internal.entrypoints.gspl.LazyInstance_SaveGaussian object at 0x75e30c6c45c0>, <internal.entrypoints.gspl.LazyInstance_ValidateOnTrainEnd object at 0x75e119063ec0>, <internal.entrypoints.gspl.LazyInstance_KeepRunningIfWebViewerEnabled object at 0x75e118ed9b50>, <internal.entrypoints.gspl.LazyInstance_StopImageSavingThreads object at 0x75e119485100>, <internal.entrypoints.gspl.LazyInstance_ProgressBar object at 0x75e1252b6ab0>, <internal.entrypoints.gspl.LazyInstance_StopDataLoaderCacheThread object at 0x75e119485ca0>, <internal.callbacks.MySaveConfigCallback object at 0x75e11896c0e0>], 'fast_dev_run': False, 'max_epochs': None, 'min_epochs': None, 'max_steps': 30000, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'overfit_batches': 0.0, 'val_check_interval': None, 'check_val_every_n_epoch': 1, 'num_sanity_val_steps': 1, 'log_every_n_steps': None, 'enable_checkpointing': False, 'enable_progress_bar': None, 'enable_model_summary': None, 'accumulate_grad_batches': 1, 'gradient_clip_val': None, 'gradient_clip_algorithm': None, 'deterministic': None, 'benchmark': None, 'inference_mode': True, 'use_distributed_sampler': False, 'profiler': None, 'detect_anomaly': False, 'barebones': False, 'plugins': None, 'sync_batchnorm': False, 'reload_dataloaders_every_n_epochs': 0, 'default_root_dir': None, 'model_registry': None, '__class__': <class 'lightning.pytorch.trainer.trainer.Trainer'>}
2025-07-23 16:06:12,163 - lightning.pytorch.utilities.rank_zero - INFO - GPU available: True (cuda), used: True
2025-07-23 16:06:12,164 - lightning.pytorch.utilities.rank_zero - INFO - TPU available: False, using: 0 TPU cores
2025-07-23 16:06:12,164 - lightning.pytorch.utilities.rank_zero - INFO - HPU available: False, using: 0 HPUs
2025-07-23 16:06:12,321 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: trainer fit stage
2025-07-23 16:06:12,323 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_callbacks
2025-07-23 16:06:12,324 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: setting up strategy environment
2025-07-23 16:06:29,300 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: Initializing trainer with parameters: {'self': <lightning.pytorch.trainer.trainer.Trainer object at 0x7ed7c4e41c10>, 'accelerator': 'gpu', 'strategy': <internal.mp_strategy.MPStrategy object at 0x7ed7c52fe180>, 'devices': -1, 'num_nodes': 1, 'precision': None, 'logger': <lightning.pytorch.loggers.tensorboard.TensorBoardLogger object at 0x7ed7c55de720>, 'callbacks': [<internal.entrypoints.gspl.LazyInstance_SaveGaussian object at 0x7ed7c557eae0>, <internal.entrypoints.gspl.LazyInstance_ValidateOnTrainEnd object at 0x7ed7d1004140>, <internal.entrypoints.gspl.LazyInstance_KeepRunningIfWebViewerEnabled object at 0x7ed7d15acce0>, <internal.entrypoints.gspl.LazyInstance_StopImageSavingThreads object at 0x7ed7d13ccec0>, <internal.entrypoints.gspl.LazyInstance_ProgressBar object at 0x7ed7c557ff50>, <internal.entrypoints.gspl.LazyInstance_StopDataLoaderCacheThread object at 0x7ed7c57da8a0>, <internal.callbacks.MySaveConfigCallback object at 0x7ed7c4e43230>], 'fast_dev_run': False, 'max_epochs': None, 'min_epochs': None, 'max_steps': 30000, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'overfit_batches': 0.0, 'val_check_interval': None, 'check_val_every_n_epoch': 1, 'num_sanity_val_steps': 1, 'log_every_n_steps': None, 'enable_checkpointing': False, 'enable_progress_bar': None, 'enable_model_summary': None, 'accumulate_grad_batches': 1, 'gradient_clip_val': None, 'gradient_clip_algorithm': None, 'deterministic': None, 'benchmark': None, 'inference_mode': True, 'use_distributed_sampler': False, 'profiler': None, 'detect_anomaly': False, 'barebones': False, 'plugins': None, 'sync_batchnorm': False, 'reload_dataloaders_every_n_epochs': 0, 'default_root_dir': None, 'model_registry': None, '__class__': <class 'lightning.pytorch.trainer.trainer.Trainer'>}
2025-07-23 16:06:29,660 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: trainer fit stage
2025-07-23 16:06:29,670 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_callbacks
2025-07-23 16:06:29,680 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: setting up strategy environment
2025-07-23 16:06:29,944 - lightning.pytorch.utilities.rank_zero - INFO - ----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 2 processes
----------------------------------------------------------------------------------------------------

2025-07-23 16:06:30,103 - lightning.pytorch.utilities.rank_zero - INFO - You are using a CUDA device ('NVIDIA GeForce RTX 3090 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
2025-07-23 16:06:31,850 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: preparing data
2025-07-23 16:06:31,937 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: preparing data
2025-07-23 16:06:31,984 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: setup
2025-07-23 16:06:31,985 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: setup
2025-07-23 16:07:46,984 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: setup
2025-07-23 16:11:38,446 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: Initializing trainer with parameters: {'self': <lightning.pytorch.trainer.trainer.Trainer object at 0x720f39a8c290>, 'accelerator': 'gpu', 'strategy': <internal.mp_strategy.MPStrategy object at 0x720f39f0deb0>, 'devices': -1, 'num_nodes': 1, 'precision': None, 'logger': <lightning.pytorch.loggers.tensorboard.TensorBoardLogger object at 0x720f39e5eb10>, 'callbacks': [<internal.entrypoints.gspl.LazyInstance_SaveGaussian object at 0x720f45c97ef0>, <internal.entrypoints.gspl.LazyInstance_ValidateOnTrainEnd object at 0x720f3a3315e0>, <internal.entrypoints.gspl.LazyInstance_KeepRunningIfWebViewerEnabled object at 0x720f3a406270>, <internal.entrypoints.gspl.LazyInstance_StopImageSavingThreads object at 0x720f39fc7e60>, <internal.entrypoints.gspl.LazyInstance_ProgressBar object at 0x720f39ffbf20>, <internal.entrypoints.gspl.LazyInstance_StopDataLoaderCacheThread object at 0x720f3a437380>, <internal.callbacks.MySaveConfigCallback object at 0x720f39f0dd90>], 'fast_dev_run': False, 'max_epochs': None, 'min_epochs': None, 'max_steps': 30000, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'overfit_batches': 0.0, 'val_check_interval': None, 'check_val_every_n_epoch': 1, 'num_sanity_val_steps': 1, 'log_every_n_steps': None, 'enable_checkpointing': False, 'enable_progress_bar': None, 'enable_model_summary': None, 'accumulate_grad_batches': 1, 'gradient_clip_val': None, 'gradient_clip_algorithm': None, 'deterministic': None, 'benchmark': None, 'inference_mode': True, 'use_distributed_sampler': False, 'profiler': None, 'detect_anomaly': False, 'barebones': False, 'plugins': None, 'sync_batchnorm': False, 'reload_dataloaders_every_n_epochs': 0, 'default_root_dir': None, 'model_registry': None, '__class__': <class 'lightning.pytorch.trainer.trainer.Trainer'>}
2025-07-23 16:11:38,927 - lightning.pytorch.utilities.rank_zero - INFO - GPU available: True (cuda), used: True
2025-07-23 16:11:38,938 - lightning.pytorch.utilities.rank_zero - INFO - TPU available: False, using: 0 TPU cores
2025-07-23 16:11:38,941 - lightning.pytorch.utilities.rank_zero - INFO - HPU available: False, using: 0 HPUs
2025-07-23 16:11:40,395 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: trainer fit stage
2025-07-23 16:11:40,412 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_callbacks
2025-07-23 16:11:40,420 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: setting up strategy environment
2025-07-23 16:12:20,660 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: Initializing trainer with parameters: {'self': <lightning.pytorch.trainer.trainer.Trainer object at 0x7da374e85d90>, 'accelerator': 'gpu', 'strategy': <internal.mp_strategy.MPStrategy object at 0x7da374d815b0>, 'devices': -1, 'num_nodes': 1, 'precision': None, 'logger': <lightning.pytorch.loggers.tensorboard.TensorBoardLogger object at 0x7da374ca73b0>, 'callbacks': [<internal.entrypoints.gspl.LazyInstance_SaveGaussian object at 0x7da554b7ce30>, <internal.entrypoints.gspl.LazyInstance_ValidateOnTrainEnd object at 0x7da37517c800>, <internal.entrypoints.gspl.LazyInstance_KeepRunningIfWebViewerEnabled object at 0x7da37533b9b0>, <internal.entrypoints.gspl.LazyInstance_StopImageSavingThreads object at 0x7da3751aba70>, <internal.entrypoints.gspl.LazyInstance_ProgressBar object at 0x7da3753a8ad0>, <internal.entrypoints.gspl.LazyInstance_StopDataLoaderCacheThread object at 0x7da3752eec60>, <internal.callbacks.MySaveConfigCallback object at 0x7da374d95910>], 'fast_dev_run': False, 'max_epochs': None, 'min_epochs': None, 'max_steps': 30000, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'overfit_batches': 0.0, 'val_check_interval': None, 'check_val_every_n_epoch': 1, 'num_sanity_val_steps': 1, 'log_every_n_steps': None, 'enable_checkpointing': False, 'enable_progress_bar': None, 'enable_model_summary': None, 'accumulate_grad_batches': 1, 'gradient_clip_val': None, 'gradient_clip_algorithm': None, 'deterministic': None, 'benchmark': None, 'inference_mode': True, 'use_distributed_sampler': False, 'profiler': None, 'detect_anomaly': False, 'barebones': False, 'plugins': None, 'sync_batchnorm': False, 'reload_dataloaders_every_n_epochs': 0, 'default_root_dir': None, 'model_registry': None, '__class__': <class 'lightning.pytorch.trainer.trainer.Trainer'>}
2025-07-23 16:12:20,886 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: trainer fit stage
2025-07-23 16:12:20,889 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_callbacks
2025-07-23 16:12:20,892 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: setting up strategy environment
2025-07-23 16:12:23,782 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: Initializing trainer with parameters: {'self': <lightning.pytorch.trainer.trainer.Trainer object at 0x7fb230502c90>, 'accelerator': 'gpu', 'strategy': <internal.mp_strategy.MPStrategy object at 0x7fb2302e0c50>, 'devices': -1, 'num_nodes': 1, 'precision': None, 'logger': <lightning.pytorch.loggers.tensorboard.TensorBoardLogger object at 0x7fb2302c22a0>, 'callbacks': [<internal.entrypoints.gspl.LazyInstance_SaveGaussian object at 0x7fb4100d8e00>, <internal.entrypoints.gspl.LazyInstance_ValidateOnTrainEnd object at 0x7fb23070b4a0>, <internal.entrypoints.gspl.LazyInstance_KeepRunningIfWebViewerEnabled object at 0x7fb230a2e3f0>, <internal.entrypoints.gspl.LazyInstance_StopImageSavingThreads object at 0x7fb230834b30>, <internal.entrypoints.gspl.LazyInstance_ProgressBar object at 0x7fb2306e6750>, <internal.entrypoints.gspl.LazyInstance_StopDataLoaderCacheThread object at 0x7fb23bea9e20>, <internal.callbacks.MySaveConfigCallback object at 0x7fb2303765d0>], 'fast_dev_run': False, 'max_epochs': None, 'min_epochs': None, 'max_steps': 30000, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'overfit_batches': 0.0, 'val_check_interval': None, 'check_val_every_n_epoch': 1, 'num_sanity_val_steps': 1, 'log_every_n_steps': None, 'enable_checkpointing': False, 'enable_progress_bar': None, 'enable_model_summary': None, 'accumulate_grad_batches': 1, 'gradient_clip_val': None, 'gradient_clip_algorithm': None, 'deterministic': None, 'benchmark': None, 'inference_mode': True, 'use_distributed_sampler': False, 'profiler': None, 'detect_anomaly': False, 'barebones': False, 'plugins': None, 'sync_batchnorm': False, 'reload_dataloaders_every_n_epochs': 0, 'default_root_dir': None, 'model_registry': None, '__class__': <class 'lightning.pytorch.trainer.trainer.Trainer'>}
2025-07-23 16:12:24,006 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: trainer fit stage
2025-07-23 16:12:24,008 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_callbacks
2025-07-23 16:12:24,010 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: setting up strategy environment
2025-07-23 16:12:24,742 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: Initializing trainer with parameters: {'self': <lightning.pytorch.trainer.trainer.Trainer object at 0x7e3c70572ba0>, 'accelerator': 'gpu', 'strategy': <internal.mp_strategy.MPStrategy object at 0x7e3c703146b0>, 'devices': -1, 'num_nodes': 1, 'precision': None, 'logger': <lightning.pytorch.loggers.tensorboard.TensorBoardLogger object at 0x7e3c70316b40>, 'callbacks': [<internal.entrypoints.gspl.LazyInstance_SaveGaussian object at 0x7e3c7c207ef0>, <internal.entrypoints.gspl.LazyInstance_ValidateOnTrainEnd object at 0x7e3c707b49e0>, <internal.entrypoints.gspl.LazyInstance_KeepRunningIfWebViewerEnabled object at 0x7e3c7048f770>, <internal.entrypoints.gspl.LazyInstance_StopImageSavingThreads object at 0x7e3c708ce060>, <internal.entrypoints.gspl.LazyInstance_ProgressBar object at 0x7e3c7084e210>, <internal.entrypoints.gspl.LazyInstance_StopDataLoaderCacheThread object at 0x7e3c70881430>, <internal.callbacks.MySaveConfigCallback object at 0x7e3c70572e70>], 'fast_dev_run': False, 'max_epochs': None, 'min_epochs': None, 'max_steps': 30000, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'overfit_batches': 0.0, 'val_check_interval': None, 'check_val_every_n_epoch': 1, 'num_sanity_val_steps': 1, 'log_every_n_steps': None, 'enable_checkpointing': False, 'enable_progress_bar': None, 'enable_model_summary': None, 'accumulate_grad_batches': 1, 'gradient_clip_val': None, 'gradient_clip_algorithm': None, 'deterministic': None, 'benchmark': None, 'inference_mode': True, 'use_distributed_sampler': False, 'profiler': None, 'detect_anomaly': False, 'barebones': False, 'plugins': None, 'sync_batchnorm': False, 'reload_dataloaders_every_n_epochs': 0, 'default_root_dir': None, 'model_registry': None, '__class__': <class 'lightning.pytorch.trainer.trainer.Trainer'>}
2025-07-23 16:12:24,976 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: trainer fit stage
2025-07-23 16:12:24,978 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_callbacks
2025-07-23 16:12:24,979 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: setting up strategy environment
2025-07-23 16:12:25,362 - lightning.pytorch.utilities.rank_zero - INFO - ----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 4 processes
----------------------------------------------------------------------------------------------------

2025-07-23 16:12:25,423 - lightning.pytorch.utilities.rank_zero - INFO - You are using a CUDA device ('NVIDIA GeForce RTX 3090 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
2025-07-23 16:12:29,201 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: preparing data
2025-07-23 16:12:29,269 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: preparing data
2025-07-23 16:12:29,311 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: preparing data
2025-07-23 16:12:29,358 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: preparing data
2025-07-23 16:12:29,395 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: setup
2025-07-23 16:12:29,395 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: setup
2025-07-23 16:12:29,397 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: setup
2025-07-23 16:12:29,399 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: setup
2025-07-23 16:12:53,735 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: setup
2025-07-23 16:12:53,735 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: setup
2025-07-23 16:12:53,737 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: setup
2025-07-23 16:12:53,737 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: setup
2025-07-23 16:21:06,656 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: Initializing trainer with parameters: {'self': <lightning.pytorch.trainer.trainer.Trainer object at 0x7cebe88d3920>, 'accelerator': 'gpu', 'strategy': <internal.mp_strategy.MPStrategy object at 0x7cebe87346b0>, 'devices': -1, 'num_nodes': 1, 'precision': None, 'logger': <lightning.pytorch.loggers.tensorboard.TensorBoardLogger object at 0x7cebe869e090>, 'callbacks': [<internal.entrypoints.gspl.LazyInstance_SaveGaussian object at 0x7cedc8580c80>, <internal.entrypoints.gspl.LazyInstance_ValidateOnTrainEnd object at 0x7cebe8baab70>, <internal.entrypoints.gspl.LazyInstance_KeepRunningIfWebViewerEnabled object at 0x7cebe8b4b470>, <internal.entrypoints.gspl.LazyInstance_StopImageSavingThreads object at 0x7cebe8baba40>, <internal.entrypoints.gspl.LazyInstance_ProgressBar object at 0x7cebe8baba70>, <internal.entrypoints.gspl.LazyInstance_StopDataLoaderCacheThread object at 0x7cebf4b07200>, <internal.callbacks.MySaveConfigCallback object at 0x7cebe8677410>], 'fast_dev_run': False, 'max_epochs': None, 'min_epochs': None, 'max_steps': 30000, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'overfit_batches': 0.0, 'val_check_interval': None, 'check_val_every_n_epoch': 1, 'num_sanity_val_steps': 1, 'log_every_n_steps': None, 'enable_checkpointing': False, 'enable_progress_bar': None, 'enable_model_summary': None, 'accumulate_grad_batches': 1, 'gradient_clip_val': None, 'gradient_clip_algorithm': None, 'deterministic': None, 'benchmark': None, 'inference_mode': True, 'use_distributed_sampler': False, 'profiler': None, 'detect_anomaly': False, 'barebones': False, 'plugins': None, 'sync_batchnorm': False, 'reload_dataloaders_every_n_epochs': 0, 'default_root_dir': None, 'model_registry': None, '__class__': <class 'lightning.pytorch.trainer.trainer.Trainer'>}
2025-07-23 16:21:06,827 - lightning.pytorch.utilities.rank_zero - INFO - GPU available: True (cuda), used: True
2025-07-23 16:21:06,830 - lightning.pytorch.utilities.rank_zero - INFO - TPU available: False, using: 0 TPU cores
2025-07-23 16:21:06,831 - lightning.pytorch.utilities.rank_zero - INFO - HPU available: False, using: 0 HPUs
2025-07-23 16:21:07,243 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: trainer fit stage
2025-07-23 16:21:07,245 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_callbacks
2025-07-23 16:21:07,246 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: setting up strategy environment
2025-07-23 16:21:47,463 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: Initializing trainer with parameters: {'self': <lightning.pytorch.trainer.trainer.Trainer object at 0x7361d2ec3ec0>, 'accelerator': 'gpu', 'strategy': <internal.mp_strategy.MPStrategy object at 0x7361d2f13a10>, 'devices': -1, 'num_nodes': 1, 'precision': None, 'logger': <lightning.pytorch.loggers.tensorboard.TensorBoardLogger object at 0x7361d2cbd4c0>, 'callbacks': [<internal.entrypoints.gspl.LazyInstance_SaveGaussian object at 0x7363b2a84e00>, <internal.entrypoints.gspl.LazyInstance_ValidateOnTrainEnd object at 0x7361dfe27fb0>, <internal.entrypoints.gspl.LazyInstance_KeepRunningIfWebViewerEnabled object at 0x7361dea1f2f0>, <internal.entrypoints.gspl.LazyInstance_StopImageSavingThreads object at 0x7361d3177ce0>, <internal.entrypoints.gspl.LazyInstance_ProgressBar object at 0x7361d319e750>, <internal.entrypoints.gspl.LazyInstance_StopDataLoaderCacheThread object at 0x7361d31f9460>, <internal.callbacks.MySaveConfigCallback object at 0x7361d2f10b90>], 'fast_dev_run': False, 'max_epochs': None, 'min_epochs': None, 'max_steps': 30000, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'overfit_batches': 0.0, 'val_check_interval': None, 'check_val_every_n_epoch': 1, 'num_sanity_val_steps': 1, 'log_every_n_steps': None, 'enable_checkpointing': False, 'enable_progress_bar': None, 'enable_model_summary': None, 'accumulate_grad_batches': 1, 'gradient_clip_val': None, 'gradient_clip_algorithm': None, 'deterministic': None, 'benchmark': None, 'inference_mode': True, 'use_distributed_sampler': False, 'profiler': None, 'detect_anomaly': False, 'barebones': False, 'plugins': None, 'sync_batchnorm': False, 'reload_dataloaders_every_n_epochs': 0, 'default_root_dir': None, 'model_registry': None, '__class__': <class 'lightning.pytorch.trainer.trainer.Trainer'>}
2025-07-23 16:21:47,812 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: trainer fit stage
2025-07-23 16:21:47,818 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_callbacks
2025-07-23 16:21:47,822 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: setting up strategy environment
2025-07-23 16:21:48,990 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: Initializing trainer with parameters: {'self': <lightning.pytorch.trainer.trainer.Trainer object at 0x7a5621ccb0e0>, 'accelerator': 'gpu', 'strategy': <internal.mp_strategy.MPStrategy object at 0x7a5621a9c6b0>, 'devices': -1, 'num_nodes': 1, 'precision': None, 'logger': <lightning.pytorch.loggers.tensorboard.TensorBoardLogger object at 0x7a5621b2d1c0>, 'callbacks': [<internal.entrypoints.gspl.LazyInstance_SaveGaussian object at 0x7a58018fcef0>, <internal.entrypoints.gspl.LazyInstance_ValidateOnTrainEnd object at 0x7a56e2bb66c0>, <internal.entrypoints.gspl.LazyInstance_KeepRunningIfWebViewerEnabled object at 0x7a56222067b0>, <internal.entrypoints.gspl.LazyInstance_StopImageSavingThreads object at 0x7a5621df6750>, <internal.entrypoints.gspl.LazyInstance_ProgressBar object at 0x7a562217e390>, <internal.entrypoints.gspl.LazyInstance_StopDataLoaderCacheThread object at 0x7a5621dcc830>, <internal.callbacks.MySaveConfigCallback object at 0x7a562185c3b0>], 'fast_dev_run': False, 'max_epochs': None, 'min_epochs': None, 'max_steps': 30000, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'overfit_batches': 0.0, 'val_check_interval': None, 'check_val_every_n_epoch': 1, 'num_sanity_val_steps': 1, 'log_every_n_steps': None, 'enable_checkpointing': False, 'enable_progress_bar': None, 'enable_model_summary': None, 'accumulate_grad_batches': 1, 'gradient_clip_val': None, 'gradient_clip_algorithm': None, 'deterministic': None, 'benchmark': None, 'inference_mode': True, 'use_distributed_sampler': False, 'profiler': None, 'detect_anomaly': False, 'barebones': False, 'plugins': None, 'sync_batchnorm': False, 'reload_dataloaders_every_n_epochs': 0, 'default_root_dir': None, 'model_registry': None, '__class__': <class 'lightning.pytorch.trainer.trainer.Trainer'>}
2025-07-23 16:21:49,182 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: trainer fit stage
2025-07-23 16:21:49,186 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_callbacks
2025-07-23 16:21:49,189 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: setting up strategy environment
2025-07-23 16:21:50,063 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: Initializing trainer with parameters: {'self': <lightning.pytorch.trainer.trainer.Trainer object at 0x7a2bfacc2210>, 'accelerator': 'gpu', 'strategy': <internal.mp_strategy.MPStrategy object at 0x7a2bfabec6b0>, 'devices': -1, 'num_nodes': 1, 'precision': None, 'logger': <lightning.pytorch.loggers.tensorboard.TensorBoardLogger object at 0x7a2bfab5a120>, 'callbacks': [<internal.entrypoints.gspl.LazyInstance_SaveGaussian object at 0x7a2bfb1bf800>, <internal.entrypoints.gspl.LazyInstance_ValidateOnTrainEnd object at 0x7a2bfb1bf830>, <internal.entrypoints.gspl.LazyInstance_KeepRunningIfWebViewerEnabled object at 0x7a2bfb10e1b0>, <internal.entrypoints.gspl.LazyInstance_StopImageSavingThreads object at 0x7a2bfb10e360>, <internal.entrypoints.gspl.LazyInstance_ProgressBar object at 0x7a2bfaf4bfe0>, <internal.entrypoints.gspl.LazyInstance_StopDataLoaderCacheThread object at 0x7a2bfb189fa0>, <internal.callbacks.MySaveConfigCallback object at 0x7a2bfb13e870>], 'fast_dev_run': False, 'max_epochs': None, 'min_epochs': None, 'max_steps': 30000, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'overfit_batches': 0.0, 'val_check_interval': None, 'check_val_every_n_epoch': 1, 'num_sanity_val_steps': 1, 'log_every_n_steps': None, 'enable_checkpointing': False, 'enable_progress_bar': None, 'enable_model_summary': None, 'accumulate_grad_batches': 1, 'gradient_clip_val': None, 'gradient_clip_algorithm': None, 'deterministic': None, 'benchmark': None, 'inference_mode': True, 'use_distributed_sampler': False, 'profiler': None, 'detect_anomaly': False, 'barebones': False, 'plugins': None, 'sync_batchnorm': False, 'reload_dataloaders_every_n_epochs': 0, 'default_root_dir': None, 'model_registry': None, '__class__': <class 'lightning.pytorch.trainer.trainer.Trainer'>}
2025-07-23 16:21:50,285 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: trainer fit stage
2025-07-23 16:21:50,289 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_callbacks
2025-07-23 16:21:50,292 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: setting up strategy environment
2025-07-23 16:21:50,559 - lightning.pytorch.utilities.rank_zero - INFO - ----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 4 processes
----------------------------------------------------------------------------------------------------

2025-07-23 16:21:50,594 - lightning.pytorch.utilities.rank_zero - INFO - You are using a CUDA device ('NVIDIA GeForce RTX 3090 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
2025-07-23 16:21:54,266 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: preparing data
2025-07-23 16:21:54,444 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: preparing data
2025-07-23 16:21:54,514 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: preparing data
2025-07-23 16:21:54,516 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: preparing data
2025-07-23 16:21:54,582 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: setup
2025-07-23 16:21:54,582 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: setup
2025-07-23 16:21:54,582 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: setup
2025-07-23 16:21:54,583 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: setup
2025-07-23 16:22:17,657 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: setup
2025-07-23 16:22:17,658 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: setup
2025-07-23 16:22:17,658 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: setup
2025-07-23 16:22:17,659 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: setup
2025-07-23 16:31:16,707 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: Initializing trainer with parameters: {'self': <lightning.pytorch.trainer.trainer.Trainer object at 0x7df0725a2c60>, 'accelerator': 'gpu', 'strategy': <internal.mp_strategy.MPStrategy object at 0x7df07eac03b0>, 'devices': -1, 'num_nodes': 1, 'precision': None, 'logger': <lightning.pytorch.loggers.tensorboard.TensorBoardLogger object at 0x7df0726c2540>, 'callbacks': [<internal.entrypoints.gspl.LazyInstance_SaveGaussian object at 0x7df072b613a0>, <internal.entrypoints.gspl.LazyInstance_ValidateOnTrainEnd object at 0x7df2523d8c80>, <internal.entrypoints.gspl.LazyInstance_KeepRunningIfWebViewerEnabled object at 0x7df072cff230>, <internal.entrypoints.gspl.LazyInstance_StopImageSavingThreads object at 0x7df07294baa0>, <internal.entrypoints.gspl.LazyInstance_ProgressBar object at 0x7df07291f650>, <internal.entrypoints.gspl.LazyInstance_StopDataLoaderCacheThread object at 0x7df0728b1a90>, <internal.callbacks.MySaveConfigCallback object at 0x7df072412b10>], 'fast_dev_run': False, 'max_epochs': None, 'min_epochs': None, 'max_steps': 30000, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'overfit_batches': 0.0, 'val_check_interval': None, 'check_val_every_n_epoch': 1, 'num_sanity_val_steps': 1, 'log_every_n_steps': None, 'enable_checkpointing': False, 'enable_progress_bar': None, 'enable_model_summary': None, 'accumulate_grad_batches': 1, 'gradient_clip_val': None, 'gradient_clip_algorithm': None, 'deterministic': None, 'benchmark': None, 'inference_mode': True, 'use_distributed_sampler': False, 'profiler': None, 'detect_anomaly': False, 'barebones': False, 'plugins': None, 'sync_batchnorm': False, 'reload_dataloaders_every_n_epochs': 0, 'default_root_dir': None, 'model_registry': None, '__class__': <class 'lightning.pytorch.trainer.trainer.Trainer'>}
2025-07-23 16:31:16,792 - lightning.pytorch.utilities.rank_zero - INFO - GPU available: True (cuda), used: True
2025-07-23 16:31:16,793 - lightning.pytorch.utilities.rank_zero - INFO - TPU available: False, using: 0 TPU cores
2025-07-23 16:31:16,793 - lightning.pytorch.utilities.rank_zero - INFO - HPU available: False, using: 0 HPUs
2025-07-23 16:31:16,946 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: trainer fit stage
2025-07-23 16:31:16,951 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_callbacks
2025-07-23 16:31:16,952 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: setting up strategy environment
2025-07-23 16:31:26,512 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: Initializing trainer with parameters: {'self': <lightning.pytorch.trainer.trainer.Trainer object at 0x77a415420980>, 'accelerator': 'gpu', 'strategy': <internal.mp_strategy.MPStrategy object at 0x77a4154d7230>, 'devices': -1, 'num_nodes': 1, 'precision': None, 'logger': <lightning.pytorch.loggers.tensorboard.TensorBoardLogger object at 0x77a415496870>, 'callbacks': [<internal.entrypoints.gspl.LazyInstance_SaveGaussian object at 0x77a415977ef0>, <internal.entrypoints.gspl.LazyInstance_ValidateOnTrainEnd object at 0x77a41599f2c0>, <internal.entrypoints.gspl.LazyInstance_KeepRunningIfWebViewerEnabled object at 0x77a415c26570>, <internal.entrypoints.gspl.LazyInstance_StopImageSavingThreads object at 0x77a415ade7e0>, <internal.entrypoints.gspl.LazyInstance_ProgressBar object at 0x77a415976090>, <internal.entrypoints.gspl.LazyInstance_StopDataLoaderCacheThread object at 0x77a4158ddb80>, <internal.callbacks.MySaveConfigCallback object at 0x77a4153341d0>], 'fast_dev_run': False, 'max_epochs': None, 'min_epochs': None, 'max_steps': 30000, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'overfit_batches': 0.0, 'val_check_interval': None, 'check_val_every_n_epoch': 1, 'num_sanity_val_steps': 1, 'log_every_n_steps': None, 'enable_checkpointing': False, 'enable_progress_bar': None, 'enable_model_summary': None, 'accumulate_grad_batches': 1, 'gradient_clip_val': None, 'gradient_clip_algorithm': None, 'deterministic': None, 'benchmark': None, 'inference_mode': True, 'use_distributed_sampler': False, 'profiler': None, 'detect_anomaly': False, 'barebones': False, 'plugins': None, 'sync_batchnorm': False, 'reload_dataloaders_every_n_epochs': 0, 'default_root_dir': None, 'model_registry': None, '__class__': <class 'lightning.pytorch.trainer.trainer.Trainer'>}
2025-07-23 16:31:26,601 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: trainer fit stage
2025-07-23 16:31:26,601 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_callbacks
2025-07-23 16:31:26,602 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: setting up strategy environment
2025-07-23 16:31:26,760 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: Initializing trainer with parameters: {'self': <lightning.pytorch.trainer.trainer.Trainer object at 0x722783be53d0>, 'accelerator': 'gpu', 'strategy': <internal.mp_strategy.MPStrategy object at 0x7227839dc6b0>, 'devices': -1, 'num_nodes': 1, 'precision': None, 'logger': <lightning.pytorch.loggers.tensorboard.TensorBoardLogger object at 0x722783a692e0>, 'callbacks': [<internal.entrypoints.gspl.LazyInstance_SaveGaussian object at 0x72278f997ef0>, <internal.entrypoints.gspl.LazyInstance_ValidateOnTrainEnd object at 0x722783c9fb90>, <internal.entrypoints.gspl.LazyInstance_KeepRunningIfWebViewerEnabled object at 0x722783d12330>, <internal.entrypoints.gspl.LazyInstance_StopImageSavingThreads object at 0x722783fafad0>, <internal.entrypoints.gspl.LazyInstance_ProgressBar object at 0x722783d3bfe0>, <internal.entrypoints.gspl.LazyInstance_StopDataLoaderCacheThread object at 0x72278f967ec0>, <internal.callbacks.MySaveConfigCallback object at 0x722783be7cb0>], 'fast_dev_run': False, 'max_epochs': None, 'min_epochs': None, 'max_steps': 30000, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'overfit_batches': 0.0, 'val_check_interval': None, 'check_val_every_n_epoch': 1, 'num_sanity_val_steps': 1, 'log_every_n_steps': None, 'enable_checkpointing': False, 'enable_progress_bar': None, 'enable_model_summary': None, 'accumulate_grad_batches': 1, 'gradient_clip_val': None, 'gradient_clip_algorithm': None, 'deterministic': None, 'benchmark': None, 'inference_mode': True, 'use_distributed_sampler': False, 'profiler': None, 'detect_anomaly': False, 'barebones': False, 'plugins': None, 'sync_batchnorm': False, 'reload_dataloaders_every_n_epochs': 0, 'default_root_dir': None, 'model_registry': None, '__class__': <class 'lightning.pytorch.trainer.trainer.Trainer'>}
2025-07-23 16:31:26,793 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: Initializing trainer with parameters: {'self': <lightning.pytorch.trainer.trainer.Trainer object at 0x7f24d1180680>, 'accelerator': 'gpu', 'strategy': <internal.mp_strategy.MPStrategy object at 0x7f241262c200>, 'devices': -1, 'num_nodes': 1, 'precision': None, 'logger': <lightning.pytorch.loggers.tensorboard.TensorBoardLogger object at 0x7f24126d4320>, 'callbacks': [<internal.entrypoints.gspl.LazyInstance_SaveGaussian object at 0x7f25f245ce00>, <internal.entrypoints.gspl.LazyInstance_ValidateOnTrainEnd object at 0x7f2412dafe30>, <internal.entrypoints.gspl.LazyInstance_KeepRunningIfWebViewerEnabled object at 0x7f2412cf23f0>, <internal.entrypoints.gspl.LazyInstance_StopImageSavingThreads object at 0x7f2412bdfaa0>, <internal.entrypoints.gspl.LazyInstance_ProgressBar object at 0x7f24127d0950>, <internal.entrypoints.gspl.LazyInstance_StopDataLoaderCacheThread object at 0x7f241e5c7740>, <internal.callbacks.MySaveConfigCallback object at 0x7f2412dade20>], 'fast_dev_run': False, 'max_epochs': None, 'min_epochs': None, 'max_steps': 30000, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'overfit_batches': 0.0, 'val_check_interval': None, 'check_val_every_n_epoch': 1, 'num_sanity_val_steps': 1, 'log_every_n_steps': None, 'enable_checkpointing': False, 'enable_progress_bar': None, 'enable_model_summary': None, 'accumulate_grad_batches': 1, 'gradient_clip_val': None, 'gradient_clip_algorithm': None, 'deterministic': None, 'benchmark': None, 'inference_mode': True, 'use_distributed_sampler': False, 'profiler': None, 'detect_anomaly': False, 'barebones': False, 'plugins': None, 'sync_batchnorm': False, 'reload_dataloaders_every_n_epochs': 0, 'default_root_dir': None, 'model_registry': None, '__class__': <class 'lightning.pytorch.trainer.trainer.Trainer'>}
2025-07-23 16:31:26,848 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: trainer fit stage
2025-07-23 16:31:26,849 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_callbacks
2025-07-23 16:31:26,849 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: setting up strategy environment
2025-07-23 16:31:26,879 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: trainer fit stage
2025-07-23 16:31:26,879 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_callbacks
2025-07-23 16:31:26,880 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: setting up strategy environment
2025-07-23 16:31:27,044 - lightning.pytorch.utilities.rank_zero - INFO - ----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 4 processes
----------------------------------------------------------------------------------------------------

2025-07-23 16:31:27,087 - lightning.pytorch.utilities.rank_zero - INFO - You are using a CUDA device ('NVIDIA GeForce RTX 3090 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
2025-07-23 16:31:27,795 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: preparing data
2025-07-23 16:31:27,843 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: preparing data
2025-07-23 16:31:27,876 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: preparing data
2025-07-23 16:31:27,877 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: preparing data
2025-07-23 16:31:27,888 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: setup
2025-07-23 16:31:27,888 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: setup
2025-07-23 16:31:27,888 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: setup
2025-07-23 16:31:27,888 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: setup
2025-07-23 16:31:32,603 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: setup
2025-07-23 16:31:32,603 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: setup
2025-07-23 16:31:32,603 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: setup
2025-07-23 16:31:32,603 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: setup
2025-07-23 16:32:44,575 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: Initializing trainer with parameters: {'self': <lightning.pytorch.trainer.trainer.Trainer object at 0x7c4cbd45f5c0>, 'accelerator': 'gpu', 'strategy': <internal.mp_strategy.MPStrategy object at 0x7c4cbd6e0170>, 'devices': -1, 'num_nodes': 1, 'precision': None, 'logger': <lightning.pytorch.loggers.tensorboard.TensorBoardLogger object at 0x7c4cbd45fcb0>, 'callbacks': [<internal.entrypoints.gspl.LazyInstance_SaveGaussian object at 0x7c4cbdabfef0>, <internal.entrypoints.gspl.LazyInstance_ValidateOnTrainEnd object at 0x7c4cc9589130>, <internal.entrypoints.gspl.LazyInstance_KeepRunningIfWebViewerEnabled object at 0x7c4cc92eeab0>, <internal.entrypoints.gspl.LazyInstance_StopImageSavingThreads object at 0x7c4cbdd4e2a0>, <internal.entrypoints.gspl.LazyInstance_ProgressBar object at 0x7c4cbdad9c10>, <internal.entrypoints.gspl.LazyInstance_StopDataLoaderCacheThread object at 0x7c4cbdb355e0>, <internal.callbacks.MySaveConfigCallback object at 0x7c4cbd668bf0>], 'fast_dev_run': False, 'max_epochs': None, 'min_epochs': None, 'max_steps': 30000, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'overfit_batches': 0.0, 'val_check_interval': None, 'check_val_every_n_epoch': 1, 'num_sanity_val_steps': 1, 'log_every_n_steps': None, 'enable_checkpointing': False, 'enable_progress_bar': None, 'enable_model_summary': None, 'accumulate_grad_batches': 1, 'gradient_clip_val': None, 'gradient_clip_algorithm': None, 'deterministic': None, 'benchmark': None, 'inference_mode': True, 'use_distributed_sampler': False, 'profiler': None, 'detect_anomaly': False, 'barebones': False, 'plugins': None, 'sync_batchnorm': False, 'reload_dataloaders_every_n_epochs': 0, 'default_root_dir': None, 'model_registry': None, '__class__': <class 'lightning.pytorch.trainer.trainer.Trainer'>}
2025-07-23 16:32:44,664 - lightning.pytorch.utilities.rank_zero - INFO - GPU available: True (cuda), used: True
2025-07-23 16:32:44,665 - lightning.pytorch.utilities.rank_zero - INFO - TPU available: False, using: 0 TPU cores
2025-07-23 16:32:44,665 - lightning.pytorch.utilities.rank_zero - INFO - HPU available: False, using: 0 HPUs
2025-07-23 16:32:44,801 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: trainer fit stage
2025-07-23 16:32:44,802 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_callbacks
2025-07-23 16:32:44,802 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: setting up strategy environment
2025-07-23 16:32:54,387 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: Initializing trainer with parameters: {'self': <lightning.pytorch.trainer.trainer.Trainer object at 0x704e9e8cc290>, 'accelerator': 'gpu', 'strategy': <internal.mp_strategy.MPStrategy object at 0x704e9e9fc3b0>, 'devices': -1, 'num_nodes': 1, 'precision': None, 'logger': <lightning.pytorch.loggers.tensorboard.TensorBoardLogger object at 0x704e9ea95130>, 'callbacks': [<internal.entrypoints.gspl.LazyInstance_SaveGaussian object at 0x70507e7d0f20>, <internal.entrypoints.gspl.LazyInstance_ValidateOnTrainEnd object at 0x704eaa98c9e0>, <internal.entrypoints.gspl.LazyInstance_KeepRunningIfWebViewerEnabled object at 0x704eabd60170>, <internal.entrypoints.gspl.LazyInstance_StopImageSavingThreads object at 0x704e9f1fe7e0>, <internal.entrypoints.gspl.LazyInstance_ProgressBar object at 0x704e9eb949b0>, <internal.entrypoints.gspl.LazyInstance_StopDataLoaderCacheThread object at 0x704e9eccf260>, <internal.callbacks.MySaveConfigCallback object at 0x704e9e96ff50>], 'fast_dev_run': False, 'max_epochs': None, 'min_epochs': None, 'max_steps': 30000, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'overfit_batches': 0.0, 'val_check_interval': None, 'check_val_every_n_epoch': 1, 'num_sanity_val_steps': 1, 'log_every_n_steps': None, 'enable_checkpointing': False, 'enable_progress_bar': None, 'enable_model_summary': None, 'accumulate_grad_batches': 1, 'gradient_clip_val': None, 'gradient_clip_algorithm': None, 'deterministic': None, 'benchmark': None, 'inference_mode': True, 'use_distributed_sampler': False, 'profiler': None, 'detect_anomaly': False, 'barebones': False, 'plugins': None, 'sync_batchnorm': False, 'reload_dataloaders_every_n_epochs': 0, 'default_root_dir': None, 'model_registry': None, '__class__': <class 'lightning.pytorch.trainer.trainer.Trainer'>}
2025-07-23 16:32:54,476 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: trainer fit stage
2025-07-23 16:32:54,477 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_callbacks
2025-07-23 16:32:54,477 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: setting up strategy environment
2025-07-23 16:32:54,737 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: Initializing trainer with parameters: {'self': <lightning.pytorch.trainer.trainer.Trainer object at 0x7fe6bbefacc0>, 'accelerator': 'gpu', 'strategy': <internal.mp_strategy.MPStrategy object at 0x7fe6b02e0950>, 'devices': -1, 'num_nodes': 1, 'precision': None, 'logger': <lightning.pytorch.loggers.tensorboard.TensorBoardLogger object at 0x7fe6b037a750>, 'callbacks': [<internal.entrypoints.gspl.LazyInstance_SaveGaussian object at 0x7fe890198e00>, <internal.entrypoints.gspl.LazyInstance_ValidateOnTrainEnd object at 0x7fe6b0741130>, <internal.entrypoints.gspl.LazyInstance_KeepRunningIfWebViewerEnabled object at 0x7fe6b06c4fb0>, <internal.entrypoints.gspl.LazyInstance_StopImageSavingThreads object at 0x7fe6b070b1a0>, <internal.entrypoints.gspl.LazyInstance_ProgressBar object at 0x7fe6b0834950>, <internal.entrypoints.gspl.LazyInstance_StopDataLoaderCacheThread object at 0x7fe6b07415e0>, <internal.callbacks.MySaveConfigCallback object at 0x7fe6b08ee0f0>], 'fast_dev_run': False, 'max_epochs': None, 'min_epochs': None, 'max_steps': 30000, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'overfit_batches': 0.0, 'val_check_interval': None, 'check_val_every_n_epoch': 1, 'num_sanity_val_steps': 1, 'log_every_n_steps': None, 'enable_checkpointing': False, 'enable_progress_bar': None, 'enable_model_summary': None, 'accumulate_grad_batches': 1, 'gradient_clip_val': None, 'gradient_clip_algorithm': None, 'deterministic': None, 'benchmark': None, 'inference_mode': True, 'use_distributed_sampler': False, 'profiler': None, 'detect_anomaly': False, 'barebones': False, 'plugins': None, 'sync_batchnorm': False, 'reload_dataloaders_every_n_epochs': 0, 'default_root_dir': None, 'model_registry': None, '__class__': <class 'lightning.pytorch.trainer.trainer.Trainer'>}
2025-07-23 16:32:54,743 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: Initializing trainer with parameters: {'self': <lightning.pytorch.trainer.trainer.Trainer object at 0x71ddac29f680>, 'accelerator': 'gpu', 'strategy': <internal.mp_strategy.MPStrategy object at 0x71ddac2dc320>, 'devices': -1, 'num_nodes': 1, 'precision': None, 'logger': <lightning.pytorch.loggers.tensorboard.TensorBoardLogger object at 0x71ddac741e50>, 'callbacks': [<internal.entrypoints.gspl.LazyInstance_SaveGaussian object at 0x71ddac891400>, <internal.entrypoints.gspl.LazyInstance_ValidateOnTrainEnd object at 0x71ddb83249e0>, <internal.entrypoints.gspl.LazyInstance_KeepRunningIfWebViewerEnabled object at 0x71ddaca2e3f0>, <internal.entrypoints.gspl.LazyInstance_StopImageSavingThreads object at 0x71ddaca2e7e0>, <internal.entrypoints.gspl.LazyInstance_ProgressBar object at 0x71ddac6c6390>, <internal.entrypoints.gspl.LazyInstance_StopDataLoaderCacheThread object at 0x71ddb82fb800>, <internal.callbacks.MySaveConfigCallback object at 0x71ddb81c3620>], 'fast_dev_run': False, 'max_epochs': None, 'min_epochs': None, 'max_steps': 30000, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'overfit_batches': 0.0, 'val_check_interval': None, 'check_val_every_n_epoch': 1, 'num_sanity_val_steps': 1, 'log_every_n_steps': None, 'enable_checkpointing': False, 'enable_progress_bar': None, 'enable_model_summary': None, 'accumulate_grad_batches': 1, 'gradient_clip_val': None, 'gradient_clip_algorithm': None, 'deterministic': None, 'benchmark': None, 'inference_mode': True, 'use_distributed_sampler': False, 'profiler': None, 'detect_anomaly': False, 'barebones': False, 'plugins': None, 'sync_batchnorm': False, 'reload_dataloaders_every_n_epochs': 0, 'default_root_dir': None, 'model_registry': None, '__class__': <class 'lightning.pytorch.trainer.trainer.Trainer'>}
2025-07-23 16:32:54,834 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: trainer fit stage
2025-07-23 16:32:54,834 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: trainer fit stage
2025-07-23 16:32:54,835 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_callbacks
2025-07-23 16:32:54,835 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_callbacks
2025-07-23 16:32:54,835 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: setting up strategy environment
2025-07-23 16:32:54,835 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: setting up strategy environment
2025-07-23 16:32:54,912 - lightning.pytorch.utilities.rank_zero - INFO - ----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 4 processes
----------------------------------------------------------------------------------------------------

2025-07-23 16:32:54,919 - lightning.pytorch.utilities.rank_zero - INFO - You are using a CUDA device ('NVIDIA GeForce RTX 3090 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
2025-07-23 16:32:55,904 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: preparing data
2025-07-23 16:32:55,953 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: preparing data
2025-07-23 16:32:55,955 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: preparing data
2025-07-23 16:32:55,963 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: preparing data
2025-07-23 16:32:55,976 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: setup
2025-07-23 16:32:55,976 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: setup
2025-07-23 16:32:55,976 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: setup
2025-07-23 16:32:55,976 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: setup
2025-07-23 16:33:00,330 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: setup
2025-07-23 16:33:00,330 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: setup
2025-07-23 16:33:00,331 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: setup
2025-07-23 16:33:00,331 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: setup
2025-07-23 16:34:06,192 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: Initializing trainer with parameters: {'self': <lightning.pytorch.trainer.trainer.Trainer object at 0x7b2d6ea1f500>, 'accelerator': 'gpu', 'strategy': <internal.mp_strategy.MPStrategy object at 0x7b2d6e7cf590>, 'devices': -1, 'num_nodes': 1, 'precision': None, 'logger': <lightning.pytorch.loggers.tensorboard.TensorBoardLogger object at 0x7b2d6e815ac0>, 'callbacks': [<internal.entrypoints.gspl.LazyInstance_SaveGaussian object at 0x7b2f4e644ec0>, <internal.entrypoints.gspl.LazyInstance_ValidateOnTrainEnd object at 0x7b2d6ec716a0>, <internal.entrypoints.gspl.LazyInstance_KeepRunningIfWebViewerEnabled object at 0x7b2d6eca61b0>, <internal.entrypoints.gspl.LazyInstance_StopImageSavingThreads object at 0x7b2d7a64f7a0>, <internal.entrypoints.gspl.LazyInstance_ProgressBar object at 0x7b2d6e94bfe0>, <internal.entrypoints.gspl.LazyInstance_StopDataLoaderCacheThread object at 0x7b2d6ec11a90>, <lightning.pytorch.cli.SaveConfigCallback object at 0x7b2d6e9b2c00>], 'fast_dev_run': False, 'max_epochs': None, 'min_epochs': None, 'max_steps': 30000, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'overfit_batches': 0.0, 'val_check_interval': None, 'check_val_every_n_epoch': 1, 'num_sanity_val_steps': 1, 'log_every_n_steps': None, 'enable_checkpointing': False, 'enable_progress_bar': None, 'enable_model_summary': None, 'accumulate_grad_batches': 1, 'gradient_clip_val': None, 'gradient_clip_algorithm': None, 'deterministic': None, 'benchmark': None, 'inference_mode': True, 'use_distributed_sampler': False, 'profiler': None, 'detect_anomaly': False, 'barebones': False, 'plugins': None, 'sync_batchnorm': False, 'reload_dataloaders_every_n_epochs': 0, 'default_root_dir': None, 'model_registry': None, '__class__': <class 'lightning.pytorch.trainer.trainer.Trainer'>}
2025-07-23 16:34:06,275 - lightning.pytorch.utilities.rank_zero - INFO - GPU available: True (cuda), used: True
2025-07-23 16:34:06,276 - lightning.pytorch.utilities.rank_zero - INFO - TPU available: False, using: 0 TPU cores
2025-07-23 16:34:06,276 - lightning.pytorch.utilities.rank_zero - INFO - HPU available: False, using: 0 HPUs
2025-07-23 16:34:06,418 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: trainer fit stage
2025-07-23 16:34:06,419 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_callbacks
2025-07-23 16:34:06,419 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: setting up strategy environment
2025-07-23 16:34:16,293 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: Initializing trainer with parameters: {'self': <lightning.pytorch.trainer.trainer.Trainer object at 0x7348ef4e2900>, 'accelerator': 'gpu', 'strategy': <internal.mp_strategy.MPStrategy object at 0x7348ef0dd6d0>, 'devices': -1, 'num_nodes': 1, 'precision': None, 'logger': <lightning.pytorch.loggers.tensorboard.TensorBoardLogger object at 0x7348ef4c1070>, 'callbacks': [<internal.entrypoints.gspl.LazyInstance_SaveGaussian object at 0x7348ef68d460>, <internal.entrypoints.gspl.LazyInstance_ValidateOnTrainEnd object at 0x7348fb08fef0>, <internal.entrypoints.gspl.LazyInstance_KeepRunningIfWebViewerEnabled object at 0x7348ef68fbf0>, <internal.entrypoints.gspl.LazyInstance_StopImageSavingThreads object at 0x7348ef68fbc0>, <internal.entrypoints.gspl.LazyInstance_ProgressBar object at 0x7348fb1cf440>, <internal.entrypoints.gspl.LazyInstance_StopDataLoaderCacheThread object at 0x7348ef4e3710>, <lightning.pytorch.cli.SaveConfigCallback object at 0x7348ef53d340>], 'fast_dev_run': False, 'max_epochs': None, 'min_epochs': None, 'max_steps': 30000, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'overfit_batches': 0.0, 'val_check_interval': None, 'check_val_every_n_epoch': 1, 'num_sanity_val_steps': 1, 'log_every_n_steps': None, 'enable_checkpointing': False, 'enable_progress_bar': None, 'enable_model_summary': None, 'accumulate_grad_batches': 1, 'gradient_clip_val': None, 'gradient_clip_algorithm': None, 'deterministic': None, 'benchmark': None, 'inference_mode': True, 'use_distributed_sampler': False, 'profiler': None, 'detect_anomaly': False, 'barebones': False, 'plugins': None, 'sync_batchnorm': False, 'reload_dataloaders_every_n_epochs': 0, 'default_root_dir': None, 'model_registry': None, '__class__': <class 'lightning.pytorch.trainer.trainer.Trainer'>}
2025-07-23 16:34:16,294 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: Initializing trainer with parameters: {'self': <lightning.pytorch.trainer.trainer.Trainer object at 0x7d5e258c0560>, 'accelerator': 'gpu', 'strategy': <internal.mp_strategy.MPStrategy object at 0x7d5e258c0950>, 'devices': -1, 'num_nodes': 1, 'precision': None, 'logger': <lightning.pytorch.loggers.tensorboard.TensorBoardLogger object at 0x7d5e25804080>, 'callbacks': [<internal.entrypoints.gspl.LazyInstance_SaveGaussian object at 0x7d600563ce30>, <internal.entrypoints.gspl.LazyInstance_ValidateOnTrainEnd object at 0x7d5e25d749e0>, <internal.entrypoints.gspl.LazyInstance_KeepRunningIfWebViewerEnabled object at 0x7d5e259376b0>, <internal.entrypoints.gspl.LazyInstance_StopImageSavingThreads object at 0x7d5e317cfda0>, <internal.entrypoints.gspl.LazyInstance_ProgressBar object at 0x7d5e25937290>, <internal.entrypoints.gspl.LazyInstance_StopDataLoaderCacheThread object at 0x7d5e25c87500>, <lightning.pytorch.cli.SaveConfigCallback object at 0x7d5e258c0dd0>], 'fast_dev_run': False, 'max_epochs': None, 'min_epochs': None, 'max_steps': 30000, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'overfit_batches': 0.0, 'val_check_interval': None, 'check_val_every_n_epoch': 1, 'num_sanity_val_steps': 1, 'log_every_n_steps': None, 'enable_checkpointing': False, 'enable_progress_bar': None, 'enable_model_summary': None, 'accumulate_grad_batches': 1, 'gradient_clip_val': None, 'gradient_clip_algorithm': None, 'deterministic': None, 'benchmark': None, 'inference_mode': True, 'use_distributed_sampler': False, 'profiler': None, 'detect_anomaly': False, 'barebones': False, 'plugins': None, 'sync_batchnorm': False, 'reload_dataloaders_every_n_epochs': 0, 'default_root_dir': None, 'model_registry': None, '__class__': <class 'lightning.pytorch.trainer.trainer.Trainer'>}
2025-07-23 16:34:16,355 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: Initializing trainer with parameters: {'self': <lightning.pytorch.trainer.trainer.Trainer object at 0x7ec7e4bc5310>, 'accelerator': 'gpu', 'strategy': <internal.mp_strategy.MPStrategy object at 0x7ec7e48b5fa0>, 'devices': -1, 'num_nodes': 1, 'precision': None, 'logger': <lightning.pytorch.loggers.tensorboard.TensorBoardLogger object at 0x7ec7e4896570>, 'callbacks': [<internal.entrypoints.gspl.LazyInstance_SaveGaussian object at 0x7ec7e4bc7ef0>, <internal.entrypoints.gspl.LazyInstance_ValidateOnTrainEnd object at 0x7ec7f08949e0>, <internal.entrypoints.gspl.LazyInstance_KeepRunningIfWebViewerEnabled object at 0x7ec7e4faa6f0>, <internal.entrypoints.gspl.LazyInstance_StopImageSavingThreads object at 0x7ec7f044f8f0>, <internal.entrypoints.gspl.LazyInstance_ProgressBar object at 0x7ec7f079e150>, <internal.entrypoints.gspl.LazyInstance_StopDataLoaderCacheThread object at 0x7ec7e4e99190>, <lightning.pytorch.cli.SaveConfigCallback object at 0x7ec7e4a9ff20>], 'fast_dev_run': False, 'max_epochs': None, 'min_epochs': None, 'max_steps': 30000, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'overfit_batches': 0.0, 'val_check_interval': None, 'check_val_every_n_epoch': 1, 'num_sanity_val_steps': 1, 'log_every_n_steps': None, 'enable_checkpointing': False, 'enable_progress_bar': None, 'enable_model_summary': None, 'accumulate_grad_batches': 1, 'gradient_clip_val': None, 'gradient_clip_algorithm': None, 'deterministic': None, 'benchmark': None, 'inference_mode': True, 'use_distributed_sampler': False, 'profiler': None, 'detect_anomaly': False, 'barebones': False, 'plugins': None, 'sync_batchnorm': False, 'reload_dataloaders_every_n_epochs': 0, 'default_root_dir': None, 'model_registry': None, '__class__': <class 'lightning.pytorch.trainer.trainer.Trainer'>}
2025-07-23 16:34:16,382 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: trainer fit stage
2025-07-23 16:34:16,382 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: trainer fit stage
2025-07-23 16:34:16,383 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_callbacks
2025-07-23 16:34:16,383 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_callbacks
2025-07-23 16:34:16,383 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: setting up strategy environment
2025-07-23 16:34:16,383 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: setting up strategy environment
2025-07-23 16:34:16,442 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: trainer fit stage
2025-07-23 16:34:16,443 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_callbacks
2025-07-23 16:34:16,444 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: setting up strategy environment
2025-07-23 16:34:16,739 - lightning.pytorch.utilities.rank_zero - INFO - ----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 4 processes
----------------------------------------------------------------------------------------------------

2025-07-23 16:34:16,749 - lightning.pytorch.utilities.rank_zero - INFO - You are using a CUDA device ('NVIDIA GeForce RTX 3090 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
2025-07-23 16:34:17,595 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: preparing data
2025-07-23 16:34:17,639 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: preparing data
2025-07-23 16:34:17,644 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: preparing data
2025-07-23 16:34:17,648 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: preparing data
2025-07-23 16:34:17,660 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: setup
2025-07-23 16:34:17,660 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: setup
2025-07-23 16:34:17,660 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: setup
2025-07-23 16:34:17,660 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: setup
2025-07-23 16:34:21,779 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: setup
2025-07-23 16:34:21,779 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: setup
2025-07-23 16:34:21,779 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: setup
2025-07-23 16:34:21,779 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: setup
2025-07-23 16:34:21,941 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: setup
2025-07-23 16:34:21,941 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: setup
2025-07-23 16:34:21,941 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: setup
2025-07-23 16:34:21,941 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: setup
2025-07-23 16:34:24,314 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: configuring model
2025-07-23 16:34:24,315 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: configuring model
2025-07-23 16:34:24,315 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: configuring model
2025-07-23 16:34:24,315 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring module and callbacks from checkpoint path: None
2025-07-23 16:34:24,315 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring module and callbacks from checkpoint path: None
2025-07-23 16:34:24,315 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: configuring model
2025-07-23 16:34:24,315 - lightning.pytorch.trainer.connectors.checkpoint_connector - DEBUG - `checkpoint_path` not specified. Skipping checkpoint loading.
2025-07-23 16:34:24,315 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring module and callbacks from checkpoint path: None
2025-07-23 16:34:24,315 - lightning.pytorch.trainer.connectors.checkpoint_connector - DEBUG - `checkpoint_path` not specified. Skipping checkpoint loading.
2025-07-23 16:34:24,315 - lightning.pytorch.trainer.connectors.checkpoint_connector - DEBUG - `checkpoint_path` not specified. Skipping checkpoint loading.
2025-07-23 16:34:24,315 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring module and callbacks from checkpoint path: None
2025-07-23 16:34:24,315 - lightning.pytorch.trainer.connectors.checkpoint_connector - DEBUG - `checkpoint_path` not specified. Skipping checkpoint loading.
2025-07-23 16:34:24,344 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [4,5,6,7]
2025-07-23 16:34:24,345 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [4,5,6,7]
2025-07-23 16:34:24,346 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_optimizers
2025-07-23 16:34:24,346 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [4,5,6,7]
2025-07-23 16:34:24,346 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_optimizers
2025-07-23 16:34:24,347 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_optimizers
2025-07-23 16:34:24,349 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_fit_start
2025-07-23 16:34:24,349 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_fit_start
2025-07-23 16:34:24,350 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_fit_start
2025-07-23 16:34:24,355 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [4,5,6,7]
2025-07-23 16:34:24,357 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_optimizers
2025-07-23 16:34:24,360 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_fit_start
2025-07-23 16:34:24,361 - lightning.pytorch.callbacks.model_summary - INFO - 
  | Name               | Type                                    | Params | Mode 
---------------------------------------------------------------------------------------
0 | gaussian_model     | VanillaGaussianModel                    | 2.0 M  | train
1 | renderer           | GSplatDistributedRendererImpl           | 0      | train
2 | density_controller | DistributedVanillaDensityControllerImpl | 0      | train
3 | metric             | VanillaMetricsImpl                      | 0      | train
---------------------------------------------------------------------------------------
2.0 M     Trainable params
0         Non-trainable params
2.0 M     Total params
8.026     Total estimated model params size (MB)
6         Modules in train mode
0         Modules in eval mode
2025-07-23 16:34:24,364 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_fit_start
2025-07-23 16:34:24,364 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_fit_start
2025-07-23 16:34:24,364 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_fit_start
2025-07-23 16:34:24,365 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_fit_start
2025-07-23 16:34:24,365 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring training state
2025-07-23 16:34:24,365 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring training state
2025-07-23 16:34:24,365 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring training state
2025-07-23 16:34:24,435 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring training state
2025-07-23 16:34:24,438 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_sanity_check_start
2025-07-23 16:34:24,438 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_sanity_check_start
2025-07-23 16:34:24,438 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_sanity_check_start
2025-07-23 16:34:24,438 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_sanity_check_start
2025-07-23 16:34:24,444 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: val_dataloader
2025-07-23 16:34:24,444 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: val_dataloader
2025-07-23 16:34:24,444 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: val_dataloader
2025-07-23 16:34:24,444 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: val_dataloader
2025-07-23 16:34:25,196 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_model_eval
2025-07-23 16:34:25,196 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_start
2025-07-23 16:34:25,197 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_model_eval
2025-07-23 16:34:25,198 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_start
2025-07-23 16:34:25,199 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_model_eval
2025-07-23 16:34:25,199 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_start
2025-07-23 16:34:25,209 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_model_eval
2025-07-23 16:34:25,210 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_start
2025-07-23 16:34:25,212 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_start
2025-07-23 16:34:25,212 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_start
2025-07-23 16:34:25,212 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_start
2025-07-23 16:34:25,212 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_start
2025-07-23 16:34:25,212 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: on_validation_start
2025-07-23 16:34:25,212 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: on_validation_start
2025-07-23 16:34:25,212 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: on_validation_start
2025-07-23 16:34:25,212 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: on_validation_start
2025-07-23 16:34:25,212 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_epoch_start
2025-07-23 16:34:25,212 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_epoch_start
2025-07-23 16:34:25,212 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_epoch_start
2025-07-23 16:34:25,212 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_epoch_start
2025-07-23 16:34:25,214 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_epoch_start
2025-07-23 16:34:25,214 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_epoch_start
2025-07-23 16:34:25,214 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_epoch_start
2025-07-23 16:34:25,214 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_epoch_start
2025-07-23 16:34:25,215 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_before_batch_transfer
2025-07-23 16:34:25,215 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_before_batch_transfer
2025-07-23 16:34:25,215 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_before_batch_transfer
2025-07-23 16:34:25,215 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_before_batch_transfer
2025-07-23 16:34:25,215 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: batch_to_device
2025-07-23 16:34:25,215 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: batch_to_device
2025-07-23 16:34:25,215 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: batch_to_device
2025-07-23 16:34:25,215 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: batch_to_device
2025-07-23 16:34:25,215 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: transfer_batch_to_device
2025-07-23 16:34:25,215 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: transfer_batch_to_device
2025-07-23 16:34:25,215 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: transfer_batch_to_device
2025-07-23 16:34:25,215 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: transfer_batch_to_device
2025-07-23 16:34:25,218 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: on_after_batch_transfer
2025-07-23 16:34:25,219 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_batch_start
2025-07-23 16:34:25,219 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: on_after_batch_transfer
2025-07-23 16:34:25,219 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: on_after_batch_transfer
2025-07-23 16:34:25,219 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_batch_start
2025-07-23 16:34:25,219 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_batch_start
2025-07-23 16:34:25,220 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: on_after_batch_transfer
2025-07-23 16:34:25,220 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_batch_start
2025-07-23 16:34:25,223 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_batch_start
2025-07-23 16:34:25,223 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_batch_start
2025-07-23 16:34:25,223 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_batch_start
2025-07-23 16:34:25,223 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_batch_start
2025-07-23 16:34:25,223 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: validation_step
2025-07-23 16:34:25,223 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: validation_step
2025-07-23 16:34:25,223 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: validation_step
2025-07-23 16:34:25,223 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: validation_step
2025-07-23 16:34:44,679 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_exception
2025-07-23 16:34:44,679 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_exception
2025-07-23 16:34:44,680 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_exception
2025-07-23 16:34:44,683 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_exception
2025-07-23 16:34:44,711 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: on_exception
2025-07-23 16:34:44,711 - lightning.pytorch.strategies.strategy - DEBUG - MPStrategy: moving model to CPU
2025-07-23 16:34:44,712 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: on_exception
2025-07-23 16:34:44,712 - lightning.pytorch.strategies.strategy - DEBUG - MPStrategy: moving model to CPU
2025-07-23 16:34:44,715 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: on_exception
2025-07-23 16:34:44,715 - lightning.pytorch.strategies.strategy - DEBUG - MPStrategy: moving model to CPU
2025-07-23 16:34:44,719 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: on_exception
2025-07-23 16:34:44,720 - lightning.pytorch.strategies.strategy - DEBUG - MPStrategy: moving model to CPU
2025-07-23 16:42:19,663 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: Initializing trainer with parameters: {'self': <lightning.pytorch.trainer.trainer.Trainer object at 0x7aec52dd3590>, 'accelerator': 'gpu', 'strategy': <internal.mp_strategy.MPStrategy object at 0x7aec52e146b0>, 'devices': -1, 'num_nodes': 1, 'precision': None, 'logger': <lightning.pytorch.loggers.tensorboard.TensorBoardLogger object at 0x7aec52b9b1d0>, 'callbacks': [<internal.entrypoints.gspl.LazyInstance_SaveGaussian object at 0x7aee32c4cec0>, <internal.entrypoints.gspl.LazyInstance_ValidateOnTrainEnd object at 0x7aec531c1220>, <internal.entrypoints.gspl.LazyInstance_KeepRunningIfWebViewerEnabled object at 0x7aec531f6cf0>, <internal.entrypoints.gspl.LazyInstance_StopImageSavingThreads object at 0x7aec5341ec60>, <internal.entrypoints.gspl.LazyInstance_ProgressBar object at 0x7aec5338e090>, <internal.entrypoints.gspl.LazyInstance_StopDataLoaderCacheThread object at 0x7aec53216840>, <lightning.pytorch.cli.SaveConfigCallback object at 0x7aec52dd0c20>], 'fast_dev_run': False, 'max_epochs': None, 'min_epochs': None, 'max_steps': 30000, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'overfit_batches': 0.0, 'val_check_interval': None, 'check_val_every_n_epoch': 1, 'num_sanity_val_steps': 1, 'log_every_n_steps': None, 'enable_checkpointing': False, 'enable_progress_bar': None, 'enable_model_summary': None, 'accumulate_grad_batches': 1, 'gradient_clip_val': None, 'gradient_clip_algorithm': None, 'deterministic': None, 'benchmark': None, 'inference_mode': True, 'use_distributed_sampler': False, 'profiler': None, 'detect_anomaly': False, 'barebones': False, 'plugins': None, 'sync_batchnorm': False, 'reload_dataloaders_every_n_epochs': 0, 'default_root_dir': None, 'model_registry': None, '__class__': <class 'lightning.pytorch.trainer.trainer.Trainer'>}
2025-07-23 16:42:19,747 - lightning.pytorch.utilities.rank_zero - INFO - GPU available: True (cuda), used: True
2025-07-23 16:42:19,747 - lightning.pytorch.utilities.rank_zero - INFO - TPU available: False, using: 0 TPU cores
2025-07-23 16:42:19,748 - lightning.pytorch.utilities.rank_zero - INFO - HPU available: False, using: 0 HPUs
2025-07-23 16:42:19,880 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: trainer fit stage
2025-07-23 16:42:19,881 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_callbacks
2025-07-23 16:42:19,882 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: setting up strategy environment
2025-07-23 16:42:29,577 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: Initializing trainer with parameters: {'self': <lightning.pytorch.trainer.trainer.Trainer object at 0x7b98079a7e90>, 'accelerator': 'gpu', 'strategy': <internal.mp_strategy.MPStrategy object at 0x7b98079f46b0>, 'devices': -1, 'num_nodes': 1, 'precision': None, 'logger': <lightning.pytorch.loggers.tensorboard.TensorBoardLogger object at 0x7b98079f5520>, 'callbacks': [<internal.entrypoints.gspl.LazyInstance_SaveGaussian object at 0x7b99e77f0e00>, <internal.entrypoints.gspl.LazyInstance_ValidateOnTrainEnd object at 0x7b9807cb3a70>, <internal.entrypoints.gspl.LazyInstance_KeepRunningIfWebViewerEnabled object at 0x7b981394b260>, <internal.entrypoints.gspl.LazyInstance_StopImageSavingThreads object at 0x7b98080d62a0>, <internal.entrypoints.gspl.LazyInstance_ProgressBar object at 0x7b9807bb48c0>, <internal.entrypoints.gspl.LazyInstance_StopDataLoaderCacheThread object at 0x7b9807fc1e80>, <lightning.pytorch.cli.SaveConfigCallback object at 0x7b9807811700>], 'fast_dev_run': False, 'max_epochs': None, 'min_epochs': None, 'max_steps': 30000, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'overfit_batches': 0.0, 'val_check_interval': None, 'check_val_every_n_epoch': 1, 'num_sanity_val_steps': 1, 'log_every_n_steps': None, 'enable_checkpointing': False, 'enable_progress_bar': None, 'enable_model_summary': None, 'accumulate_grad_batches': 1, 'gradient_clip_val': None, 'gradient_clip_algorithm': None, 'deterministic': None, 'benchmark': None, 'inference_mode': True, 'use_distributed_sampler': False, 'profiler': None, 'detect_anomaly': False, 'barebones': False, 'plugins': None, 'sync_batchnorm': False, 'reload_dataloaders_every_n_epochs': 0, 'default_root_dir': None, 'model_registry': None, '__class__': <class 'lightning.pytorch.trainer.trainer.Trainer'>}
2025-07-23 16:42:29,661 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: trainer fit stage
2025-07-23 16:42:29,661 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_callbacks
2025-07-23 16:42:29,662 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: setting up strategy environment
2025-07-23 16:42:29,847 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: Initializing trainer with parameters: {'self': <lightning.pytorch.trainer.trainer.Trainer object at 0x7d2c6fa96480>, 'accelerator': 'gpu', 'strategy': <internal.mp_strategy.MPStrategy object at 0x7d2c6f4ad2e0>, 'devices': -1, 'num_nodes': 1, 'precision': None, 'logger': <lightning.pytorch.loggers.tensorboard.TensorBoardLogger object at 0x7d2c6f54c170>, 'callbacks': [<internal.entrypoints.gspl.LazyInstance_SaveGaussian object at 0x7d2e4f2bce00>, <internal.entrypoints.gspl.LazyInstance_ValidateOnTrainEnd object at 0x7d2c6fba66c0>, <internal.entrypoints.gspl.LazyInstance_KeepRunningIfWebViewerEnabled object at 0x7d2c6f789130>, <internal.entrypoints.gspl.LazyInstance_StopImageSavingThreads object at 0x7d2c6fb05010>, <internal.entrypoints.gspl.LazyInstance_ProgressBar object at 0x7d2c6fa94fe0>, <internal.entrypoints.gspl.LazyInstance_StopDataLoaderCacheThread object at 0x7d2c7ca8ecc0>, <lightning.pytorch.cli.SaveConfigCallback object at 0x7d2c6f698dd0>], 'fast_dev_run': False, 'max_epochs': None, 'min_epochs': None, 'max_steps': 30000, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'overfit_batches': 0.0, 'val_check_interval': None, 'check_val_every_n_epoch': 1, 'num_sanity_val_steps': 1, 'log_every_n_steps': None, 'enable_checkpointing': False, 'enable_progress_bar': None, 'enable_model_summary': None, 'accumulate_grad_batches': 1, 'gradient_clip_val': None, 'gradient_clip_algorithm': None, 'deterministic': None, 'benchmark': None, 'inference_mode': True, 'use_distributed_sampler': False, 'profiler': None, 'detect_anomaly': False, 'barebones': False, 'plugins': None, 'sync_batchnorm': False, 'reload_dataloaders_every_n_epochs': 0, 'default_root_dir': None, 'model_registry': None, '__class__': <class 'lightning.pytorch.trainer.trainer.Trainer'>}
2025-07-23 16:42:29,863 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: Initializing trainer with parameters: {'self': <lightning.pytorch.trainer.trainer.Trainer object at 0x732848dbd280>, 'accelerator': 'gpu', 'strategy': <internal.mp_strategy.MPStrategy object at 0x732848eec6b0>, 'devices': -1, 'num_nodes': 1, 'precision': None, 'logger': <lightning.pytorch.loggers.tensorboard.TensorBoardLogger object at 0x732848c8bf80>, 'callbacks': [<internal.entrypoints.gspl.LazyInstance_SaveGaussian object at 0x732849497ef0>, <internal.entrypoints.gspl.LazyInstance_ValidateOnTrainEnd object at 0x73284934b7a0>, <internal.entrypoints.gspl.LazyInstance_KeepRunningIfWebViewerEnabled object at 0x7328493ab830>, <internal.entrypoints.gspl.LazyInstance_StopImageSavingThreads object at 0x732849494ef0>, <internal.entrypoints.gspl.LazyInstance_ProgressBar object at 0x73284930c890>, <internal.entrypoints.gspl.LazyInstance_StopDataLoaderCacheThread object at 0x732849636120>, <lightning.pytorch.cli.SaveConfigCallback object at 0x73284911ade0>], 'fast_dev_run': False, 'max_epochs': None, 'min_epochs': None, 'max_steps': 30000, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'overfit_batches': 0.0, 'val_check_interval': None, 'check_val_every_n_epoch': 1, 'num_sanity_val_steps': 1, 'log_every_n_steps': None, 'enable_checkpointing': False, 'enable_progress_bar': None, 'enable_model_summary': None, 'accumulate_grad_batches': 1, 'gradient_clip_val': None, 'gradient_clip_algorithm': None, 'deterministic': None, 'benchmark': None, 'inference_mode': True, 'use_distributed_sampler': False, 'profiler': None, 'detect_anomaly': False, 'barebones': False, 'plugins': None, 'sync_batchnorm': False, 'reload_dataloaders_every_n_epochs': 0, 'default_root_dir': None, 'model_registry': None, '__class__': <class 'lightning.pytorch.trainer.trainer.Trainer'>}
2025-07-23 16:42:29,931 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: trainer fit stage
2025-07-23 16:42:29,932 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_callbacks
2025-07-23 16:42:29,932 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: setting up strategy environment
2025-07-23 16:42:29,951 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: trainer fit stage
2025-07-23 16:42:29,952 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_callbacks
2025-07-23 16:42:29,952 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: setting up strategy environment
2025-07-23 16:42:30,107 - lightning.pytorch.utilities.rank_zero - INFO - ----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 4 processes
----------------------------------------------------------------------------------------------------

2025-07-23 16:42:30,113 - lightning.pytorch.utilities.rank_zero - INFO - You are using a CUDA device ('NVIDIA GeForce RTX 3090 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
2025-07-23 16:42:30,932 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: preparing data
2025-07-23 16:42:30,980 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: preparing data
2025-07-23 16:42:30,981 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: preparing data
2025-07-23 16:42:30,988 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: preparing data
2025-07-23 16:42:30,999 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: setup
2025-07-23 16:42:30,999 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: setup
2025-07-23 16:42:30,999 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: setup
2025-07-23 16:42:30,999 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: setup
2025-07-23 16:42:36,275 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: setup
2025-07-23 16:42:36,275 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: setup
2025-07-23 16:42:36,275 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: setup
2025-07-23 16:42:36,275 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: setup
2025-07-23 16:42:36,439 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: setup
2025-07-23 16:42:36,439 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: setup
2025-07-23 16:42:36,439 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: setup
2025-07-23 16:42:36,439 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: setup
2025-07-23 16:42:38,685 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: configuring model
2025-07-23 16:42:38,685 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: configuring model
2025-07-23 16:42:38,685 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: configuring model
2025-07-23 16:42:38,685 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: configuring model
2025-07-23 16:42:38,685 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring module and callbacks from checkpoint path: None
2025-07-23 16:42:38,685 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring module and callbacks from checkpoint path: None
2025-07-23 16:42:38,685 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring module and callbacks from checkpoint path: None
2025-07-23 16:42:38,685 - lightning.pytorch.trainer.connectors.checkpoint_connector - DEBUG - `checkpoint_path` not specified. Skipping checkpoint loading.
2025-07-23 16:42:38,685 - lightning.pytorch.trainer.connectors.checkpoint_connector - DEBUG - `checkpoint_path` not specified. Skipping checkpoint loading.
2025-07-23 16:42:38,685 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring module and callbacks from checkpoint path: None
2025-07-23 16:42:38,685 - lightning.pytorch.trainer.connectors.checkpoint_connector - DEBUG - `checkpoint_path` not specified. Skipping checkpoint loading.
2025-07-23 16:42:38,685 - lightning.pytorch.trainer.connectors.checkpoint_connector - DEBUG - `checkpoint_path` not specified. Skipping checkpoint loading.
2025-07-23 16:42:38,711 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [4,5,6,7]
2025-07-23 16:42:38,711 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [4,5,6,7]
2025-07-23 16:42:38,711 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [4,5,6,7]
2025-07-23 16:42:38,712 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_optimizers
2025-07-23 16:42:38,712 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_optimizers
2025-07-23 16:42:38,712 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_optimizers
2025-07-23 16:42:38,713 - lightning.pytorch.accelerators.cuda - INFO - LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [4,5,6,7]
2025-07-23 16:42:38,714 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: configure_optimizers
2025-07-23 16:42:38,715 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_fit_start
2025-07-23 16:42:38,716 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_fit_start
2025-07-23 16:42:38,716 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_fit_start
2025-07-23 16:42:38,718 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_fit_start
2025-07-23 16:42:38,720 - lightning.pytorch.callbacks.model_summary - INFO - 
  | Name               | Type                                    | Params | Mode 
---------------------------------------------------------------------------------------
0 | gaussian_model     | VanillaGaussianModel                    | 2.0 M  | train
1 | renderer           | GSplatDistributedRendererImpl           | 0      | train
2 | density_controller | DistributedVanillaDensityControllerImpl | 0      | train
3 | metric             | VanillaMetricsImpl                      | 0      | train
---------------------------------------------------------------------------------------
2.0 M     Trainable params
0         Non-trainable params
2.0 M     Total params
8.026     Total estimated model params size (MB)
6         Modules in train mode
0         Modules in eval mode
2025-07-23 16:42:38,724 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_fit_start
2025-07-23 16:42:38,724 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_fit_start
2025-07-23 16:42:38,724 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_fit_start
2025-07-23 16:42:38,724 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_fit_start
2025-07-23 16:42:38,724 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring training state
2025-07-23 16:42:38,724 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring training state
2025-07-23 16:42:38,725 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring training state
2025-07-23 16:42:39,093 - lightning.pytorch.trainer.trainer - DEBUG - Trainer: restoring training state
2025-07-23 16:42:39,096 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_sanity_check_start
2025-07-23 16:42:39,096 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_sanity_check_start
2025-07-23 16:42:39,096 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_sanity_check_start
2025-07-23 16:42:39,096 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_sanity_check_start
2025-07-23 16:42:39,100 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: val_dataloader
2025-07-23 16:42:39,100 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: val_dataloader
2025-07-23 16:42:39,100 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: val_dataloader
2025-07-23 16:42:39,100 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: val_dataloader
2025-07-23 16:42:40,523 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_model_eval
2025-07-23 16:42:40,524 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_start
2025-07-23 16:42:40,533 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_model_eval
2025-07-23 16:42:40,533 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_start
2025-07-23 16:42:40,536 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_model_eval
2025-07-23 16:42:40,536 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_start
2025-07-23 16:42:40,549 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_model_eval
2025-07-23 16:42:40,550 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_start
2025-07-23 16:42:40,553 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_start
2025-07-23 16:42:40,553 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_start
2025-07-23 16:42:40,553 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_start
2025-07-23 16:42:40,553 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_start
2025-07-23 16:42:40,553 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: on_validation_start
2025-07-23 16:42:40,553 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: on_validation_start
2025-07-23 16:42:40,553 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: on_validation_start
2025-07-23 16:42:40,553 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: on_validation_start
2025-07-23 16:42:40,553 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_epoch_start
2025-07-23 16:42:40,553 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_epoch_start
2025-07-23 16:42:40,553 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_epoch_start
2025-07-23 16:42:40,553 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_epoch_start
2025-07-23 16:42:40,555 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_epoch_start
2025-07-23 16:42:40,555 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_epoch_start
2025-07-23 16:42:40,555 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_epoch_start
2025-07-23 16:42:40,555 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_epoch_start
2025-07-23 16:42:40,555 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_before_batch_transfer
2025-07-23 16:42:40,555 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_before_batch_transfer
2025-07-23 16:42:40,556 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: batch_to_device
2025-07-23 16:42:40,556 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_before_batch_transfer
2025-07-23 16:42:40,556 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_before_batch_transfer
2025-07-23 16:42:40,556 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: batch_to_device
2025-07-23 16:42:40,556 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: batch_to_device
2025-07-23 16:42:40,556 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: batch_to_device
2025-07-23 16:42:40,556 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: transfer_batch_to_device
2025-07-23 16:42:40,556 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: transfer_batch_to_device
2025-07-23 16:42:40,556 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: transfer_batch_to_device
2025-07-23 16:42:40,556 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: transfer_batch_to_device
2025-07-23 16:42:40,559 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: on_after_batch_transfer
2025-07-23 16:42:40,559 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: on_after_batch_transfer
2025-07-23 16:42:40,559 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_batch_start
2025-07-23 16:42:40,559 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_batch_start
2025-07-23 16:42:40,559 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: on_after_batch_transfer
2025-07-23 16:42:40,559 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: on_after_batch_transfer
2025-07-23 16:42:40,560 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_batch_start
2025-07-23 16:42:40,560 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_validation_batch_start
2025-07-23 16:42:40,563 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_batch_start
2025-07-23 16:42:40,563 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_batch_start
2025-07-23 16:42:40,563 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_batch_start
2025-07-23 16:42:40,563 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning module hook: on_validation_batch_start
2025-07-23 16:42:40,563 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: validation_step
2025-07-23 16:42:40,563 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: validation_step
2025-07-23 16:42:40,563 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: validation_step
2025-07-23 16:42:40,563 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling strategy hook: validation_step
2025-07-23 16:42:42,246 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_exception
2025-07-23 16:42:42,247 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_exception
2025-07-23 16:42:42,264 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_exception
2025-07-23 16:42:42,272 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling callback hook: on_exception
2025-07-23 16:42:42,277 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: on_exception
2025-07-23 16:42:42,277 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: on_exception
2025-07-23 16:42:42,277 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: on_exception
2025-07-23 16:42:42,277 - lightning.pytorch.trainer.call - DEBUG - Trainer: calling lightning datamodule hook: on_exception
2025-07-23 16:42:42,277 - lightning.pytorch.strategies.strategy - DEBUG - MPStrategy: moving model to CPU
2025-07-23 16:42:42,277 - lightning.pytorch.strategies.strategy - DEBUG - MPStrategy: moving model to CPU
2025-07-23 16:42:42,277 - lightning.pytorch.strategies.strategy - DEBUG - MPStrategy: moving model to CPU
2025-07-23 16:42:42,278 - lightning.pytorch.strategies.strategy - DEBUG - MPStrategy: moving model to CPU
